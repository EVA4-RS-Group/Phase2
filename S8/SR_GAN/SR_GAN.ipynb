{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwc3ursEjfv6",
        "outputId": "503069a9-af0f-40e4-a880-a6123816ce28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Oct  7 01:27:56 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPaA-JkHo5kW",
        "outputId": "d82fb726-64f4-4c74-ff89-8aad7f6dc2ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pytorch_ssim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_ssim\n",
            "  Downloading https://files.pythonhosted.org/packages/dc/78/f6cfa15ff7c66de5bb0873fb4bd699ff8024a0b00a94babbd216e64202b7/pytorch_ssim-0.1.tar.gz\n",
            "Building wheels for collected packages: pytorch-ssim\n",
            "  Building wheel for pytorch-ssim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-ssim: filename=pytorch_ssim-0.1-cp36-none-any.whl size=2027 sha256=7b36427cdc281fd38ceaa3ca0d1ed014033dd3383d287fe81061a605133d5984\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/60/c8/85a73ea90dcf1d39d5d7f94d83988511f0370229dee641bb79\n",
            "Successfully built pytorch-ssim\n",
            "Installing collected packages: pytorch-ssim\n",
            "Successfully installed pytorch-ssim-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfbj60t6gxqS"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "from math import log10\n",
        "\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.utils as utils\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pytorch_ssim\n",
        "from data_utils import TrainDatasetFromFolder, ValDatasetFromFolder, display_transform\n",
        "from loss import GeneratorLoss\n",
        "from model import Generator, Discriminator"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oovM1vXJqMfJ",
        "outputId": "b035a129-7233-40a6-dc14-a4e9a9f8a08c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd .."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBb5Cwcfjbew"
      },
      "source": [
        "# !mkdir data\n",
        "!cp -r \"/content/drive/My Drive/Phase2_S2/S2/final_images_ver1/data\" \"/content/\"\n",
        "# %cd data\n",
        "# !unzip \"Large QuadCopters.zip\"\n",
        "# !rm -rf \"Large QuadCopters.zip\"\n",
        "# !cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4RyGMjAg0gS"
      },
      "source": [
        "CROP_SIZE = 88#opt.crop_size\n",
        "UPSCALE_FACTOR = 4#opt.upscale_factor\n",
        "NUM_EPOCHS = 100#opt.num_epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTFvSdJyg4oN"
      },
      "source": [
        "train_set = TrainDatasetFromFolder('data/DIV2K_train_HR', crop_size=CROP_SIZE, upscale_factor=UPSCALE_FACTOR)\n",
        "val_set = ValDatasetFromFolder('data/DIV2K_valid_HR', upscale_factor=UPSCALE_FACTOR)\n",
        "train_loader = DataLoader(dataset=train_set, num_workers=4, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_set, num_workers=4, batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1iGuEJThBBE"
      },
      "source": [
        "netG = Generator(UPSCALE_FACTOR)\n",
        "print('# generator parameters:', sum(param.numel() for param in netG.parameters()))\n",
        "netD = Discriminator()\n",
        "print('# discriminator parameters:', sum(param.numel() for param in netD.parameters()))\n",
        "\n",
        "generator_criterion = GeneratorLoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    netG.cuda()\n",
        "    netD.cuda()\n",
        "    generator_criterion.cuda()\n",
        "\n",
        "optimizerG = optim.Adam(netG.parameters())\n",
        "optimizerD = optim.Adam(netD.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWfXgVlzgWNJ"
      },
      "source": [
        "results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    train_bar = tqdm(train_loader)\n",
        "    running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
        "\n",
        "    netG.train()\n",
        "    netD.train()\n",
        "    for data, target in train_bar:\n",
        "        g_update_first = True\n",
        "        batch_size = data.size(0)\n",
        "        running_results['batch_sizes'] += batch_size\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize D(x)-1-D(G(z))\n",
        "        ###########################\n",
        "        real_img = Variable(target)\n",
        "        if torch.cuda.is_available():\n",
        "            real_img = real_img.cuda()\n",
        "        z = Variable(data)\n",
        "        if torch.cuda.is_available():\n",
        "            z = z.cuda()\n",
        "        fake_img = netG(z)\n",
        "\n",
        "        netD.zero_grad()\n",
        "        real_out = netD(real_img).mean()\n",
        "        fake_out = netD(fake_img).mean()\n",
        "        d_loss = 1 - real_out + fake_out\n",
        "        d_loss.backward(retain_graph=True)\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
        "        g_loss.backward()\n",
        "        \n",
        "        fake_img = netG(z)\n",
        "        fake_out = netD(fake_img).mean()\n",
        "        \n",
        "        \n",
        "        optimizerG.step()\n",
        "\n",
        "        # loss for current batch before optimization \n",
        "        running_results['g_loss'] += g_loss.item() * batch_size\n",
        "        running_results['d_loss'] += d_loss.item() * batch_size\n",
        "        running_results['d_score'] += real_out.item() * batch_size\n",
        "        running_results['g_score'] += fake_out.item() * batch_size\n",
        "\n",
        "        train_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f' % (\n",
        "            epoch, NUM_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n",
        "            running_results['g_loss'] / running_results['batch_sizes'],\n",
        "            running_results['d_score'] / running_results['batch_sizes'],\n",
        "            running_results['g_score'] / running_results['batch_sizes']))\n",
        "\n",
        "    netG.eval()\n",
        "    out_path = 'training_results/SRF_' + str(UPSCALE_FACTOR) + '/'\n",
        "    if not os.path.exists(out_path):\n",
        "        os.makedirs(out_path)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        val_bar = tqdm(val_loader)\n",
        "        valing_results = {'mse': 0, 'ssims': 0, 'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n",
        "        val_images = []\n",
        "        for val_lr, val_hr_restore, val_hr in val_bar:\n",
        "            batch_size = val_lr.size(0)\n",
        "            valing_results['batch_sizes'] += batch_size\n",
        "            lr = val_lr\n",
        "            hr = val_hr\n",
        "            if torch.cuda.is_available():\n",
        "                lr = lr.cuda()\n",
        "                hr = hr.cuda()\n",
        "            sr = netG(lr)\n",
        "    \n",
        "            batch_mse = ((sr - hr) ** 2).data.mean()\n",
        "            valing_results['mse'] += batch_mse * batch_size\n",
        "            batch_ssim = pytorch_ssim.ssim(sr, hr).item()\n",
        "            valing_results['ssims'] += batch_ssim * batch_size\n",
        "            valing_results['psnr'] = 10 * log10((hr.max()**2) / (valing_results['mse'] / valing_results['batch_sizes']))\n",
        "            valing_results['ssim'] = valing_results['ssims'] / valing_results['batch_sizes']\n",
        "            val_bar.set_description(\n",
        "                desc='[converting LR images to SR images] PSNR: %.4f dB SSIM: %.4f' % (\n",
        "                    valing_results['psnr'], valing_results['ssim']))\n",
        "    \n",
        "            val_images.extend(\n",
        "                [display_transform()(val_hr_restore.squeeze(0)), display_transform()(hr.data.cpu().squeeze(0)),\n",
        "                 display_transform()(sr.data.cpu().squeeze(0))])\n",
        "        val_images = torch.stack(val_images)\n",
        "        val_images = torch.chunk(val_images, val_images.size(0) // 15)\n",
        "        val_save_bar = tqdm(val_images, desc='[saving training results]')\n",
        "        index = 1\n",
        "        for image in val_save_bar:\n",
        "            image = utils.make_grid(image, nrow=3, padding=5)\n",
        "            utils.save_image(image, out_path + 'epoch_%d_index_%d.png' % (epoch, index), padding=5)\n",
        "            index += 1\n",
        "\n",
        "    # save model parameters\n",
        "    torch.save(netG.state_dict(), 'epochs/netG_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
        "    torch.save(netD.state_dict(), 'epochs/netD_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
        "    # save loss\\scores\\psnr\\ssim\n",
        "    results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\n",
        "    results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\n",
        "    results['d_score'].append(running_results['d_score'] / running_results['batch_sizes'])\n",
        "    results['g_score'].append(running_results['g_score'] / running_results['batch_sizes'])\n",
        "    results['psnr'].append(valing_results['psnr'])\n",
        "    results['ssim'].append(valing_results['ssim'])\n",
        "\n",
        "    if epoch % 10 == 0 and epoch != 0:\n",
        "        out_path = 'statistics/'\n",
        "        data_frame = pd.DataFrame(\n",
        "            data={'Loss_D': results['d_loss'], 'Loss_G': results['g_loss'], 'Score_D': results['d_score'],\n",
        "                  'Score_G': results['g_score'], 'PSNR': results['psnr'], 'SSIM': results['ssim']},\n",
        "            index=range(1, epoch + 1))\n",
        "        data_frame.to_csv(out_path + 'srf_' + str(UPSCALE_FACTOR) + '_train_results.csv', index_label='Epoch')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
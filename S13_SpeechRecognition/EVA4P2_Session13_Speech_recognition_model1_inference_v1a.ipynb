{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4P2_Session13_Speech_recognition_model1_inference_v1a.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMujiCmkwF+xY55JimNCgvY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EVA4-RS-Group/Phase2/blob/master/S13_SpeechRecognition/EVA4P2_Session13_Speech_recognition_model1_inference_v1a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVuKGv1pvVQB"
      },
      "source": [
        "# 1. Loading the required libraries and dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV0Qb8sqyhsc",
        "outputId": "9443e1a7-f1fe-4cf9-cdf1-1154e0a898a7"
      },
      "source": [
        "!pip install torchaudio -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.6MB 12.6MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk4SbCnKzgbG"
      },
      "source": [
        "!rm -rf ./*\n",
        "!wget https://github.com/EVA4-RS-Group/Phase2/releases/download/S13/sample_test_data.zip -q\n",
        "!unzip -q sample_test_data.zip\n",
        "!rm -rf /content/__MACOSX\n",
        "!rm -rf /content/sample_test_data.zip\n",
        "!wget -q https://github.com/EVA4-RS-Group/Phase2/releases/download/S13/weights_cpu_voicerec.pt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfxu_1koAupf"
      },
      "source": [
        "import glob\n",
        "sample_file_list = list(glob.iglob('/content/sample_test_data/*.wav', recursive=True))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI7Xgs6Ovbni",
        "outputId": "f3af933a-b3a7-4d75-dd4e-2fe357ccdd7a"
      },
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import random "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
            "  '\"sox\" backend is being deprecated. '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1niHG1Uwtw8u"
      },
      "source": [
        "# 2. Define the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-Uw0f25RhEp"
      },
      "source": [
        "class SpeechRNN(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(SpeechRNN, self).__init__()\n",
        "    \n",
        "    self.lstm = torch.nn.GRU(input_size = 12, \n",
        "                              hidden_size= 256, \n",
        "                              num_layers = 2, \n",
        "                              batch_first=True)\n",
        "    \n",
        "    self.out_layer = torch.nn.Linear(256, 30)\n",
        "    \n",
        "    self.softmax = torch.nn.LogSoftmax(dim=1)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    \n",
        "    out, _ = self.lstm(x)\n",
        "    \n",
        "    x = self.out_layer(out[:,-1,:])\n",
        "    \n",
        "    return self.softmax(x)\n",
        "\n",
        "classes = ['cat', 'dog', 'six', 'bird', 'eight', 'no', 'tree', 'marvin', 'left',\n",
        "           'down', 'off', 'on', 'five', 'three', 'go', 'seven', 'sheila', \n",
        "           'right', 'four', 'happy', 'bed', 'zero', 'one', 'wow', 'two', 'yes',\n",
        "           'house', 'up', 'nine', 'stop']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6cWG01zyRXD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQioLWGBvSwT",
        "outputId": "0d9c92c3-f47f-4d4e-d01b-27028cfde060"
      },
      "source": [
        "DEVICE=torch.device('cpu')\n",
        "model = SpeechRNN()\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "model.load_state_dict(torch.load('/content/weights_cpu_voicerec.pt', map_location=DEVICE))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvl7KI1vw88R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a51a4733-a2ed-432e-a276-33dccb1caf47"
      },
      "source": [
        "\n",
        "wav_file = random.choice(sample_file_list)\n",
        "waveform,_ = torchaudio.load(wav_file, normalization=True)\n",
        "      \n",
        "# if the waveform is too short (less than 1 second) we pad it with zeroes\n",
        "if waveform.shape[1] < 16000:\n",
        "    waveform = F.pad(input=waveform, pad=(0, 16000 - waveform.shape[1]), mode='constant', value=0)\n",
        "                     \n",
        "mfcc_transform = torchaudio.transforms.MFCC(n_mfcc=12, log_mels=True)\n",
        "mfcc = mfcc_transform(waveform).squeeze(0).transpose(0,1)\n",
        "x = mfcc.unsqueeze(0)\n",
        "\n",
        "model.eval()\n",
        "y = model(x)\n",
        "predicted_label = classes[y.max(1)[1].numpy().item()]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchaudio/functional.py:318: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  \"At least one mel filterbank has all zero values. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiVq0GixBlfh",
        "outputId": "30969bb3-eb1f-4190-9e10-46398442e67c"
      },
      "source": [
        "print(f'Prediction of input file {wav_file.split(\"/\")[-1]} is {predicted_label}.')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction of input file marvin_20d3f11f_nohash_0.wav is marvin.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
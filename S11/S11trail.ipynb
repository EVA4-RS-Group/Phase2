{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S11trail.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO7vNdQFCvBYujCE0399UTe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EVA4-RS-Group/Phase2/blob/master/S11/S11trail.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-94vfBJKBtG",
        "outputId": "4e68a7d3-a745-40a3-abeb-48327d6b061b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, copy, time\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "# we will use CUDA if it is available\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE=torch.device('cuda:0') # or set to 'cpu'\n",
        "print(\"CUDA:\", USE_CUDA)\n",
        "print(DEVICE)\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA: True\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXczNEkZsukw"
      },
      "source": [
        "\n",
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A standard Encoder-Decoder architecture. Base for this and many \n",
        "    other models.\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.trg_embed = trg_embed\n",
        "        self.generator = generator\n",
        "        \n",
        "    def forward(self, src, trg, src_mask, trg_mask, src_lengths, trg_lengths):\n",
        "        \"\"\"Take in and process masked src and target sequences.\"\"\"\n",
        "        encoder_hidden, encoder_final = self.encode(src, src_mask, src_lengths)\n",
        "        return self.decode(encoder_hidden, encoder_final, src_mask, trg, trg_mask)\n",
        "    \n",
        "    def encode(self, src, src_mask, src_lengths):\n",
        "        return self.encoder(self.src_embed(src), src_mask, src_lengths)\n",
        "    \n",
        "    def decode(self, encoder_hidden, encoder_final, src_mask, trg, trg_mask,\n",
        "               decoder_hidden=None):\n",
        "        return self.decoder(self.trg_embed(trg), encoder_hidden, encoder_final,\n",
        "                            src_mask, trg_mask, hidden=decoder_hidden)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shFnR2hssx_3"
      },
      "source": [
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
        "    def __init__(self, hidden_size, vocab_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.proj(x), dim=-1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQhMtvdNs0pf"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"Encodes a sequence of word embeddings\"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, \n",
        "                          batch_first=True, bidirectional=True, dropout=dropout)\n",
        "        \n",
        "    def forward(self, x, mask, lengths):\n",
        "        \"\"\"\n",
        "        Applies a bidirectional GRU to sequence of embeddings x.\n",
        "        The input mini-batch x needs to be sorted by length.\n",
        "        x should have dimensions [batch, time, dim].\n",
        "        \"\"\"\n",
        "        packed = pack_padded_sequence(x, lengths, batch_first=True)\n",
        "        output, final = self.rnn(packed)\n",
        "        output, _ = pad_packed_sequence(output, batch_first=True)\n",
        "\n",
        "        # we need to manually concatenate the final states for both directions\n",
        "        fwd_final = final[0:final.size(0):2]\n",
        "        bwd_final = final[1:final.size(0):2]\n",
        "        final = torch.cat([fwd_final, bwd_final], dim=2)  # [num_layers, batch, 2*dim]\n",
        "\n",
        "        return output, final"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KDP5Llqs36X"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"A conditional RNN decoder with attention.\"\"\"\n",
        "    \n",
        "    def __init__(self, emb_size, hidden_size, attention, num_layers=1, dropout=0.5,\n",
        "                 bridge=True):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.attention = attention\n",
        "        self.dropout = dropout\n",
        "                 \n",
        "        self.rnn = nn.GRU(emb_size + 2*hidden_size, hidden_size, num_layers,\n",
        "                          batch_first=True, dropout=dropout)\n",
        "                 \n",
        "        # to initialize from the final encoder state\n",
        "        self.bridge = nn.Linear(2*hidden_size, hidden_size, bias=True) if bridge else None\n",
        "\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "        self.pre_output_layer = nn.Linear(hidden_size + 2*hidden_size + emb_size,\n",
        "                                          hidden_size, bias=False)\n",
        "        \n",
        "    def forward_step(self, prev_embed, encoder_hidden, src_mask, proj_key, hidden):\n",
        "        \"\"\"Perform a single decoder step (1 word)\"\"\"\n",
        "\n",
        "        # compute context vector using attention mechanism\n",
        "        query = hidden[-1].unsqueeze(1)  # [#layers, B, D] -> [B, 1, D]\n",
        "        context, attn_probs = self.attention(\n",
        "            query=query, proj_key=proj_key,\n",
        "            value=encoder_hidden, mask=src_mask)\n",
        "\n",
        "        # update rnn hidden state\n",
        "        rnn_input = torch.cat([prev_embed, context], dim=2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "         \n",
        "        pre_output = torch.cat([prev_embed, output, context], dim=2)\n",
        "        pre_output = self.dropout_layer(pre_output)\n",
        "        pre_output = self.pre_output_layer(pre_output)\n",
        "\n",
        "        return output, hidden, pre_output\n",
        "    \n",
        "    def forward(self, trg_embed, encoder_hidden, encoder_final, \n",
        "                src_mask, trg_mask, hidden=None, max_len=None):\n",
        "        \"\"\"Unroll the decoder one step at a time.\"\"\"\n",
        "                                         \n",
        "        # the maximum number of steps to unroll the RNN\n",
        "        if max_len is None:\n",
        "            max_len = trg_mask.size(-1)\n",
        "\n",
        "        # initialize decoder hidden state\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(encoder_final)\n",
        "        \n",
        "        # pre-compute projected encoder hidden states\n",
        "        # (the \"keys\" for the attention mechanism)\n",
        "        # this is only done for efficiency\n",
        "        proj_key = self.attention.key_layer(encoder_hidden)\n",
        "        \n",
        "        # here we store all intermediate hidden states and pre-output vectors\n",
        "        decoder_states = []\n",
        "        pre_output_vectors = []\n",
        "        \n",
        "        # unroll the decoder RNN for max_len steps\n",
        "        for i in range(max_len):\n",
        "            prev_embed = trg_embed[:, i].unsqueeze(1)\n",
        "            output, hidden, pre_output = self.forward_step(\n",
        "              prev_embed, encoder_hidden, src_mask, proj_key, hidden)\n",
        "            decoder_states.append(output)\n",
        "            pre_output_vectors.append(pre_output)\n",
        "\n",
        "        decoder_states = torch.cat(decoder_states, dim=1)\n",
        "        pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n",
        "        return decoder_states, hidden, pre_output_vectors  # [B, N, D]\n",
        "\n",
        "    def init_hidden(self, encoder_final):\n",
        "        \"\"\"Returns the initial decoder state,\n",
        "        conditioned on the final encoder state.\"\"\"\n",
        "\n",
        "        if encoder_final is None:\n",
        "            return None  # start with zeros\n",
        "\n",
        "        return torch.tanh(self.bridge(encoder_final))\n",
        "       "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in-EoGuttOxu"
      },
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    \"\"\"Implements Bahdanau (MLP) attention\"\"\"\n",
        "    \n",
        "    def __init__(self, hidden_size, key_size=None, query_size=None):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        \n",
        "        # We assume a bi-directional encoder so key_size is 2*hidden_size\n",
        "        key_size = 2 * hidden_size if key_size is None else key_size\n",
        "        query_size = hidden_size if query_size is None else query_size\n",
        "\n",
        "        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n",
        "        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n",
        "        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n",
        "        \n",
        "        # to store attention scores\n",
        "        self.alphas = None\n",
        "        \n",
        "    def forward(self, query=None, proj_key=None, value=None, mask=None):\n",
        "        assert mask is not None, \"mask is required\"\n",
        "\n",
        "        # We first project the query (the decoder state).\n",
        "        # The projected keys (the encoder states) were already pre-computated.\n",
        "        query = self.query_layer(query)\n",
        "        \n",
        "        # Calculate scores.\n",
        "        scores = self.energy_layer(torch.tanh(query + proj_key))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "        \n",
        "        # Mask out invalid positions.\n",
        "        # The mask marks valid positions so we invert it using `mask & 0`.\n",
        "        scores.data.masked_fill_(mask == 0, -float('inf'))\n",
        "        \n",
        "        # Turn scores to probabilities.\n",
        "        alphas = F.softmax(scores, dim=-1)\n",
        "        self.alphas = alphas        \n",
        "        \n",
        "        # The context vector is the weighted sum of the values.\n",
        "        context = torch.bmm(alphas, value)\n",
        "        \n",
        "        # context shape: [B, 1, 2D], alphas shape: [B, 1, M]\n",
        "        return context, alphas"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj9t9ll-tXbO"
      },
      "source": [
        "def make_model(src_vocab, tgt_vocab, emb_size=256, hidden_size=512, num_layers=1, dropout=0.1):\n",
        "    \"Helper: Construct a model from hyperparameters.\"\n",
        "\n",
        "    attention = BahdanauAttention(hidden_size)\n",
        "\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n",
        "        Decoder(emb_size, hidden_size, attention, num_layers=num_layers, dropout=dropout),\n",
        "        nn.Embedding(src_vocab, emb_size),\n",
        "        nn.Embedding(tgt_vocab, emb_size),\n",
        "        Generator(hidden_size, tgt_vocab))\n",
        "\n",
        "    return model.cuda() if USE_CUDA else model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKxlWZLAtibG"
      },
      "source": [
        "class Batch:\n",
        "    \"\"\"Object for holding a batch of data with mask during training.\n",
        "    Input is a batch from a torch text iterator.\n",
        "    \"\"\"\n",
        "    def __init__(self, src, trg, pad_index=0):\n",
        "        \n",
        "        src, src_lengths = src\n",
        "        \n",
        "        self.src = src\n",
        "        self.src_lengths = src_lengths\n",
        "        self.src_mask = (src != pad_index).unsqueeze(-2)\n",
        "        self.nseqs = src.size(0)\n",
        "        \n",
        "        self.trg = None\n",
        "        self.trg_y = None\n",
        "        self.trg_mask = None\n",
        "        self.trg_lengths = None\n",
        "        self.ntokens = None\n",
        "\n",
        "        if trg is not None:\n",
        "            trg, trg_lengths = trg\n",
        "            self.trg = trg[:, :-1]\n",
        "            self.trg_lengths = trg_lengths\n",
        "            self.trg_y = trg[:, 1:]\n",
        "            self.trg_mask = (self.trg_y != pad_index)\n",
        "            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n",
        "        \n",
        "        if USE_CUDA:\n",
        "            self.src = self.src.cuda()\n",
        "            self.src_mask = self.src_mask.cuda()\n",
        "\n",
        "            if trg is not None:\n",
        "                self.trg = self.trg.cuda()\n",
        "                self.trg_y = self.trg_y.cuda()\n",
        "                self.trg_mask = self.trg_mask.cuda()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQxxvLrItjSW"
      },
      "source": [
        "\n",
        "def run_epoch(data_iter, model, loss_compute, print_every=50):\n",
        "    \"\"\"Standard Training and Logging Function\"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "    print_tokens = 0\n",
        "\n",
        "    for i, batch in enumerate(data_iter, 1):\n",
        "        \n",
        "        out, _, pre_output = model.forward(batch.src, batch.trg,\n",
        "                                           batch.src_mask, batch.trg_mask,\n",
        "                                           batch.src_lengths, batch.trg_lengths)\n",
        "        loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n",
        "        total_loss += loss\n",
        "        total_tokens += batch.ntokens\n",
        "        print_tokens += batch.ntokens\n",
        "        \n",
        "        if model.training and i % print_every == 0:\n",
        "            elapsed = time.time() - start\n",
        "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
        "                    (i, loss / batch.nseqs, print_tokens / elapsed))\n",
        "            start = time.time()\n",
        "            print_tokens = 0\n",
        "\n",
        "    return math.exp(total_loss / float(total_tokens))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKCWhRLftmx2"
      },
      "source": [
        "def data_gen(num_words=11, batch_size=16, num_batches=100, length=10, pad_index=0, sos_index=1):\n",
        "    \"\"\"Generate random data for a src-tgt copy task.\"\"\"\n",
        "    for i in range(num_batches):\n",
        "        data = torch.from_numpy(\n",
        "          np.random.randint(1, num_words, size=(batch_size, length)))\n",
        "        data[:, 0] = sos_index\n",
        "        data = data.cuda() if USE_CUDA else data\n",
        "        src = data[:, 1:]\n",
        "        trg = data\n",
        "        src_lengths = [length-1] * batch_size\n",
        "        trg_lengths = [length] * batch_size\n",
        "        yield Batch((src, src_lengths), (trg, trg_lengths), pad_index=pad_index)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T_kYEnXtpil"
      },
      "source": [
        "class SimpleLossCompute:\n",
        "    \"\"\"A simple loss compute and train function.\"\"\"\n",
        "\n",
        "    def __init__(self, generator, criterion, opt=None):\n",
        "        self.generator = generator\n",
        "        self.criterion = criterion\n",
        "        self.opt = opt\n",
        "\n",
        "    def __call__(self, x, y, norm):\n",
        "        x = self.generator(x)\n",
        "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n",
        "                              y.contiguous().view(-1))\n",
        "        loss = loss / norm\n",
        "\n",
        "        if self.opt is not None:\n",
        "            loss.backward()          \n",
        "            self.opt.step()\n",
        "            self.opt.zero_grad()\n",
        "\n",
        "        return loss.data.item() * norm"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zCmqMdqtr2d"
      },
      "source": [
        "def greedy_decode(model, src, src_mask, src_lengths, max_len=100, sos_index=1, eos_index=None):\n",
        "    \"\"\"Greedily decode a sentence.\"\"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n",
        "        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n",
        "        trg_mask = torch.ones_like(prev_y)\n",
        "\n",
        "    output = []\n",
        "    attention_scores = []\n",
        "    hidden = None\n",
        "\n",
        "    for i in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            out, hidden, pre_output = model.decode(\n",
        "              encoder_hidden, encoder_final, src_mask,\n",
        "              prev_y, trg_mask, hidden)\n",
        "\n",
        "            # we predict from the pre-output layer, which is\n",
        "            # a combination of Decoder state, prev emb, and context\n",
        "            prob = model.generator(pre_output[:, -1])\n",
        "\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.data.item()\n",
        "        output.append(next_word)\n",
        "        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n",
        "        attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n",
        "    \n",
        "    output = np.array(output)\n",
        "        \n",
        "    # cut off everything starting from </s> \n",
        "    # (only when eos_index provided)\n",
        "    if eos_index is not None:\n",
        "        first_eos = np.where(output==eos_index)[0]\n",
        "        if len(first_eos) > 0:\n",
        "            output = output[:first_eos[0]]      \n",
        "    \n",
        "    return output, np.concatenate(attention_scores, axis=1)\n",
        "  \n",
        "\n",
        "def lookup_words(x, vocab=None):\n",
        "    if vocab is not None:\n",
        "        x = [vocab.itos[i] for i in x]\n",
        "\n",
        "    return [str(t) for t in x]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYZgmksutxa1"
      },
      "source": [
        "def print_examples(example_iter, model, n=2, max_len=100, \n",
        "                   sos_index=1, \n",
        "                   src_eos_index=None, \n",
        "                   trg_eos_index=None, \n",
        "                   src_vocab=None, trg_vocab=None):\n",
        "    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    print()\n",
        "    \n",
        "    if src_vocab is not None and trg_vocab is not None:\n",
        "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
        "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
        "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
        "    else:\n",
        "        src_eos_index = None\n",
        "        trg_sos_index = 1\n",
        "        trg_eos_index = None\n",
        "        \n",
        "    for i, batch in enumerate(example_iter):\n",
        "      \n",
        "        src = batch.src.cpu().numpy()[0, :]\n",
        "        trg = batch.trg_y.cpu().numpy()[0, :]\n",
        "\n",
        "        # remove </s> (if it is there)\n",
        "        src = src[:-1] if src[-1] == src_eos_index else src\n",
        "        trg = trg[:-1] if trg[-1] == trg_eos_index else trg      \n",
        "      \n",
        "        result, _ = greedy_decode(\n",
        "          model, batch.src, batch.src_mask, batch.src_lengths,\n",
        "          max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n",
        "        print(\"Example #%d\" % (i+1))\n",
        "        print(\"Src : \", \" \".join(lookup_words(src, vocab=src_vocab)))\n",
        "        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n",
        "        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n",
        "        print()\n",
        "        \n",
        "        count += 1\n",
        "        if count == n:\n",
        "            break\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YYoXrnnt22d"
      },
      "source": [
        "def train_copy_task():\n",
        "    \"\"\"Train the simple copy task.\"\"\"\n",
        "    num_words = 11\n",
        "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=0)\n",
        "    model = make_model(num_words, num_words, emb_size=32, hidden_size=64)\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
        "    eval_data = list(data_gen(num_words=num_words, batch_size=1, num_batches=100))\n",
        " \n",
        "    dev_perplexities = []\n",
        "    \n",
        "    if USE_CUDA:\n",
        "        model.cuda()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        \n",
        "        print(\"Epoch %d\" % epoch)\n",
        "\n",
        "        # train\n",
        "        model.train()\n",
        "        data = data_gen(num_words=num_words, batch_size=32, num_batches=100)\n",
        "        run_epoch(data, model,\n",
        "                  SimpleLossCompute(model.generator, criterion, optim))\n",
        "\n",
        "        # evaluate\n",
        "        model.eval()\n",
        "        with torch.no_grad(): \n",
        "            perplexity = run_epoch(eval_data, model,\n",
        "                                   SimpleLossCompute(model.generator, criterion, None))\n",
        "            print(\"Evaluation perplexity: %f\" % perplexity)\n",
        "            dev_perplexities.append(perplexity)\n",
        "            print_examples(eval_data, model, n=2, max_len=9)\n",
        "        \n",
        "    return dev_perplexities"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6-6STAJt7LN",
        "outputId": "2ba0d76f-a18c-451b-f43e-71132160baa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# train the copy task\n",
        "dev_perplexities = train_copy_task()\n",
        "\n",
        "def plot_perplexity(perplexities):\n",
        "    \"\"\"plot perplexities\"\"\"\n",
        "    plt.title(\"Perplexity per Epoch\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Perplexity\")\n",
        "    plt.plot(perplexities)\n",
        "    \n",
        "plot_perplexity(dev_perplexities)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch Step: 50 Loss: 19.720032 Tokens per Sec: 9873.514669\n",
            "Epoch Step: 100 Loss: 17.850552 Tokens per Sec: 14248.919405\n",
            "Evaluation perplexity: 7.165516\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  5 8 7 5 8 7 5 8 7\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 8 8 8 8 8 8 8\n",
            "\n",
            "Epoch 1\n",
            "Epoch Step: 50 Loss: 15.429652 Tokens per Sec: 14571.904042\n",
            "Epoch Step: 100 Loss: 11.758204 Tokens per Sec: 14616.527781\n",
            "Evaluation perplexity: 3.761093\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 5 3 8 7 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 8 2 5 8 3 2\n",
            "\n",
            "Epoch 2\n",
            "Epoch Step: 50 Loss: 9.917423 Tokens per Sec: 14595.324458\n",
            "Epoch Step: 100 Loss: 8.949948 Tokens per Sec: 14179.187167\n",
            "Evaluation perplexity: 2.573576\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 5 7 8 10\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 8 5 2 6 8 2\n",
            "\n",
            "Epoch 3\n",
            "Epoch Step: 50 Loss: 7.275528 Tokens per Sec: 13305.699789\n",
            "Epoch Step: 100 Loss: 6.582399 Tokens per Sec: 14469.575883\n",
            "Evaluation perplexity: 2.072119\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 5 8 7 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 2 5 8 2 6\n",
            "\n",
            "Epoch 4\n",
            "Epoch Step: 50 Loss: 5.942049 Tokens per Sec: 14476.997965\n",
            "Epoch Step: 100 Loss: 4.906624 Tokens per Sec: 14840.961147\n",
            "Evaluation perplexity: 1.765160\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 5 10 8 7\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n",
            "Epoch 5\n",
            "Epoch Step: 50 Loss: 5.266298 Tokens per Sec: 14403.571442\n",
            "Epoch Step: 100 Loss: 4.140487 Tokens per Sec: 14651.659113\n",
            "Evaluation perplexity: 1.565404\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 10 5 7 8\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n",
            "Epoch 6\n",
            "Epoch Step: 50 Loss: 3.958579 Tokens per Sec: 14655.822354\n",
            "Epoch Step: 100 Loss: 3.681249 Tokens per Sec: 14423.146199\n",
            "Evaluation perplexity: 1.455613\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 5 8 7\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 8 6\n",
            "\n",
            "Epoch 7\n",
            "Epoch Step: 50 Loss: 2.987803 Tokens per Sec: 13366.205030\n",
            "Epoch Step: 100 Loss: 2.790762 Tokens per Sec: 14175.975658\n",
            "Evaluation perplexity: 1.366846\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 7 8 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n",
            "Epoch 8\n",
            "Epoch Step: 50 Loss: 2.148364 Tokens per Sec: 14517.261482\n",
            "Epoch Step: 100 Loss: 2.303624 Tokens per Sec: 14248.909320\n",
            "Evaluation perplexity: 1.275108\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 7 8 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n",
            "Epoch 9\n",
            "Epoch Step: 50 Loss: 2.088928 Tokens per Sec: 13449.023510\n",
            "Epoch Step: 100 Loss: 2.050288 Tokens per Sec: 13240.353477\n",
            "Evaluation perplexity: 1.195517\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 7 8 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGxVGL6St94_",
        "outputId": "31de6a4a-7422-4707-a6df-1a9325f9d9b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install git+git://github.com/pytorch/text spacy \n",
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/pytorch/text\n",
            "  Cloning git://github.com/pytorch/text to /tmp/pip-req-build-o4q2b8_e\n",
            "  Running command git clone -q git://github.com/pytorch/text /tmp/pip-req-build-o4q2b8_e\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (1.18.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (2020.6.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.9.0a0+97e6d1d) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.3.1)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Building wheel for torchtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchtext: filename=torchtext-0.9.0a0+97e6d1d-cp36-cp36m-linux_x86_64.whl size=6975865 sha256=01ace84e1106652604029dca07e7f5b09905276859f9e56b279f9d97cd008fa4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1qwuod19/wheels/39/42/ff/82f5ccbb0f30b25e14610376f5d0c67913fc05017dab59f8eb\n",
            "Successfully built torchtext\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed torchtext-0.9.0a0+97e6d1d\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.3.1)\n",
            "\u001b[38;5;2m Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     || 14.9MB 22.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.3.1)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907056 sha256=754e2f0629e0df6627f6e35c03e6f1088d7e34126ea0e32146ab2749061451e3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bfeapyaq/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvECCjHguQ_U",
        "outputId": "4f1c40a4-e5ff-49bf-8ab6-a13aa637a36b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# For data loading.\n",
        "from torchtext import data, datasets\n",
        "\n",
        "if True:\n",
        "    import spacy\n",
        "    spacy_de = spacy.load('de')\n",
        "    spacy_en = spacy.load('en')\n",
        "\n",
        "    def tokenize_de(text):\n",
        "        return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "    def tokenize_en(text):\n",
        "        return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "    UNK_TOKEN = \"<unk>\"\n",
        "    PAD_TOKEN = \"<pad>\"    \n",
        "    SOS_TOKEN = \"<s>\"\n",
        "    EOS_TOKEN = \"</s>\"\n",
        "    LOWER = True\n",
        "    \n",
        "    # we include lengths to provide to the RNNs\n",
        "    SRC = data.Field(tokenize=tokenize_de, \n",
        "                     batch_first=True, lower=LOWER, include_lengths=True,\n",
        "                     unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=None, eos_token=EOS_TOKEN)\n",
        "    TRG = data.Field(tokenize=tokenize_en, \n",
        "                     batch_first=True, lower=LOWER, include_lengths=True,\n",
        "                     unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=SOS_TOKEN, eos_token=EOS_TOKEN)\n",
        "\n",
        "    MAX_LEN = 25  # NOTE: we filter out a lot of sentences for speed\n",
        "    train_data, valid_data, test_data = datasets.IWSLT.splits(\n",
        "        exts=('.de', '.en'), fields=(SRC, TRG), \n",
        "        filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
        "            len(vars(x)['trg']) <= MAX_LEN)\n",
        "    MIN_FREQ = 5  # NOTE: we limit the vocabulary to frequent words for speed\n",
        "    SRC.build_vocab(train_data.src, min_freq=MIN_FREQ)\n",
        "    TRG.build_vocab(train_data.trg, min_freq=MIN_FREQ)\n",
        "    \n",
        "    PAD_INDEX = TRG.vocab.stoi[PAD_TOKEN]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading de-en.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "de-en.tgz: 100%|| 24.2M/24.2M [00:05<00:00, 4.35MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.en.xml\n",
            ".data/iwslt/de-en/train.tags.de-en.de\n",
            ".data/iwslt/de-en/train.tags.de-en.en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgoNC-NauXFU",
        "outputId": "642e259b-190d-406c-fdc5-88c063f53905",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def print_data_info(train_data, valid_data, test_data, src_field, trg_field):\n",
        "    \"\"\" This prints some useful stuff about our data sets. \"\"\"\n",
        "\n",
        "    print(\"Data set sizes (number of sentence pairs):\")\n",
        "    print('train', len(train_data))\n",
        "    print('valid', len(valid_data))\n",
        "    print('test', len(test_data), \"\\n\")\n",
        "\n",
        "    print(\"First training example:\")\n",
        "    print(\"src:\", \" \".join(vars(train_data[0])['src']))\n",
        "    print(\"trg:\", \" \".join(vars(train_data[0])['trg']), \"\\n\")\n",
        "\n",
        "    print(\"Most common words (src):\")\n",
        "    print(\"\\n\".join([\"%10s %10d\" % x for x in src_field.vocab.freqs.most_common(10)]), \"\\n\")\n",
        "    print(\"Most common words (trg):\")\n",
        "    print(\"\\n\".join([\"%10s %10d\" % x for x in trg_field.vocab.freqs.most_common(10)]), \"\\n\")\n",
        "\n",
        "    print(\"First 10 words (src):\")\n",
        "    print(\"\\n\".join(\n",
        "        '%02d %s' % (i, t) for i, t in enumerate(src_field.vocab.itos[:10])), \"\\n\")\n",
        "    print(\"First 10 words (trg):\")\n",
        "    print(\"\\n\".join(\n",
        "        '%02d %s' % (i, t) for i, t in enumerate(trg_field.vocab.itos[:10])), \"\\n\")\n",
        "\n",
        "    print(\"Number of German words (types):\", len(src_field.vocab))\n",
        "    print(\"Number of English words (types):\", len(trg_field.vocab), \"\\n\")\n",
        "    \n",
        "    \n",
        "print_data_info(train_data, valid_data, test_data, SRC, TRG)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data set sizes (number of sentence pairs):\n",
            "train 143115\n",
            "valid 690\n",
            "test 963 \n",
            "\n",
            "First training example:\n",
            "src: david gallo : das ist bill lange . ich bin dave gallo .\n",
            "trg: david gallo : this is bill lange . i 'm dave gallo . \n",
            "\n",
            "Most common words (src):\n",
            "         .     138329\n",
            "         ,     105944\n",
            "       und      41843\n",
            "       die      40808\n",
            "       das      33324\n",
            "       sie      33034\n",
            "       ich      31150\n",
            "       ist      31037\n",
            "        es      27449\n",
            "       wir      25817 \n",
            "\n",
            "Most common words (trg):\n",
            "         .     137259\n",
            "         ,      91615\n",
            "       the      73343\n",
            "       and      50276\n",
            "        to      42799\n",
            "         a      39572\n",
            "        of      39496\n",
            "         i      33521\n",
            "        it      32920\n",
            "      that      32640 \n",
            "\n",
            "First 10 words (src):\n",
            "00 <unk>\n",
            "01 <pad>\n",
            "02 </s>\n",
            "03 .\n",
            "04 ,\n",
            "05 und\n",
            "06 die\n",
            "07 das\n",
            "08 sie\n",
            "09 ich \n",
            "\n",
            "First 10 words (trg):\n",
            "00 <unk>\n",
            "01 <pad>\n",
            "02 <s>\n",
            "03 </s>\n",
            "04 .\n",
            "05 ,\n",
            "06 the\n",
            "07 and\n",
            "08 to\n",
            "09 a \n",
            "\n",
            "Number of German words (types): 15765\n",
            "Number of English words (types): 13002 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tpjBcpRuZtU",
        "outputId": "6bae0848-4c42-40b9-fc14-d67e6e551af0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "train_iter = data.BucketIterator(train_data, batch_size=64, train=True, \n",
        "                                 sort_within_batch=True, \n",
        "                                 sort_key=lambda x: (len(x.src), len(x.trg)), repeat=False,\n",
        "                                 device=DEVICE)\n",
        "valid_iter = data.Iterator(valid_data, batch_size=1, train=False, sort=False, repeat=False, \n",
        "                           device=DEVICE)\n",
        "\n",
        "\n",
        "def rebatch(pad_idx, batch):\n",
        "    \"\"\"Wrap torchtext batch into our own Batch class for pre-processing\"\"\"\n",
        "    return Batch(batch.src, batch.trg, pad_idx)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: Iterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEDhqD8FudHs"
      },
      "source": [
        "def train(model, num_epochs=10, lr=0.0003, print_every=100):\n",
        "    \"\"\"Train a model on IWSLT\"\"\"\n",
        "    \n",
        "    if USE_CUDA:\n",
        "        model.cuda()\n",
        "\n",
        "    # optionally add label smoothing; see the Annotated Transformer\n",
        "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    dev_perplexities = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      \n",
        "        print(\"Epoch\", epoch)\n",
        "        model.train()\n",
        "        train_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in train_iter), \n",
        "                                     model,\n",
        "                                     SimpleLossCompute(model.generator, criterion, optim),\n",
        "                                     print_every=print_every)\n",
        "        \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            print_examples((rebatch(PAD_INDEX, x) for x in valid_iter), \n",
        "                           model, n=3, src_vocab=SRC.vocab, trg_vocab=TRG.vocab)        \n",
        "\n",
        "            dev_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in valid_iter), \n",
        "                                       model, \n",
        "                                       SimpleLossCompute(model.generator, criterion, None))\n",
        "            print(\"Validation perplexity: %f\" % dev_perplexity)\n",
        "            dev_perplexities.append(dev_perplexity)\n",
        "        \n",
        "    return dev_perplexities\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mF-9PItukW8",
        "outputId": "be628639-14b4-4e58-a832-6948599214dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "model = make_model(len(SRC.vocab), len(TRG.vocab),\n",
        "                   emb_size=256, hidden_size=256,\n",
        "                   num_layers=1, dropout=0.2)\n",
        "dev_perplexities = train(model, print_every=100)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch Step: 100 Loss: 27.735802 Tokens per Sec: 22226.225839\n",
            "Epoch Step: 200 Loss: 75.748734 Tokens per Sec: 23570.555882\n",
            "Epoch Step: 300 Loss: 126.858376 Tokens per Sec: 23739.821574\n",
            "Epoch Step: 400 Loss: 31.422281 Tokens per Sec: 23759.081093\n",
            "Epoch Step: 500 Loss: 87.299309 Tokens per Sec: 22795.829811\n",
            "Epoch Step: 600 Loss: 49.668217 Tokens per Sec: 23920.615100\n",
            "Epoch Step: 700 Loss: 67.411842 Tokens per Sec: 24057.984604\n",
            "Epoch Step: 800 Loss: 71.796181 Tokens per Sec: 24138.320282\n",
            "Epoch Step: 900 Loss: 71.188629 Tokens per Sec: 24002.904863\n",
            "Epoch Step: 1000 Loss: 47.664963 Tokens per Sec: 23989.509293\n",
            "Epoch Step: 1100 Loss: 110.241669 Tokens per Sec: 23078.690178\n",
            "Epoch Step: 1200 Loss: 101.958923 Tokens per Sec: 23953.804317\n",
            "Epoch Step: 1300 Loss: 79.825508 Tokens per Sec: 23036.725541\n",
            "Epoch Step: 1400 Loss: 43.861324 Tokens per Sec: 23693.144538\n",
            "Epoch Step: 1500 Loss: 40.748844 Tokens per Sec: 24205.402379\n",
            "Epoch Step: 1600 Loss: 25.819824 Tokens per Sec: 24458.933948\n",
            "Epoch Step: 1700 Loss: 60.767414 Tokens per Sec: 23727.923791\n",
            "Epoch Step: 1800 Loss: 82.372322 Tokens per Sec: 23699.604686\n",
            "Epoch Step: 1900 Loss: 65.475975 Tokens per Sec: 22863.560620\n",
            "Epoch Step: 2000 Loss: 51.591583 Tokens per Sec: 22920.462730\n",
            "Epoch Step: 2100 Loss: 52.060009 Tokens per Sec: 24268.679565\n",
            "Epoch Step: 2200 Loss: 51.783413 Tokens per Sec: 24011.393589\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was years old , i was a <unk> of the <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hrte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father is to be <unk> , the <unk> of the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glcklich aus , was damals ziemlich ungewhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he had very much , what happened was , there was a <unk> .\n",
            "\n",
            "Validation perplexity: 31.683697\n",
            "Epoch 1\n",
            "Epoch Step: 100 Loss: 64.940948 Tokens per Sec: 22510.065656\n",
            "Epoch Step: 200 Loss: 74.401733 Tokens per Sec: 23169.673404\n",
            "Epoch Step: 300 Loss: 32.740707 Tokens per Sec: 24277.441542\n",
            "Epoch Step: 400 Loss: 50.145931 Tokens per Sec: 24325.040822\n",
            "Epoch Step: 500 Loss: 83.468231 Tokens per Sec: 23709.299451\n",
            "Epoch Step: 600 Loss: 54.800152 Tokens per Sec: 24172.565285\n",
            "Epoch Step: 700 Loss: 61.110703 Tokens per Sec: 24497.241283\n",
            "Epoch Step: 800 Loss: 40.610298 Tokens per Sec: 22869.967808\n",
            "Epoch Step: 900 Loss: 22.858322 Tokens per Sec: 23367.754232\n",
            "Epoch Step: 1000 Loss: 12.030720 Tokens per Sec: 22259.682729\n",
            "Epoch Step: 1100 Loss: 53.940186 Tokens per Sec: 22717.778632\n",
            "Epoch Step: 1200 Loss: 54.736862 Tokens per Sec: 24022.205509\n",
            "Epoch Step: 1300 Loss: 82.624390 Tokens per Sec: 22626.610836\n",
            "Epoch Step: 1400 Loss: 87.326904 Tokens per Sec: 23564.844098\n",
            "Epoch Step: 1500 Loss: 27.987137 Tokens per Sec: 22988.180460\n",
            "Epoch Step: 1600 Loss: 19.397421 Tokens per Sec: 23631.308972\n",
            "Epoch Step: 1700 Loss: 47.411633 Tokens per Sec: 23761.332815\n",
            "Epoch Step: 1800 Loss: 61.280205 Tokens per Sec: 22877.536226\n",
            "Epoch Step: 1900 Loss: 18.653461 Tokens per Sec: 23933.817956\n",
            "Epoch Step: 2000 Loss: 35.075390 Tokens per Sec: 24250.243283\n",
            "Epoch Step: 2100 Loss: 25.317360 Tokens per Sec: 23801.672345\n",
            "Epoch Step: 2200 Loss: 65.685310 Tokens per Sec: 23212.777541\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> of <unk> <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hrte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on his little , the <unk> of the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glcklich aus , was damals ziemlich ungewhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , what was pretty much , it was the <unk> .\n",
            "\n",
            "Validation perplexity: 19.766255\n",
            "Epoch 2\n",
            "Epoch Step: 100 Loss: 7.685939 Tokens per Sec: 22781.476142\n",
            "Epoch Step: 200 Loss: 70.917625 Tokens per Sec: 22979.105529\n",
            "Epoch Step: 300 Loss: 47.367672 Tokens per Sec: 23850.447829\n",
            "Epoch Step: 400 Loss: 42.108604 Tokens per Sec: 23194.915867\n",
            "Epoch Step: 500 Loss: 34.911152 Tokens per Sec: 24043.063063\n",
            "Epoch Step: 600 Loss: 37.080803 Tokens per Sec: 22696.826878\n",
            "Epoch Step: 700 Loss: 58.668892 Tokens per Sec: 23508.018061\n",
            "Epoch Step: 800 Loss: 32.177307 Tokens per Sec: 24455.025679\n",
            "Epoch Step: 900 Loss: 36.641117 Tokens per Sec: 24524.445596\n",
            "Epoch Step: 1000 Loss: 18.127424 Tokens per Sec: 24166.507883\n",
            "Epoch Step: 1100 Loss: 14.307224 Tokens per Sec: 24035.635638\n",
            "Epoch Step: 1200 Loss: 65.027702 Tokens per Sec: 23954.745831\n",
            "Epoch Step: 1300 Loss: 22.149071 Tokens per Sec: 24035.910833\n",
            "Epoch Step: 1400 Loss: 43.126240 Tokens per Sec: 23424.534349\n",
            "Epoch Step: 1500 Loss: 11.614280 Tokens per Sec: 24611.751314\n",
            "Epoch Step: 1600 Loss: 68.267273 Tokens per Sec: 24162.797421\n",
            "Epoch Step: 1700 Loss: 35.980095 Tokens per Sec: 24374.950788\n",
            "Epoch Step: 1800 Loss: 27.513096 Tokens per Sec: 23753.182481\n",
            "Epoch Step: 1900 Loss: 48.457615 Tokens per Sec: 24404.094630\n",
            "Epoch Step: 2000 Loss: 2.667787 Tokens per Sec: 23804.676844\n",
            "Epoch Step: 2100 Loss: 17.486322 Tokens per Sec: 23816.500909\n",
            "Epoch Step: 2200 Loss: 63.986526 Tokens per Sec: 24061.036992\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> from the <unk> <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hrte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on his little , the <unk> <unk> the <unk> of the same .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glcklich aus , was damals ziemlich ungewhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty much , because the news was <unk> .\n",
            "\n",
            "Validation perplexity: 15.921995\n",
            "Epoch 3\n",
            "Epoch Step: 100 Loss: 22.069393 Tokens per Sec: 22768.018466\n",
            "Epoch Step: 200 Loss: 51.175957 Tokens per Sec: 23826.014161\n",
            "Epoch Step: 300 Loss: 21.030182 Tokens per Sec: 24192.534243\n",
            "Epoch Step: 400 Loss: 70.878586 Tokens per Sec: 23955.301440\n",
            "Epoch Step: 500 Loss: 37.085190 Tokens per Sec: 24293.031049\n",
            "Epoch Step: 600 Loss: 46.561260 Tokens per Sec: 23236.497611\n",
            "Epoch Step: 700 Loss: 8.713013 Tokens per Sec: 24230.067523\n",
            "Epoch Step: 800 Loss: 28.564026 Tokens per Sec: 23627.993436\n",
            "Epoch Step: 900 Loss: 40.140709 Tokens per Sec: 23176.722489\n",
            "Epoch Step: 1000 Loss: 36.092377 Tokens per Sec: 24125.098634\n",
            "Epoch Step: 1100 Loss: 50.738625 Tokens per Sec: 23841.096656\n",
            "Epoch Step: 1200 Loss: 38.199364 Tokens per Sec: 23450.888417\n",
            "Epoch Step: 1300 Loss: 44.357113 Tokens per Sec: 24357.727884\n",
            "Epoch Step: 1400 Loss: 33.664471 Tokens per Sec: 24318.511551\n",
            "Epoch Step: 1500 Loss: 16.556593 Tokens per Sec: 24047.126207\n",
            "Epoch Step: 1600 Loss: 29.709679 Tokens per Sec: 24590.380636\n",
            "Epoch Step: 1700 Loss: 44.718605 Tokens per Sec: 23597.242672\n",
            "Epoch Step: 1800 Loss: 35.726223 Tokens per Sec: 22840.230888\n",
            "Epoch Step: 1900 Loss: 29.038710 Tokens per Sec: 23928.811911\n",
            "Epoch Step: 2000 Loss: 21.704514 Tokens per Sec: 24243.979737\n",
            "Epoch Step: 2100 Loss: 19.206165 Tokens per Sec: 23691.027410\n",
            "Epoch Step: 2200 Loss: 37.849991 Tokens per Sec: 23664.603624\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> of <unk> <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hrte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on his little , tiny radio <unk> the <unk> of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glcklich aus , was damals ziemlich ungewhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was a lot of unusual , because it was the news of the <unk> .\n",
            "\n",
            "Validation perplexity: 13.884223\n",
            "Epoch 4\n",
            "Epoch Step: 100 Loss: 31.338758 Tokens per Sec: 22432.987049\n",
            "Epoch Step: 200 Loss: 27.870932 Tokens per Sec: 23696.112511\n",
            "Epoch Step: 300 Loss: 18.891268 Tokens per Sec: 23804.784047\n",
            "Epoch Step: 400 Loss: 20.289211 Tokens per Sec: 24045.735123\n",
            "Epoch Step: 500 Loss: 15.785973 Tokens per Sec: 23385.787454\n",
            "Epoch Step: 600 Loss: 20.555986 Tokens per Sec: 23213.119838\n",
            "Epoch Step: 700 Loss: 20.503946 Tokens per Sec: 22554.139856\n",
            "Epoch Step: 800 Loss: 56.832645 Tokens per Sec: 24500.671464\n",
            "Epoch Step: 900 Loss: 59.503838 Tokens per Sec: 23323.454036\n",
            "Epoch Step: 1000 Loss: 39.476334 Tokens per Sec: 24251.071548\n",
            "Epoch Step: 1100 Loss: 3.751539 Tokens per Sec: 22603.787057\n",
            "Epoch Step: 1200 Loss: 34.237633 Tokens per Sec: 24291.064632\n",
            "Epoch Step: 1300 Loss: 23.498743 Tokens per Sec: 23908.841718\n",
            "Epoch Step: 1400 Loss: 24.633263 Tokens per Sec: 24215.649040\n",
            "Epoch Step: 1500 Loss: 22.656174 Tokens per Sec: 23820.893271\n",
            "Epoch Step: 1600 Loss: 30.625721 Tokens per Sec: 22472.318957\n",
            "Epoch Step: 1700 Loss: 19.088833 Tokens per Sec: 24305.075568\n",
            "Epoch Step: 1800 Loss: 48.483349 Tokens per Sec: 24035.447189\n",
            "Epoch Step: 1900 Loss: 32.027294 Tokens per Sec: 24055.643961\n",
            "Epoch Step: 2000 Loss: 32.254108 Tokens per Sec: 24181.728359\n",
            "Epoch Step: 2100 Loss: 67.841003 Tokens per Sec: 22509.519653\n",
            "Epoch Step: 2200 Loss: 32.972195 Tokens per Sec: 23702.738653\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> of <unk> <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hrte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on his little , tiny radio the <unk> of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glcklich aus , was damals ziemlich ungewhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was quite unusual , because the news was <unk> the <unk> .\n",
            "\n",
            "Validation perplexity: 12.528261\n",
            "Epoch 5\n",
            "Epoch Step: 100 Loss: 21.496735 Tokens per Sec: 22561.573216\n",
            "Epoch Step: 200 Loss: 55.184776 Tokens per Sec: 23301.666754\n",
            "Epoch Step: 300 Loss: 23.849463 Tokens per Sec: 23935.670891\n",
            "Epoch Step: 400 Loss: 14.681965 Tokens per Sec: 23275.391703\n",
            "Epoch Step: 500 Loss: 23.410160 Tokens per Sec: 23409.926703\n",
            "Epoch Step: 600 Loss: 11.041868 Tokens per Sec: 24096.654975\n",
            "Epoch Step: 700 Loss: 9.330876 Tokens per Sec: 23708.383681\n",
            "Epoch Step: 800 Loss: 53.070919 Tokens per Sec: 24234.380260\n",
            "Epoch Step: 900 Loss: 47.359879 Tokens per Sec: 23115.005576\n",
            "Epoch Step: 1000 Loss: 41.779823 Tokens per Sec: 23761.930447\n",
            "Epoch Step: 1100 Loss: 21.054979 Tokens per Sec: 24286.706144\n",
            "Epoch Step: 1200 Loss: 53.250458 Tokens per Sec: 23167.598610\n",
            "Epoch Step: 1300 Loss: 21.413965 Tokens per Sec: 24103.048629\n",
            "Epoch Step: 1400 Loss: 25.789984 Tokens per Sec: 24428.154226\n",
            "Epoch Step: 1500 Loss: 38.974396 Tokens per Sec: 24523.280140\n",
            "Epoch Step: 1600 Loss: 15.688786 Tokens per Sec: 24378.708803\n",
            "Epoch Step: 1700 Loss: 46.152702 Tokens per Sec: 24201.487679\n",
            "Epoch Step: 1800 Loss: 44.798306 Tokens per Sec: 23812.007708\n",
            "Epoch Step: 1900 Loss: 25.980158 Tokens per Sec: 23319.299808\n",
            "Epoch Step: 2000 Loss: 41.596165 Tokens per Sec: 23965.314180\n",
            "Epoch Step: 2100 Loss: 57.078289 Tokens per Sec: 23033.113401\n",
            "Epoch Step: 2200 Loss: 57.555111 Tokens per Sec: 24090.093285\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i became a <unk> of the <unk> of joy .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hrte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father stopped on his little , gray radio the <unk> of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glcklich aus , was damals ziemlich ungewhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was quite unusual , because the news was going to be the news .\n",
            "\n",
            "Validation perplexity: 12.099543\n",
            "Epoch 6\n",
            "Epoch Step: 100 Loss: 45.536137 Tokens per Sec: 22453.850213\n",
            "Epoch Step: 200 Loss: 49.325615 Tokens per Sec: 23603.467304\n",
            "Epoch Step: 300 Loss: 52.108849 Tokens per Sec: 23249.841582\n",
            "Epoch Step: 400 Loss: 27.723520 Tokens per Sec: 23510.817332\n",
            "Epoch Step: 500 Loss: 19.130407 Tokens per Sec: 24136.453001\n",
            "Epoch Step: 600 Loss: 55.010006 Tokens per Sec: 24015.310763\n",
            "Epoch Step: 700 Loss: 41.343403 Tokens per Sec: 22967.073661\n",
            "Epoch Step: 800 Loss: 42.858902 Tokens per Sec: 23662.652308\n",
            "Epoch Step: 900 Loss: 34.604076 Tokens per Sec: 23543.315769\n",
            "Epoch Step: 1000 Loss: 17.910423 Tokens per Sec: 22562.284569\n",
            "Epoch Step: 1100 Loss: 37.356030 Tokens per Sec: 23170.853434\n",
            "Epoch Step: 1200 Loss: 34.270885 Tokens per Sec: 23766.897274\n",
            "Epoch Step: 1300 Loss: 51.392681 Tokens per Sec: 24011.198434\n",
            "Epoch Step: 1400 Loss: 16.920918 Tokens per Sec: 23813.413650\n",
            "Epoch Step: 1500 Loss: 27.719883 Tokens per Sec: 24323.527127\n",
            "Epoch Step: 1600 Loss: 52.797348 Tokens per Sec: 23824.047267\n",
            "Epoch Step: 1700 Loss: 38.980148 Tokens per Sec: 24162.026565\n",
            "Epoch Step: 1800 Loss: 5.964743 Tokens per Sec: 23090.559472\n",
            "Epoch Step: 1900 Loss: 26.519308 Tokens per Sec: 23931.588546\n",
            "Epoch Step: 2000 Loss: 16.979988 Tokens per Sec: 24176.589850\n",
            "Epoch Step: 2100 Loss: 23.767750 Tokens per Sec: 24078.123876\n",
            "Epoch Step: 2200 Loss: 16.188995 Tokens per Sec: 23430.634268\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was published by a morning of <unk> <unk> delight .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hrte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father stopped on his small , gray radio 's the bbc of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glcklich aus , was damals ziemlich ungewhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty much , because it was the news of the news .\n",
            "\n",
            "Validation perplexity: 11.827416\n",
            "Epoch 7\n",
            "Epoch Step: 100 Loss: 24.750057 Tokens per Sec: 22394.475034\n",
            "Epoch Step: 200 Loss: 20.425215 Tokens per Sec: 23874.851882\n",
            "Epoch Step: 300 Loss: 29.794804 Tokens per Sec: 24321.297216\n",
            "Epoch Step: 400 Loss: 44.076927 Tokens per Sec: 24527.566927\n",
            "Epoch Step: 500 Loss: 1.980540 Tokens per Sec: 24587.776482\n",
            "Epoch Step: 600 Loss: 50.482960 Tokens per Sec: 24289.186005\n",
            "Epoch Step: 700 Loss: 54.190056 Tokens per Sec: 24169.191934\n",
            "Epoch Step: 800 Loss: 13.667422 Tokens per Sec: 23999.007596\n",
            "Epoch Step: 900 Loss: 12.782900 Tokens per Sec: 23863.522992\n",
            "Epoch Step: 1000 Loss: 26.008476 Tokens per Sec: 22529.487926\n",
            "Epoch Step: 1100 Loss: 29.064333 Tokens per Sec: 23689.591967\n",
            "Epoch Step: 1200 Loss: 26.014963 Tokens per Sec: 23296.088132\n",
            "Epoch Step: 1300 Loss: 45.545490 Tokens per Sec: 24320.032159\n",
            "Epoch Step: 1400 Loss: 54.410229 Tokens per Sec: 22852.409162\n",
            "Epoch Step: 1500 Loss: 43.506702 Tokens per Sec: 23834.636427\n",
            "Epoch Step: 1600 Loss: 53.345085 Tokens per Sec: 23376.471890\n",
            "Epoch Step: 1700 Loss: 20.704517 Tokens per Sec: 24428.552812\n",
            "Epoch Step: 1800 Loss: 24.711596 Tokens per Sec: 23593.422470\n",
            "Epoch Step: 1900 Loss: 56.350914 Tokens per Sec: 23906.526032\n",
            "Epoch Step: 2000 Loss: 34.447739 Tokens per Sec: 23578.739878\n",
            "Epoch Step: 2100 Loss: 58.834385 Tokens per Sec: 24546.390927\n",
            "Epoch Step: 2200 Loss: 16.292221 Tokens per Sec: 23408.215313\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> of <unk> to <unk> <unk> by joy .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hrte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father listened to his little , tiny radio <unk> the <unk> of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glcklich aus , was damals ziemlich ungewhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was quite a lot of <unk> , because it was the news of the news .\n",
            "\n",
            "Validation perplexity: 11.866460\n",
            "Epoch 8\n",
            "Epoch Step: 100 Loss: 46.248726 Tokens per Sec: 23064.075989\n",
            "Epoch Step: 200 Loss: 10.687084 Tokens per Sec: 23204.777113\n",
            "Epoch Step: 300 Loss: 34.016125 Tokens per Sec: 23565.135156\n",
            "Epoch Step: 400 Loss: 15.128448 Tokens per Sec: 22775.229024\n",
            "Epoch Step: 500 Loss: 20.303799 Tokens per Sec: 24009.373367\n",
            "Epoch Step: 600 Loss: 8.177230 Tokens per Sec: 23332.838524\n",
            "Epoch Step: 700 Loss: 54.031288 Tokens per Sec: 24348.234674\n",
            "Epoch Step: 800 Loss: 17.476307 Tokens per Sec: 23989.602316\n",
            "Epoch Step: 900 Loss: 32.861557 Tokens per Sec: 23585.610024\n",
            "Epoch Step: 1000 Loss: 31.964073 Tokens per Sec: 23397.983075\n",
            "Epoch Step: 1100 Loss: 43.571381 Tokens per Sec: 24317.738074\n",
            "Epoch Step: 1200 Loss: 35.181595 Tokens per Sec: 24613.382243\n",
            "Epoch Step: 1300 Loss: 14.478071 Tokens per Sec: 24211.050290\n",
            "Epoch Step: 1400 Loss: 35.999683 Tokens per Sec: 23949.009157\n",
            "Epoch Step: 1500 Loss: 50.250885 Tokens per Sec: 24623.095202\n",
            "Epoch Step: 1600 Loss: 26.054665 Tokens per Sec: 23997.123534\n",
            "Epoch Step: 1700 Loss: 11.797624 Tokens per Sec: 23875.178044\n",
            "Epoch Step: 1800 Loss: 19.601851 Tokens per Sec: 24065.580440\n",
            "Epoch Step: 1900 Loss: 46.943260 Tokens per Sec: 23370.548494\n",
            "Epoch Step: 2000 Loss: 46.756859 Tokens per Sec: 22945.517574\n",
            "Epoch Step: 2100 Loss: 19.885012 Tokens per Sec: 23434.308000\n",
            "Epoch Step: 2200 Loss: 20.361456 Tokens per Sec: 24728.271758\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was one of the <unk> of the <unk> <unk> delight .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hrte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father listened to his little , gray radio waves the <unk> of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glcklich aus , was damals ziemlich ungewhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  and he looked very happy , which was a pretty unusual thing , because the news was going to be the <unk> .\n",
            "\n",
            "Validation perplexity: 11.658626\n",
            "Epoch 9\n",
            "Epoch Step: 100 Loss: 4.386352 Tokens per Sec: 21530.529875\n",
            "Epoch Step: 200 Loss: 46.028252 Tokens per Sec: 24332.065994\n",
            "Epoch Step: 300 Loss: 33.401482 Tokens per Sec: 23764.191588\n",
            "Epoch Step: 400 Loss: 35.042519 Tokens per Sec: 23810.771413\n",
            "Epoch Step: 500 Loss: 21.835167 Tokens per Sec: 23637.657036\n",
            "Epoch Step: 600 Loss: 19.951351 Tokens per Sec: 23658.598333\n",
            "Epoch Step: 700 Loss: 17.942211 Tokens per Sec: 23447.626232\n",
            "Epoch Step: 800 Loss: 22.436520 Tokens per Sec: 24410.103221\n",
            "Epoch Step: 900 Loss: 14.285416 Tokens per Sec: 24232.405074\n",
            "Epoch Step: 1000 Loss: 36.798370 Tokens per Sec: 24435.834414\n",
            "Epoch Step: 1100 Loss: 30.899240 Tokens per Sec: 23786.536716\n",
            "Epoch Step: 1200 Loss: 12.989038 Tokens per Sec: 24421.230986\n",
            "Epoch Step: 1300 Loss: 11.448281 Tokens per Sec: 23754.428314\n",
            "Epoch Step: 1400 Loss: 15.393875 Tokens per Sec: 24184.639025\n",
            "Epoch Step: 1500 Loss: 5.972243 Tokens per Sec: 24284.299770\n",
            "Epoch Step: 1600 Loss: 12.359884 Tokens per Sec: 24416.433142\n",
            "Epoch Step: 1700 Loss: 41.536205 Tokens per Sec: 24433.660267\n",
            "Epoch Step: 1800 Loss: 11.846695 Tokens per Sec: 22245.201968\n",
            "Epoch Step: 1900 Loss: 36.459278 Tokens per Sec: 22958.682318\n",
            "Epoch Step: 2000 Loss: 30.697346 Tokens per Sec: 23032.649726\n",
            "Epoch Step: 2100 Loss: 47.027653 Tokens per Sec: 23982.460798\n",
            "Epoch Step: 2200 Loss: 40.908188 Tokens per Sec: 23819.205672\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was one of the morning by the <unk> <unk> <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hrte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my dad listened to his own , gray radio 's the bbc of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glcklich aus , was damals ziemlich ungewhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  and he looked very happy , which was actually quite unusual , because the news was going to be the <unk> .\n",
            "\n",
            "Validation perplexity: 11.754340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_OnRwXiumt7",
        "outputId": "60256aff-a739-47e0-c43b-88d6f71d8c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plot_perplexity(dev_perplexities)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrMu3XssuqYj",
        "outputId": "18785a4c-0233-4730-83ec-2af4d13e5416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import sacrebleu"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-a42160e8fb94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msacrebleu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sacrebleu'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9c87By3usx7"
      },
      "source": [
        "\n",
        "# this should result in a perfect BLEU of 100%\n",
        "hypotheses = [\"this is a test\"]\n",
        "references = [\"this is a test\"]\n",
        "bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n",
        "print(bleu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5LUlIHpuvS1"
      },
      "source": [
        "# here the BLEU score will be lower, because some n-grams won't match\n",
        "hypotheses = [\"this is a test\"]\n",
        "references = [\"this is a fest\"]\n",
        "bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n",
        "print(bleu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8K29vJnuyBb"
      },
      "source": [
        "\n",
        "len(valid_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3fnIZQFu0Qb"
      },
      "source": [
        "\n",
        "references = [\" \".join(example.trg) for example in valid_data]\n",
        "print(len(references))\n",
        "print(references[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbl-BnoOu2i0"
      },
      "source": [
        "\n",
        "references[-2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLo0rDCyu4UD"
      },
      "source": [
        "\n",
        "hypotheses = []\n",
        "alphas = []  # save the last attention scores\n",
        "for batch in valid_iter:\n",
        "  batch = rebatch(PAD_INDEX, batch)\n",
        "  pred, attention = greedy_decode(\n",
        "    model, batch.src, batch.src_mask, batch.src_lengths, max_len=25,\n",
        "    sos_index=TRG.vocab.stoi[SOS_TOKEN],\n",
        "    eos_index=TRG.vocab.stoi[EOS_TOKEN])\n",
        "  hypotheses.append(pred)\n",
        "  alphas.append(attention)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoaNsGCpu7E7"
      },
      "source": [
        "# we will still need to convert the indices to actual words!\n",
        "hypotheses[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhqNooaGu9zL"
      },
      "source": [
        "hypotheses = [lookup_words(x, TRG.vocab) for x in hypotheses]\n",
        "hypotheses[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ivquOCZvA1b"
      },
      "source": [
        "# finally, the SacreBLEU raw scorer requires string input, so we convert the lists to strings\n",
        "hypotheses = [\" \".join(x) for x in hypotheses]\n",
        "print(len(hypotheses))\n",
        "print(hypotheses[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAJG_HimvD5r"
      },
      "source": [
        "# now we can compute the BLEU score!\n",
        "bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n",
        "print(bleu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsKeTlUuvGPb"
      },
      "source": [
        "def plot_heatmap(src, trg, scores):\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    heatmap = ax.pcolor(scores, cmap='viridis')\n",
        "\n",
        "    ax.set_xticklabels(trg, minor=False, rotation='vertical')\n",
        "    ax.set_yticklabels(src, minor=False)\n",
        "\n",
        "    # put the major ticks at the middle of each cell\n",
        "    # and the x-ticks on top\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.set_xticks(np.arange(scores.shape[1]) + 0.5, minor=False)\n",
        "    ax.set_yticks(np.arange(scores.shape[0]) + 0.5, minor=False)\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "    plt.colorbar(heatmap)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1NzcqsTvMt7"
      },
      "source": [
        "# This plots a chosen sentence, for which we saved the attention scores above.\n",
        "idx = 5\n",
        "src = valid_data[idx].src + [\"</s>\"]\n",
        "trg = valid_data[idx].trg + [\"</s>\"]\n",
        "pred = hypotheses[idx].split() + [\"</s>\"]\n",
        "pred_att = alphas[idx][0].T[:, :len(pred)]\n",
        "print(\"src\", src)\n",
        "print(\"ref\", trg)\n",
        "print(\"pred\", pred)\n",
        "plot_heatmap(src, pred, pred_att)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
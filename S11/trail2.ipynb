{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S11trail.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNWNOL48yzrPq2bsmm78nmp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EVA4-RS-Group/Phase2/blob/master/S11/trail2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-94vfBJKBtG",
        "outputId": "dc20a213-0aa4-4081-e5b3-53594ae6d718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, copy, time\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "# we will use CUDA if it is available\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE=torch.device('cuda:0') # or set to 'cpu'\n",
        "print(\"CUDA:\", USE_CUDA)\n",
        "print(DEVICE)\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA: True\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXczNEkZsukw"
      },
      "source": [
        "\n",
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A standard Encoder-Decoder architecture. Base for this and many \n",
        "    other models.\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.trg_embed = trg_embed\n",
        "        self.generator = generator\n",
        "        \n",
        "    def forward(self, src, trg, src_mask, trg_mask, src_lengths, trg_lengths):\n",
        "        \"\"\"Take in and process masked src and target sequences.\"\"\"\n",
        "        encoder_hidden, encoder_final = self.encode(src, src_mask, src_lengths)\n",
        "        return self.decode(encoder_hidden, encoder_final, src_mask, trg, trg_mask)\n",
        "    \n",
        "    def encode(self, src, src_mask, src_lengths):\n",
        "        return self.encoder(self.src_embed(src), src_mask, src_lengths)\n",
        "    \n",
        "    def decode(self, encoder_hidden, encoder_final, src_mask, trg, trg_mask,\n",
        "               decoder_hidden=None):\n",
        "        return self.decoder(self.trg_embed(trg), encoder_hidden, encoder_final,\n",
        "                            src_mask, trg_mask, hidden=decoder_hidden)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shFnR2hssx_3"
      },
      "source": [
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
        "    def __init__(self, hidden_size, vocab_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.proj(x), dim=-1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQhMtvdNs0pf"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"Encodes a sequence of word embeddings\"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, \n",
        "                          batch_first=True, bidirectional=True, dropout=dropout)\n",
        "        \n",
        "    def forward(self, x, mask, lengths):\n",
        "        \"\"\"\n",
        "        Applies a bidirectional GRU to sequence of embeddings x.\n",
        "        The input mini-batch x needs to be sorted by length.\n",
        "        x should have dimensions [batch, time, dim].\n",
        "        \"\"\"\n",
        "        packed = pack_padded_sequence(x, lengths, batch_first=True)\n",
        "        output, final = self.rnn(packed)\n",
        "        output, _ = pad_packed_sequence(output, batch_first=True)\n",
        "\n",
        "        # we need to manually concatenate the final states for both directions\n",
        "        fwd_final = final[0:final.size(0):2]\n",
        "        bwd_final = final[1:final.size(0):2]\n",
        "        final = torch.cat([fwd_final, bwd_final], dim=2)  # [num_layers, batch, 2*dim]\n",
        "\n",
        "        return output, final"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KDP5Llqs36X"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"A conditional RNN decoder with attention.\"\"\"\n",
        "    \n",
        "    def __init__(self, emb_size, hidden_size, attention, num_layers=1, dropout=0.5,\n",
        "                 bridge=True):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.attention = attention\n",
        "        self.dropout = dropout\n",
        "                 \n",
        "        self.rnn = nn.GRU(emb_size + 2*hidden_size, hidden_size, num_layers,\n",
        "                          batch_first=True, dropout=dropout)\n",
        "                 \n",
        "        # to initialize from the final encoder state\n",
        "        self.bridge = nn.Linear(2*hidden_size, hidden_size, bias=True) if bridge else None\n",
        "\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "        self.pre_output_layer = nn.Linear(hidden_size + 2*hidden_size + emb_size,\n",
        "                                          hidden_size, bias=False)\n",
        "        \n",
        "    def forward_step(self, prev_embed, encoder_hidden, src_mask, proj_key, hidden):\n",
        "        \"\"\"Perform a single decoder step (1 word)\"\"\"\n",
        "\n",
        "        # compute context vector using attention mechanism\n",
        "        query = hidden[-1].unsqueeze(1)  # [#layers, B, D] -> [B, 1, D]\n",
        "        context, attn_probs = self.attention(\n",
        "            query=query, proj_key=proj_key,\n",
        "            value=encoder_hidden, mask=src_mask)\n",
        "\n",
        "        # update rnn hidden state\n",
        "        rnn_input = torch.cat([prev_embed, context], dim=2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "         \n",
        "        pre_output = torch.cat([prev_embed, output, context], dim=2)\n",
        "        pre_output = self.dropout_layer(pre_output)\n",
        "        pre_output = self.pre_output_layer(pre_output)\n",
        "\n",
        "        return output, hidden, pre_output\n",
        "    \n",
        "    def forward(self, trg_embed, encoder_hidden, encoder_final, \n",
        "                src_mask, trg_mask, hidden=None, max_len=None):\n",
        "        \"\"\"Unroll the decoder one step at a time.\"\"\"\n",
        "                                         \n",
        "        # the maximum number of steps to unroll the RNN\n",
        "        if max_len is None:\n",
        "            max_len = trg_mask.size(-1)\n",
        "\n",
        "        # initialize decoder hidden state\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(encoder_final)\n",
        "        \n",
        "        # pre-compute projected encoder hidden states\n",
        "        # (the \"keys\" for the attention mechanism)\n",
        "        # this is only done for efficiency\n",
        "        proj_key = self.attention.key_layer(encoder_hidden)\n",
        "        \n",
        "        # here we store all intermediate hidden states and pre-output vectors\n",
        "        decoder_states = []\n",
        "        pre_output_vectors = []\n",
        "        \n",
        "        # unroll the decoder RNN for max_len steps\n",
        "        for i in range(max_len):\n",
        "            prev_embed = trg_embed[:, i].unsqueeze(1)\n",
        "            output, hidden, pre_output = self.forward_step(\n",
        "              prev_embed, encoder_hidden, src_mask, proj_key, hidden)\n",
        "            decoder_states.append(output)\n",
        "            pre_output_vectors.append(pre_output)\n",
        "\n",
        "        decoder_states = torch.cat(decoder_states, dim=1)\n",
        "        pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n",
        "        return decoder_states, hidden, pre_output_vectors  # [B, N, D]\n",
        "\n",
        "    def init_hidden(self, encoder_final):\n",
        "        \"\"\"Returns the initial decoder state,\n",
        "        conditioned on the final encoder state.\"\"\"\n",
        "\n",
        "        if encoder_final is None:\n",
        "            return None  # start with zeros\n",
        "\n",
        "        return torch.tanh(self.bridge(encoder_final))\n",
        "       "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in-EoGuttOxu"
      },
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    \"\"\"Implements Bahdanau (MLP) attention\"\"\"\n",
        "    \n",
        "    def __init__(self, hidden_size, key_size=None, query_size=None):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        \n",
        "        # We assume a bi-directional encoder so key_size is 2*hidden_size\n",
        "        key_size = 2 * hidden_size if key_size is None else key_size\n",
        "        query_size = hidden_size if query_size is None else query_size\n",
        "\n",
        "        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n",
        "        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n",
        "        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n",
        "        \n",
        "        # to store attention scores\n",
        "        self.alphas = None\n",
        "        \n",
        "    def forward(self, query=None, proj_key=None, value=None, mask=None):\n",
        "        assert mask is not None, \"mask is required\"\n",
        "\n",
        "        # We first project the query (the decoder state).\n",
        "        # The projected keys (the encoder states) were already pre-computated.\n",
        "        query = self.query_layer(query)\n",
        "        \n",
        "        # Calculate scores.\n",
        "        scores = self.energy_layer(torch.tanh(query + proj_key))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "        \n",
        "        # Mask out invalid positions.\n",
        "        # The mask marks valid positions so we invert it using `mask & 0`.\n",
        "        scores.data.masked_fill_(mask == 0, -float('inf'))\n",
        "        \n",
        "        # Turn scores to probabilities.\n",
        "        alphas = F.softmax(scores, dim=-1)\n",
        "        self.alphas = alphas        \n",
        "        \n",
        "        # The context vector is the weighted sum of the values.\n",
        "        context = torch.bmm(alphas, value)\n",
        "        \n",
        "        # context shape: [B, 1, 2D], alphas shape: [B, 1, M]\n",
        "        return context, alphas"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj9t9ll-tXbO"
      },
      "source": [
        "def make_model(src_vocab, tgt_vocab, emb_size=256, hidden_size=512, num_layers=1, dropout=0.1):\n",
        "    \"Helper: Construct a model from hyperparameters.\"\n",
        "\n",
        "    attention = BahdanauAttention(hidden_size)\n",
        "\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n",
        "        Decoder(emb_size, hidden_size, attention, num_layers=num_layers, dropout=dropout),\n",
        "        nn.Embedding(src_vocab, emb_size),\n",
        "        nn.Embedding(tgt_vocab, emb_size),\n",
        "        Generator(hidden_size, tgt_vocab))\n",
        "\n",
        "    return model.cuda() if USE_CUDA else model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKxlWZLAtibG"
      },
      "source": [
        "class Batch:\n",
        "    \"\"\"Object for holding a batch of data with mask during training.\n",
        "    Input is a batch from a torch text iterator.\n",
        "    \"\"\"\n",
        "    def __init__(self, src, trg, pad_index=0):\n",
        "        \n",
        "        src, src_lengths = src\n",
        "        \n",
        "        self.src = src\n",
        "        self.src_lengths = src_lengths\n",
        "        self.src_mask = (src != pad_index).unsqueeze(-2)\n",
        "        self.nseqs = src.size(0)\n",
        "        \n",
        "        self.trg = None\n",
        "        self.trg_y = None\n",
        "        self.trg_mask = None\n",
        "        self.trg_lengths = None\n",
        "        self.ntokens = None\n",
        "\n",
        "        if trg is not None:\n",
        "            trg, trg_lengths = trg\n",
        "            self.trg = trg[:, :-1]\n",
        "            self.trg_lengths = trg_lengths\n",
        "            self.trg_y = trg[:, 1:]\n",
        "            self.trg_mask = (self.trg_y != pad_index)\n",
        "            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n",
        "        \n",
        "        if USE_CUDA:\n",
        "            self.src = self.src.cuda()\n",
        "            self.src_mask = self.src_mask.cuda()\n",
        "\n",
        "            if trg is not None:\n",
        "                self.trg = self.trg.cuda()\n",
        "                self.trg_y = self.trg_y.cuda()\n",
        "                self.trg_mask = self.trg_mask.cuda()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQxxvLrItjSW"
      },
      "source": [
        "\n",
        "def run_epoch(data_iter, model, loss_compute, print_every=50):\n",
        "    \"\"\"Standard Training and Logging Function\"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "    print_tokens = 0\n",
        "\n",
        "    for i, batch in enumerate(data_iter, 1):\n",
        "        \n",
        "        out, _, pre_output = model.forward(batch.src, batch.trg,\n",
        "                                           batch.src_mask, batch.trg_mask,\n",
        "                                           batch.src_lengths, batch.trg_lengths)\n",
        "        loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n",
        "        total_loss += loss\n",
        "        total_tokens += batch.ntokens\n",
        "        print_tokens += batch.ntokens\n",
        "        \n",
        "        if model.training and i % print_every == 0:\n",
        "            elapsed = time.time() - start\n",
        "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
        "                    (i, loss / batch.nseqs, print_tokens / elapsed))\n",
        "            start = time.time()\n",
        "            print_tokens = 0\n",
        "\n",
        "    return math.exp(total_loss / float(total_tokens))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKCWhRLftmx2"
      },
      "source": [
        "def data_gen(num_words=11, batch_size=16, num_batches=100, length=10, pad_index=0, sos_index=1):\n",
        "    \"\"\"Generate random data for a src-tgt copy task.\"\"\"\n",
        "    for i in range(num_batches):\n",
        "        data = torch.from_numpy(\n",
        "          np.random.randint(1, num_words, size=(batch_size, length)))\n",
        "        data[:, 0] = sos_index\n",
        "        data = data.cuda() if USE_CUDA else data\n",
        "        src = data[:, 1:]\n",
        "        trg = data\n",
        "        src_lengths = [length-1] * batch_size\n",
        "        trg_lengths = [length] * batch_size\n",
        "        yield Batch((src, src_lengths), (trg, trg_lengths), pad_index=pad_index)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T_kYEnXtpil"
      },
      "source": [
        "class SimpleLossCompute:\n",
        "    \"\"\"A simple loss compute and train function.\"\"\"\n",
        "\n",
        "    def __init__(self, generator, criterion, opt=None):\n",
        "        self.generator = generator\n",
        "        self.criterion = criterion\n",
        "        self.opt = opt\n",
        "\n",
        "    def __call__(self, x, y, norm):\n",
        "        x = self.generator(x)\n",
        "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n",
        "                              y.contiguous().view(-1))\n",
        "        loss = loss / norm\n",
        "\n",
        "        if self.opt is not None:\n",
        "            loss.backward()          \n",
        "            self.opt.step()\n",
        "            self.opt.zero_grad()\n",
        "\n",
        "        return loss.data.item() * norm"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zCmqMdqtr2d"
      },
      "source": [
        "def greedy_decode(model, src, src_mask, src_lengths, max_len=100, sos_index=1, eos_index=None):\n",
        "    \"\"\"Greedily decode a sentence.\"\"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n",
        "        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n",
        "        trg_mask = torch.ones_like(prev_y)\n",
        "\n",
        "    output = []\n",
        "    attention_scores = []\n",
        "    hidden = None\n",
        "\n",
        "    for i in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            out, hidden, pre_output = model.decode(\n",
        "              encoder_hidden, encoder_final, src_mask,\n",
        "              prev_y, trg_mask, hidden)\n",
        "\n",
        "            # we predict from the pre-output layer, which is\n",
        "            # a combination of Decoder state, prev emb, and context\n",
        "            prob = model.generator(pre_output[:, -1])\n",
        "\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.data.item()\n",
        "        output.append(next_word)\n",
        "        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n",
        "        attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n",
        "    \n",
        "    output = np.array(output)\n",
        "        \n",
        "    # cut off everything starting from </s> \n",
        "    # (only when eos_index provided)\n",
        "    if eos_index is not None:\n",
        "        first_eos = np.where(output==eos_index)[0]\n",
        "        if len(first_eos) > 0:\n",
        "            output = output[:first_eos[0]]      \n",
        "    \n",
        "    return output, np.concatenate(attention_scores, axis=1)\n",
        "  \n",
        "\n",
        "def lookup_words(x, vocab=None):\n",
        "    if vocab is not None:\n",
        "        x = [vocab.itos[i] for i in x]\n",
        "\n",
        "    return [str(t) for t in x]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYZgmksutxa1"
      },
      "source": [
        "def print_examples(example_iter, model, n=2, max_len=100, \n",
        "                   sos_index=1, \n",
        "                   src_eos_index=None, \n",
        "                   trg_eos_index=None, \n",
        "                   src_vocab=None, trg_vocab=None):\n",
        "    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    print()\n",
        "    \n",
        "    if src_vocab is not None and trg_vocab is not None:\n",
        "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
        "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
        "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
        "    else:\n",
        "        src_eos_index = None\n",
        "        trg_sos_index = 1\n",
        "        trg_eos_index = None\n",
        "        \n",
        "    for i, batch in enumerate(example_iter):\n",
        "      \n",
        "        src = batch.src.cpu().numpy()[0, :]\n",
        "        trg = batch.trg_y.cpu().numpy()[0, :]\n",
        "\n",
        "        # remove </s> (if it is there)\n",
        "        src = src[:-1] if src[-1] == src_eos_index else src\n",
        "        trg = trg[:-1] if trg[-1] == trg_eos_index else trg      \n",
        "      \n",
        "        result, _ = greedy_decode(\n",
        "          model, batch.src, batch.src_mask, batch.src_lengths,\n",
        "          max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n",
        "        print(\"Example #%d\" % (i+1))\n",
        "        print(\"Src : \", \" \".join(lookup_words(src, vocab=src_vocab)))\n",
        "        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n",
        "        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n",
        "        print()\n",
        "        \n",
        "        count += 1\n",
        "        if count == n:\n",
        "            break\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YYoXrnnt22d"
      },
      "source": [
        "def train_copy_task():\n",
        "    \"\"\"Train the simple copy task.\"\"\"\n",
        "    num_words = 11\n",
        "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=0)\n",
        "    model = make_model(num_words, num_words, emb_size=32, hidden_size=64)\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
        "    eval_data = list(data_gen(num_words=num_words, batch_size=1, num_batches=100))\n",
        " \n",
        "    dev_perplexities = []\n",
        "    \n",
        "    if USE_CUDA:\n",
        "        model.cuda()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        \n",
        "        print(\"Epoch %d\" % epoch)\n",
        "\n",
        "        # train\n",
        "        model.train()\n",
        "        data = data_gen(num_words=num_words, batch_size=32, num_batches=100)\n",
        "        run_epoch(data, model,\n",
        "                  SimpleLossCompute(model.generator, criterion, optim))\n",
        "\n",
        "        # evaluate\n",
        "        model.eval()\n",
        "        with torch.no_grad(): \n",
        "            perplexity = run_epoch(eval_data, model,\n",
        "                                   SimpleLossCompute(model.generator, criterion, None))\n",
        "            print(\"Evaluation perplexity: %f\" % perplexity)\n",
        "            dev_perplexities.append(perplexity)\n",
        "            print_examples(eval_data, model, n=2, max_len=9)\n",
        "        \n",
        "    return dev_perplexities"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6-6STAJt7LN",
        "outputId": "e26a6dd0-5709-4ec8-8b86-ae255aaa4ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# train the copy task\n",
        "dev_perplexities = train_copy_task()\n",
        "\n",
        "def plot_perplexity(perplexities):\n",
        "    \"\"\"plot perplexities\"\"\"\n",
        "    plt.title(\"Perplexity per Epoch\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Perplexity\")\n",
        "    plt.plot(perplexities)\n",
        "    \n",
        "plot_perplexity(dev_perplexities)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch Step: 50 Loss: 19.720032 Tokens per Sec: 11598.307512\n",
            "Epoch Step: 100 Loss: 17.850552 Tokens per Sec: 15170.816200\n",
            "Evaluation perplexity: 7.165516\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  5 8 7 5 8 7 5 8 7\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 8 8 8 8 8 8 8\n",
            "\n",
            "Epoch 1\n",
            "Epoch Step: 50 Loss: 15.429652 Tokens per Sec: 14992.098502\n",
            "Epoch Step: 100 Loss: 11.758207 Tokens per Sec: 14947.578424\n",
            "Evaluation perplexity: 3.761093\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 5 3 8 7 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 8 2 5 8 3 2\n",
            "\n",
            "Epoch 2\n",
            "Epoch Step: 50 Loss: 9.917424 Tokens per Sec: 14847.338341\n",
            "Epoch Step: 100 Loss: 8.949946 Tokens per Sec: 15304.885970\n",
            "Evaluation perplexity: 2.573576\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 5 7 8 10\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 8 5 2 6 8 2\n",
            "\n",
            "Epoch 3\n",
            "Epoch Step: 50 Loss: 7.275528 Tokens per Sec: 15346.500157\n",
            "Epoch Step: 100 Loss: 6.582398 Tokens per Sec: 15400.779856\n",
            "Evaluation perplexity: 2.072119\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 5 8 7 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 2 5 8 2 6\n",
            "\n",
            "Epoch 4\n",
            "Epoch Step: 50 Loss: 5.942048 Tokens per Sec: 15180.589107\n",
            "Epoch Step: 100 Loss: 4.906624 Tokens per Sec: 15352.991481\n",
            "Evaluation perplexity: 1.765160\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 5 10 8 7\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n",
            "Epoch 5\n",
            "Epoch Step: 50 Loss: 5.266299 Tokens per Sec: 15213.914447\n",
            "Epoch Step: 100 Loss: 4.140487 Tokens per Sec: 15393.824321\n",
            "Evaluation perplexity: 1.565404\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 10 5 7 8\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n",
            "Epoch 6\n",
            "Epoch Step: 50 Loss: 3.958579 Tokens per Sec: 15295.417223\n",
            "Epoch Step: 100 Loss: 3.681248 Tokens per Sec: 15672.915439\n",
            "Evaluation perplexity: 1.455613\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 5 8 7\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 8 6\n",
            "\n",
            "Epoch 7\n",
            "Epoch Step: 50 Loss: 2.987802 Tokens per Sec: 15615.157655\n",
            "Epoch Step: 100 Loss: 2.790762 Tokens per Sec: 15562.333769\n",
            "Evaluation perplexity: 1.366846\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 7 8 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n",
            "Epoch 8\n",
            "Epoch Step: 50 Loss: 2.148365 Tokens per Sec: 15162.452694\n",
            "Epoch Step: 100 Loss: 2.303626 Tokens per Sec: 15209.286436\n",
            "Evaluation perplexity: 1.275108\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 7 8 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n",
            "Epoch 9\n",
            "Epoch Step: 50 Loss: 2.088912 Tokens per Sec: 15180.264794\n",
            "Epoch Step: 100 Loss: 2.050288 Tokens per Sec: 15610.564778\n",
            "Evaluation perplexity: 1.195517\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 7 8 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGxVGL6St94_",
        "outputId": "800cee35-ecc3-4d18-a78b-3d7dee64ebb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install git+git://github.com/pytorch/text spacy \n",
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/pytorch/text\n",
            "  Cloning git://github.com/pytorch/text to /tmp/pip-req-build-yibe22ds\n",
            "  Running command git clone -q git://github.com/pytorch/text /tmp/pip-req-build-yibe22ds\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (1.18.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (2020.6.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.9.0a0+97e6d1d) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.3.1)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Building wheel for torchtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchtext: filename=torchtext-0.9.0a0+97e6d1d-cp36-cp36m-linux_x86_64.whl size=6975680 sha256=e4ab71965f0b40fa739d34dd825e0f70b8b54c6804e91936461639f862526f4c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nzpkgdxb/wheels/39/42/ff/82f5ccbb0f30b25e14610376f5d0c67913fc05017dab59f8eb\n",
            "Successfully built torchtext\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed torchtext-0.9.0a0+97e6d1d\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.3.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 734kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.3.1)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907056 sha256=497c0331b33deaaa8bac02f1c2fac3ab7a0f3b3d4fd1e7a9aa2d76b8d77fd9b9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ryk6frhx/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvECCjHguQ_U",
        "outputId": "e0c070bd-9090-42d9-c5bf-ad413f7a58e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# For data loading.\n",
        "from torchtext import data, datasets\n",
        "\n",
        "if True:\n",
        "    import spacy\n",
        "    spacy_de = spacy.load('de')\n",
        "    spacy_en = spacy.load('en')\n",
        "\n",
        "    def tokenize_de(text):\n",
        "        return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "    def tokenize_en(text):\n",
        "        return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "    UNK_TOKEN = \"<unk>\"\n",
        "    PAD_TOKEN = \"<pad>\"    \n",
        "    SOS_TOKEN = \"<s>\"\n",
        "    EOS_TOKEN = \"</s>\"\n",
        "    LOWER = True\n",
        "    \n",
        "    # we include lengths to provide to the RNNs\n",
        "    SRC = data.Field(tokenize=tokenize_de, \n",
        "                     batch_first=True, lower=LOWER, include_lengths=True,\n",
        "                     unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=None, eos_token=EOS_TOKEN)\n",
        "    TRG = data.Field(tokenize=tokenize_en, \n",
        "                     batch_first=True, lower=LOWER, include_lengths=True,\n",
        "                     unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=SOS_TOKEN, eos_token=EOS_TOKEN)\n",
        "\n",
        "    MAX_LEN = 25  # NOTE: we filter out a lot of sentences for speed\n",
        "    train_data, valid_data, test_data = datasets.IWSLT.splits(\n",
        "        exts=('.de', '.en'), fields=(SRC, TRG), \n",
        "        filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
        "            len(vars(x)['trg']) <= MAX_LEN)\n",
        "    MIN_FREQ = 5  # NOTE: we limit the vocabulary to frequent words for speed\n",
        "    SRC.build_vocab(train_data.src, min_freq=MIN_FREQ)\n",
        "    TRG.build_vocab(train_data.trg, min_freq=MIN_FREQ)\n",
        "    \n",
        "    PAD_INDEX = TRG.vocab.stoi[PAD_TOKEN]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading de-en.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "de-en.tgz: 100%|██████████| 24.2M/24.2M [00:13<00:00, 1.74MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.en.xml\n",
            ".data/iwslt/de-en/train.tags.de-en.de\n",
            ".data/iwslt/de-en/train.tags.de-en.en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgoNC-NauXFU",
        "outputId": "773011c0-3a70-4b1c-e526-d832bdaf3aa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def print_data_info(train_data, valid_data, test_data, src_field, trg_field):\n",
        "    \"\"\" This prints some useful stuff about our data sets. \"\"\"\n",
        "\n",
        "    print(\"Data set sizes (number of sentence pairs):\")\n",
        "    print('train', len(train_data))\n",
        "    print('valid', len(valid_data))\n",
        "    print('test', len(test_data), \"\\n\")\n",
        "\n",
        "    print(\"First training example:\")\n",
        "    print(\"src:\", \" \".join(vars(train_data[0])['src']))\n",
        "    print(\"trg:\", \" \".join(vars(train_data[0])['trg']), \"\\n\")\n",
        "\n",
        "    print(\"Most common words (src):\")\n",
        "    print(\"\\n\".join([\"%10s %10d\" % x for x in src_field.vocab.freqs.most_common(10)]), \"\\n\")\n",
        "    print(\"Most common words (trg):\")\n",
        "    print(\"\\n\".join([\"%10s %10d\" % x for x in trg_field.vocab.freqs.most_common(10)]), \"\\n\")\n",
        "\n",
        "    print(\"First 10 words (src):\")\n",
        "    print(\"\\n\".join(\n",
        "        '%02d %s' % (i, t) for i, t in enumerate(src_field.vocab.itos[:10])), \"\\n\")\n",
        "    print(\"First 10 words (trg):\")\n",
        "    print(\"\\n\".join(\n",
        "        '%02d %s' % (i, t) for i, t in enumerate(trg_field.vocab.itos[:10])), \"\\n\")\n",
        "\n",
        "    print(\"Number of German words (types):\", len(src_field.vocab))\n",
        "    print(\"Number of English words (types):\", len(trg_field.vocab), \"\\n\")\n",
        "    \n",
        "    \n",
        "print_data_info(train_data, valid_data, test_data, SRC, TRG)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data set sizes (number of sentence pairs):\n",
            "train 143115\n",
            "valid 690\n",
            "test 963 \n",
            "\n",
            "First training example:\n",
            "src: david gallo : das ist bill lange . ich bin dave gallo .\n",
            "trg: david gallo : this is bill lange . i 'm dave gallo . \n",
            "\n",
            "Most common words (src):\n",
            "         .     138329\n",
            "         ,     105944\n",
            "       und      41843\n",
            "       die      40808\n",
            "       das      33324\n",
            "       sie      33034\n",
            "       ich      31150\n",
            "       ist      31037\n",
            "        es      27449\n",
            "       wir      25817 \n",
            "\n",
            "Most common words (trg):\n",
            "         .     137259\n",
            "         ,      91615\n",
            "       the      73343\n",
            "       and      50276\n",
            "        to      42799\n",
            "         a      39572\n",
            "        of      39496\n",
            "         i      33521\n",
            "        it      32920\n",
            "      that      32640 \n",
            "\n",
            "First 10 words (src):\n",
            "00 <unk>\n",
            "01 <pad>\n",
            "02 </s>\n",
            "03 .\n",
            "04 ,\n",
            "05 und\n",
            "06 die\n",
            "07 das\n",
            "08 sie\n",
            "09 ich \n",
            "\n",
            "First 10 words (trg):\n",
            "00 <unk>\n",
            "01 <pad>\n",
            "02 <s>\n",
            "03 </s>\n",
            "04 .\n",
            "05 ,\n",
            "06 the\n",
            "07 and\n",
            "08 to\n",
            "09 a \n",
            "\n",
            "Number of German words (types): 15765\n",
            "Number of English words (types): 13002 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tpjBcpRuZtU",
        "outputId": "110ba8ef-2a7e-49a3-81bb-a9a530a2eb4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "train_iter = data.BucketIterator(train_data, batch_size=64, train=True, \n",
        "                                 sort_within_batch=True, \n",
        "                                 sort_key=lambda x: (len(x.src), len(x.trg)), repeat=False,\n",
        "                                 device=DEVICE)\n",
        "valid_iter = data.Iterator(valid_data, batch_size=1, train=False, sort=False, repeat=False, \n",
        "                           device=DEVICE)\n",
        "\n",
        "\n",
        "def rebatch(pad_idx, batch):\n",
        "    \"\"\"Wrap torchtext batch into our own Batch class for pre-processing\"\"\"\n",
        "    return Batch(batch.src, batch.trg, pad_idx)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: Iterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEDhqD8FudHs"
      },
      "source": [
        "def train(model, num_epochs=10, lr=0.0003, print_every=100):\n",
        "    \"\"\"Train a model on IWSLT\"\"\"\n",
        "    \n",
        "    if USE_CUDA:\n",
        "        model.cuda()\n",
        "\n",
        "    # optionally add label smoothing; see the Annotated Transformer\n",
        "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    dev_perplexities = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      \n",
        "        print(\"Epoch\", epoch)\n",
        "        model.train()\n",
        "        train_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in train_iter), \n",
        "                                     model,\n",
        "                                     SimpleLossCompute(model.generator, criterion, optim),\n",
        "                                     print_every=print_every)\n",
        "        \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            print_examples((rebatch(PAD_INDEX, x) for x in valid_iter), \n",
        "                           model, n=3, src_vocab=SRC.vocab, trg_vocab=TRG.vocab)        \n",
        "\n",
        "            dev_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in valid_iter), \n",
        "                                       model, \n",
        "                                       SimpleLossCompute(model.generator, criterion, None))\n",
        "            print(\"Validation perplexity: %f\" % dev_perplexity)\n",
        "            dev_perplexities.append(dev_perplexity)\n",
        "        \n",
        "    return dev_perplexities\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mF-9PItukW8",
        "outputId": "3f768c4a-a3e1-4320-f98b-4187e2fed860",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "model = make_model(len(SRC.vocab), len(TRG.vocab),\n",
        "                   emb_size=256, hidden_size=256,\n",
        "                   num_layers=1, dropout=0.2)\n",
        "dev_perplexities = train(model, print_every=100)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch Step: 100 Loss: 32.068207 Tokens per Sec: 26829.839052\n",
            "Epoch Step: 200 Loss: 77.528320 Tokens per Sec: 27903.585899\n",
            "Epoch Step: 300 Loss: 122.597214 Tokens per Sec: 28114.747786\n",
            "Epoch Step: 400 Loss: 80.730759 Tokens per Sec: 28277.876286\n",
            "Epoch Step: 500 Loss: 45.135300 Tokens per Sec: 28643.011406\n",
            "Epoch Step: 600 Loss: 26.416521 Tokens per Sec: 28581.329652\n",
            "Epoch Step: 700 Loss: 65.228302 Tokens per Sec: 28414.226198\n",
            "Epoch Step: 800 Loss: 49.033859 Tokens per Sec: 28630.063524\n",
            "Epoch Step: 900 Loss: 92.301254 Tokens per Sec: 28742.606331\n",
            "Epoch Step: 1000 Loss: 87.172104 Tokens per Sec: 28871.885942\n",
            "Epoch Step: 1100 Loss: 96.741325 Tokens per Sec: 28320.050981\n",
            "Epoch Step: 1200 Loss: 89.191422 Tokens per Sec: 29024.837862\n",
            "Epoch Step: 1300 Loss: 63.926044 Tokens per Sec: 28882.152057\n",
            "Epoch Step: 1400 Loss: 49.518196 Tokens per Sec: 28840.525866\n",
            "Epoch Step: 1500 Loss: 67.475319 Tokens per Sec: 28276.090712\n",
            "Epoch Step: 1600 Loss: 83.188034 Tokens per Sec: 28802.490318\n",
            "Epoch Step: 1700 Loss: 69.758034 Tokens per Sec: 28348.245160\n",
            "Epoch Step: 1800 Loss: 5.818039 Tokens per Sec: 28513.447561\n",
            "Epoch Step: 1900 Loss: 86.115616 Tokens per Sec: 27984.519000\n",
            "Epoch Step: 2000 Loss: 66.854187 Tokens per Sec: 28286.675357\n",
            "Epoch Step: 2100 Loss: 28.565779 Tokens per Sec: 27673.969049\n",
            "Epoch Step: 2200 Loss: 95.154961 Tokens per Sec: 28046.597744\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 15 years old , i was a <unk> of the <unk> of the <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on the same way to be the same , the <unk> of the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he was very much , what was really interesting , there was the <unk> of the <unk> .\n",
            "\n",
            "Validation perplexity: 31.838225\n",
            "Epoch 1\n",
            "Epoch Step: 100 Loss: 69.140083 Tokens per Sec: 27363.391419\n",
            "Epoch Step: 200 Loss: 26.569559 Tokens per Sec: 28501.378995\n",
            "Epoch Step: 300 Loss: 75.672844 Tokens per Sec: 28758.547543\n",
            "Epoch Step: 400 Loss: 70.079453 Tokens per Sec: 28641.545982\n",
            "Epoch Step: 500 Loss: 85.948242 Tokens per Sec: 28879.173842\n",
            "Epoch Step: 600 Loss: 16.590904 Tokens per Sec: 28751.405705\n",
            "Epoch Step: 700 Loss: 57.912651 Tokens per Sec: 28564.012288\n",
            "Epoch Step: 800 Loss: 78.670158 Tokens per Sec: 28532.694878\n",
            "Epoch Step: 900 Loss: 79.375160 Tokens per Sec: 28725.424316\n",
            "Epoch Step: 1000 Loss: 12.349929 Tokens per Sec: 28637.621947\n",
            "Epoch Step: 1100 Loss: 39.298481 Tokens per Sec: 28620.890368\n",
            "Epoch Step: 1200 Loss: 87.252663 Tokens per Sec: 28740.703537\n",
            "Epoch Step: 1300 Loss: 20.448593 Tokens per Sec: 28436.824748\n",
            "Epoch Step: 1400 Loss: 48.099323 Tokens per Sec: 28694.726475\n",
            "Epoch Step: 1500 Loss: 83.669167 Tokens per Sec: 28464.627685\n",
            "Epoch Step: 1600 Loss: 88.695518 Tokens per Sec: 28646.996892\n",
            "Epoch Step: 1700 Loss: 84.389816 Tokens per Sec: 28942.889918\n",
            "Epoch Step: 1800 Loss: 55.633255 Tokens per Sec: 28863.731317\n",
            "Epoch Step: 1900 Loss: 30.958385 Tokens per Sec: 28415.491076\n",
            "Epoch Step: 2000 Loss: 43.618408 Tokens per Sec: 28268.128059\n",
            "Epoch Step: 2100 Loss: 48.500484 Tokens per Sec: 28471.758469\n",
            "Epoch Step: 2200 Loss: 67.632324 Tokens per Sec: 28531.531689\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> of the <unk> <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on his little , <unk> , the <unk> of the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw his happy , which was pretty much , there was a <unk> , there was the news .\n",
            "\n",
            "Validation perplexity: 20.011770\n",
            "Epoch 2\n",
            "Epoch Step: 100 Loss: 24.867628 Tokens per Sec: 27187.239535\n",
            "Epoch Step: 200 Loss: 43.195244 Tokens per Sec: 28543.898113\n",
            "Epoch Step: 300 Loss: 37.499802 Tokens per Sec: 28674.454486\n",
            "Epoch Step: 400 Loss: 15.839211 Tokens per Sec: 28469.072895\n",
            "Epoch Step: 500 Loss: 66.933266 Tokens per Sec: 28812.973370\n",
            "Epoch Step: 600 Loss: 22.079924 Tokens per Sec: 28607.751453\n",
            "Epoch Step: 700 Loss: 44.928463 Tokens per Sec: 28690.424073\n",
            "Epoch Step: 800 Loss: 29.815289 Tokens per Sec: 28754.803502\n",
            "Epoch Step: 900 Loss: 44.412495 Tokens per Sec: 28572.110520\n",
            "Epoch Step: 1000 Loss: 27.608017 Tokens per Sec: 29193.329635\n",
            "Epoch Step: 1100 Loss: 33.657631 Tokens per Sec: 28944.333950\n",
            "Epoch Step: 1200 Loss: 19.610304 Tokens per Sec: 28720.046978\n",
            "Epoch Step: 1300 Loss: 85.366035 Tokens per Sec: 28711.249015\n",
            "Epoch Step: 1400 Loss: 63.533314 Tokens per Sec: 28431.633936\n",
            "Epoch Step: 1500 Loss: 36.580055 Tokens per Sec: 28558.017530\n",
            "Epoch Step: 1600 Loss: 42.608303 Tokens per Sec: 28500.071986\n",
            "Epoch Step: 1700 Loss: 36.128407 Tokens per Sec: 28740.632586\n",
            "Epoch Step: 1800 Loss: 16.689840 Tokens per Sec: 28600.065012\n",
            "Epoch Step: 1900 Loss: 69.255981 Tokens per Sec: 28300.199433\n",
            "Epoch Step: 2000 Loss: 8.593110 Tokens per Sec: 28262.823452\n",
            "Epoch Step: 2100 Loss: 30.453068 Tokens per Sec: 28978.609892\n",
            "Epoch Step: 2200 Loss: 77.792709 Tokens per Sec: 28846.583536\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> by the <unk> of joy .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on his little , the radio <unk> the <unk> of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty much of the time , there was the news <unk> .\n",
            "\n",
            "Validation perplexity: 15.743297\n",
            "Epoch 3\n",
            "Epoch Step: 100 Loss: 4.076390 Tokens per Sec: 27316.604283\n",
            "Epoch Step: 200 Loss: 53.449860 Tokens per Sec: 28538.122489\n",
            "Epoch Step: 300 Loss: 45.511856 Tokens per Sec: 28653.710360\n",
            "Epoch Step: 400 Loss: 17.893641 Tokens per Sec: 28734.581182\n",
            "Epoch Step: 500 Loss: 34.667206 Tokens per Sec: 28543.530593\n",
            "Epoch Step: 600 Loss: 14.853942 Tokens per Sec: 28585.423226\n",
            "Epoch Step: 700 Loss: 25.388937 Tokens per Sec: 28798.593462\n",
            "Epoch Step: 800 Loss: 39.563324 Tokens per Sec: 28873.361060\n",
            "Epoch Step: 900 Loss: 17.722918 Tokens per Sec: 28774.794271\n",
            "Epoch Step: 1000 Loss: 41.159355 Tokens per Sec: 28800.394137\n",
            "Epoch Step: 1100 Loss: 22.008875 Tokens per Sec: 28625.565889\n",
            "Epoch Step: 1200 Loss: 15.459769 Tokens per Sec: 28487.291175\n",
            "Epoch Step: 1300 Loss: 42.096081 Tokens per Sec: 28896.138773\n",
            "Epoch Step: 1400 Loss: 17.427977 Tokens per Sec: 28352.843513\n",
            "Epoch Step: 1500 Loss: 42.844372 Tokens per Sec: 28061.420138\n",
            "Epoch Step: 1600 Loss: 68.921227 Tokens per Sec: 28302.238304\n",
            "Epoch Step: 1700 Loss: 31.442167 Tokens per Sec: 28365.271693\n",
            "Epoch Step: 1800 Loss: 38.627079 Tokens per Sec: 28465.254656\n",
            "Epoch Step: 1900 Loss: 30.791969 Tokens per Sec: 28433.383149\n",
            "Epoch Step: 2000 Loss: 50.827148 Tokens per Sec: 28472.440681\n",
            "Epoch Step: 2100 Loss: 20.567951 Tokens per Sec: 27981.166895\n",
            "Epoch Step: 2200 Loss: 13.095542 Tokens per Sec: 28258.564356\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a one of the <unk> of the <unk> <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father stopped on his little , tiny radio <unk> the <unk> of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty unusual , which was pretty much , because it was the news most important .\n",
            "\n",
            "Validation perplexity: 13.863045\n",
            "Epoch 4\n",
            "Epoch Step: 100 Loss: 19.533295 Tokens per Sec: 27133.711943\n",
            "Epoch Step: 200 Loss: 15.230255 Tokens per Sec: 28691.901903\n",
            "Epoch Step: 300 Loss: 44.631645 Tokens per Sec: 28522.341328\n",
            "Epoch Step: 400 Loss: 46.738766 Tokens per Sec: 28890.518491\n",
            "Epoch Step: 500 Loss: 36.212276 Tokens per Sec: 28900.595352\n",
            "Epoch Step: 600 Loss: 66.191673 Tokens per Sec: 28694.203485\n",
            "Epoch Step: 700 Loss: 62.214405 Tokens per Sec: 28357.939419\n",
            "Epoch Step: 800 Loss: 11.226195 Tokens per Sec: 28900.945858\n",
            "Epoch Step: 900 Loss: 16.727257 Tokens per Sec: 28787.647494\n",
            "Epoch Step: 1000 Loss: 20.659739 Tokens per Sec: 28740.002717\n",
            "Epoch Step: 1100 Loss: 15.310055 Tokens per Sec: 28408.397665\n",
            "Epoch Step: 1200 Loss: 55.645653 Tokens per Sec: 28643.138044\n",
            "Epoch Step: 1300 Loss: 53.063679 Tokens per Sec: 28643.822395\n",
            "Epoch Step: 1400 Loss: 30.972755 Tokens per Sec: 28868.785195\n",
            "Epoch Step: 1500 Loss: 8.864389 Tokens per Sec: 28369.290131\n",
            "Epoch Step: 1600 Loss: 15.640836 Tokens per Sec: 28386.553939\n",
            "Epoch Step: 1700 Loss: 45.774311 Tokens per Sec: 28240.855996\n",
            "Epoch Step: 1800 Loss: 60.665016 Tokens per Sec: 27557.818137\n",
            "Epoch Step: 1900 Loss: 59.544495 Tokens per Sec: 27548.164359\n",
            "Epoch Step: 2000 Loss: 11.937892 Tokens per Sec: 28157.377563\n",
            "Epoch Step: 2100 Loss: 51.245434 Tokens per Sec: 28367.341321\n",
            "Epoch Step: 2200 Loss: 55.329636 Tokens per Sec: 28961.164532\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> by the <unk> of joy .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father stopped on his little , <unk> radio the <unk> of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw his happy , which was pretty unusual , because it was the news most of the most important .\n",
            "\n",
            "Validation perplexity: 12.723827\n",
            "Epoch 5\n",
            "Epoch Step: 100 Loss: 24.821918 Tokens per Sec: 26900.872442\n",
            "Epoch Step: 200 Loss: 44.731060 Tokens per Sec: 29084.255730\n",
            "Epoch Step: 300 Loss: 39.427818 Tokens per Sec: 28927.732625\n",
            "Epoch Step: 400 Loss: 32.117931 Tokens per Sec: 28329.275713\n",
            "Epoch Step: 500 Loss: 21.066019 Tokens per Sec: 28539.375013\n",
            "Epoch Step: 600 Loss: 6.325708 Tokens per Sec: 28645.837365\n",
            "Epoch Step: 700 Loss: 20.930817 Tokens per Sec: 28808.007494\n",
            "Epoch Step: 800 Loss: 36.846954 Tokens per Sec: 28545.752100\n",
            "Epoch Step: 900 Loss: 51.663647 Tokens per Sec: 29123.365266\n",
            "Epoch Step: 1000 Loss: 23.484470 Tokens per Sec: 28440.331031\n",
            "Epoch Step: 1100 Loss: 20.888832 Tokens per Sec: 28106.013023\n",
            "Epoch Step: 1200 Loss: 28.999193 Tokens per Sec: 28691.115996\n",
            "Epoch Step: 1300 Loss: 28.941225 Tokens per Sec: 28758.654172\n",
            "Epoch Step: 1400 Loss: 61.508350 Tokens per Sec: 28309.410588\n",
            "Epoch Step: 1500 Loss: 37.041965 Tokens per Sec: 28646.651897\n",
            "Epoch Step: 1600 Loss: 24.497730 Tokens per Sec: 28874.982187\n",
            "Epoch Step: 1700 Loss: 22.541216 Tokens per Sec: 28247.451482\n",
            "Epoch Step: 1800 Loss: 40.523373 Tokens per Sec: 28583.759513\n",
            "Epoch Step: 1900 Loss: 54.770187 Tokens per Sec: 27898.481453\n",
            "Epoch Step: 2000 Loss: 24.599474 Tokens per Sec: 28527.351706\n",
            "Epoch Step: 2100 Loss: 23.119852 Tokens per Sec: 28513.749244\n",
            "Epoch Step: 2200 Loss: 54.909782 Tokens per Sec: 28639.021868\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a one of the <unk> of <unk> <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father stopped on his little , radio radio <unk> the bbc of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty unusual , because it was the news of the most beautiful <unk> .\n",
            "\n",
            "Validation perplexity: 12.676535\n",
            "Epoch 6\n",
            "Epoch Step: 100 Loss: 45.643600 Tokens per Sec: 27331.375118\n",
            "Epoch Step: 200 Loss: 13.870678 Tokens per Sec: 28761.338121\n",
            "Epoch Step: 300 Loss: 40.852573 Tokens per Sec: 29059.183664\n",
            "Epoch Step: 400 Loss: 20.264585 Tokens per Sec: 28990.497234\n",
            "Epoch Step: 500 Loss: 33.310535 Tokens per Sec: 28745.311690\n",
            "Epoch Step: 600 Loss: 52.928982 Tokens per Sec: 28718.456341\n",
            "Epoch Step: 700 Loss: 36.754692 Tokens per Sec: 28722.181517\n",
            "Epoch Step: 800 Loss: 64.436668 Tokens per Sec: 28513.524273\n",
            "Epoch Step: 900 Loss: 39.432632 Tokens per Sec: 28545.258429\n",
            "Epoch Step: 1000 Loss: 42.178143 Tokens per Sec: 28650.571006\n",
            "Epoch Step: 1100 Loss: 15.687601 Tokens per Sec: 28597.912104\n",
            "Epoch Step: 1200 Loss: 45.047489 Tokens per Sec: 28642.131259\n",
            "Epoch Step: 1300 Loss: 40.924587 Tokens per Sec: 28553.678370\n",
            "Epoch Step: 1400 Loss: 54.712357 Tokens per Sec: 28782.603900\n",
            "Epoch Step: 1500 Loss: 13.989870 Tokens per Sec: 28567.132879\n",
            "Epoch Step: 1600 Loss: 17.393648 Tokens per Sec: 28660.025605\n",
            "Epoch Step: 1700 Loss: 62.156174 Tokens per Sec: 28315.337867\n",
            "Epoch Step: 1800 Loss: 44.215565 Tokens per Sec: 28644.508427\n",
            "Epoch Step: 1900 Loss: 12.600540 Tokens per Sec: 28351.187896\n",
            "Epoch Step: 2000 Loss: 43.740143 Tokens per Sec: 28423.981656\n",
            "Epoch Step: 2100 Loss: 34.730881 Tokens per Sec: 28471.714313\n",
            "Epoch Step: 2200 Loss: 52.712574 Tokens per Sec: 28702.369732\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a one of the <unk> of pleasure in pleasure .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father heard on his little , gray radio the <unk> of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he looked very happy , which was quite unusual in the back of the time , it was the news most difficult .\n",
            "\n",
            "Validation perplexity: 11.831467\n",
            "Epoch 7\n",
            "Epoch Step: 100 Loss: 17.431919 Tokens per Sec: 27119.057929\n",
            "Epoch Step: 200 Loss: 37.690609 Tokens per Sec: 28665.138081\n",
            "Epoch Step: 300 Loss: 21.792273 Tokens per Sec: 28653.195763\n",
            "Epoch Step: 400 Loss: 15.620675 Tokens per Sec: 28621.647283\n",
            "Epoch Step: 500 Loss: 15.210653 Tokens per Sec: 28490.090509\n",
            "Epoch Step: 600 Loss: 31.710649 Tokens per Sec: 28671.983291\n",
            "Epoch Step: 700 Loss: 42.859470 Tokens per Sec: 28653.465509\n",
            "Epoch Step: 800 Loss: 17.268618 Tokens per Sec: 28648.547517\n",
            "Epoch Step: 900 Loss: 25.883152 Tokens per Sec: 28529.308918\n",
            "Epoch Step: 1000 Loss: 9.833585 Tokens per Sec: 28040.248653\n",
            "Epoch Step: 1100 Loss: 1.886168 Tokens per Sec: 28559.543518\n",
            "Epoch Step: 1200 Loss: 24.523451 Tokens per Sec: 28782.448807\n",
            "Epoch Step: 1300 Loss: 38.188347 Tokens per Sec: 28905.413195\n",
            "Epoch Step: 1400 Loss: 44.977386 Tokens per Sec: 28636.130726\n",
            "Epoch Step: 1500 Loss: 39.349998 Tokens per Sec: 28244.210038\n",
            "Epoch Step: 1600 Loss: 33.422997 Tokens per Sec: 27905.727176\n",
            "Epoch Step: 1700 Loss: 24.480370 Tokens per Sec: 28575.973698\n",
            "Epoch Step: 1800 Loss: 45.164330 Tokens per Sec: 29022.378036\n",
            "Epoch Step: 1900 Loss: 22.631742 Tokens per Sec: 28150.086812\n",
            "Epoch Step: 2000 Loss: 25.135077 Tokens per Sec: 28123.250316\n",
            "Epoch Step: 2100 Loss: 51.714443 Tokens per Sec: 28296.463267\n",
            "Epoch Step: 2200 Loss: 33.442299 Tokens per Sec: 28825.110619\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a one of the <unk> of pleasure in pleasure .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father stopped on his little , radio radio the <unk> of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty unusual , because it was the news of the most wonderful .\n",
            "\n",
            "Validation perplexity: 11.964200\n",
            "Epoch 8\n",
            "Epoch Step: 100 Loss: 44.201412 Tokens per Sec: 27450.443553\n",
            "Epoch Step: 200 Loss: 48.105228 Tokens per Sec: 28719.950325\n",
            "Epoch Step: 300 Loss: 33.931087 Tokens per Sec: 29040.806959\n",
            "Epoch Step: 400 Loss: 8.940966 Tokens per Sec: 28602.624184\n",
            "Epoch Step: 500 Loss: 31.461584 Tokens per Sec: 28725.884372\n",
            "Epoch Step: 600 Loss: 23.686666 Tokens per Sec: 28814.131379\n",
            "Epoch Step: 700 Loss: 29.754688 Tokens per Sec: 28954.576787\n",
            "Epoch Step: 800 Loss: 29.394054 Tokens per Sec: 28895.524317\n",
            "Epoch Step: 900 Loss: 51.119965 Tokens per Sec: 28519.193452\n",
            "Epoch Step: 1000 Loss: 29.138176 Tokens per Sec: 28911.805699\n",
            "Epoch Step: 1100 Loss: 21.260937 Tokens per Sec: 29204.896578\n",
            "Epoch Step: 1200 Loss: 35.920845 Tokens per Sec: 28979.162463\n",
            "Epoch Step: 1300 Loss: 20.960796 Tokens per Sec: 28554.045527\n",
            "Epoch Step: 1400 Loss: 42.050156 Tokens per Sec: 27868.340755\n",
            "Epoch Step: 1500 Loss: 51.109493 Tokens per Sec: 27858.401777\n",
            "Epoch Step: 1600 Loss: 43.336094 Tokens per Sec: 27788.257816\n",
            "Epoch Step: 1700 Loss: 22.960848 Tokens per Sec: 28268.219422\n",
            "Epoch Step: 1800 Loss: 41.847427 Tokens per Sec: 28482.042211\n",
            "Epoch Step: 1900 Loss: 21.624386 Tokens per Sec: 28179.453495\n",
            "Epoch Step: 2000 Loss: 48.192051 Tokens per Sec: 28364.756694\n",
            "Epoch Step: 2100 Loss: 30.841469 Tokens per Sec: 28701.826634\n",
            "Epoch Step: 2200 Loss: 17.007357 Tokens per Sec: 28584.028124\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> by the morning of pleasure .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father stopped on his little , radio radio <unk> the bbc of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy from what was pretty unusual to be the news of the most beautiful <unk> .\n",
            "\n",
            "Validation perplexity: 11.803411\n",
            "Epoch 9\n",
            "Epoch Step: 100 Loss: 4.315799 Tokens per Sec: 27455.544830\n",
            "Epoch Step: 200 Loss: 45.120197 Tokens per Sec: 28842.925380\n",
            "Epoch Step: 300 Loss: 26.554762 Tokens per Sec: 28666.737909\n",
            "Epoch Step: 400 Loss: 26.134411 Tokens per Sec: 28521.198678\n",
            "Epoch Step: 500 Loss: 19.488354 Tokens per Sec: 28657.816815\n",
            "Epoch Step: 600 Loss: 41.383736 Tokens per Sec: 28295.759275\n",
            "Epoch Step: 700 Loss: 5.924700 Tokens per Sec: 28061.983018\n",
            "Epoch Step: 800 Loss: 10.070564 Tokens per Sec: 28451.295016\n",
            "Epoch Step: 900 Loss: 9.534557 Tokens per Sec: 28505.914894\n",
            "Epoch Step: 1000 Loss: 18.224661 Tokens per Sec: 28237.145990\n",
            "Epoch Step: 1100 Loss: 30.210661 Tokens per Sec: 28313.919185\n",
            "Epoch Step: 1200 Loss: 45.087444 Tokens per Sec: 28629.745360\n",
            "Epoch Step: 1300 Loss: 38.942333 Tokens per Sec: 28254.387814\n",
            "Epoch Step: 1400 Loss: 7.571163 Tokens per Sec: 28253.049745\n",
            "Epoch Step: 1500 Loss: 23.640469 Tokens per Sec: 28607.984234\n",
            "Epoch Step: 1600 Loss: 35.757454 Tokens per Sec: 28769.250296\n",
            "Epoch Step: 1700 Loss: 53.029938 Tokens per Sec: 28650.834159\n",
            "Epoch Step: 1800 Loss: 24.933641 Tokens per Sec: 28575.634350\n",
            "Epoch Step: 1900 Loss: 16.185041 Tokens per Sec: 28312.396397\n",
            "Epoch Step: 2000 Loss: 31.677523 Tokens per Sec: 28333.076569\n",
            "Epoch Step: 2100 Loss: 24.371696 Tokens per Sec: 28505.266858\n",
            "Epoch Step: 2200 Loss: 43.778130 Tokens per Sec: 28888.536242\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a one of the morning of the pleasure of pleasure .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father stopped on his little , radio radio <unk> the bbc of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he looked very happy , which was quite likely to see the news was that the news was largely .\n",
            "\n",
            "Validation perplexity: 12.108419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_OnRwXiumt7",
        "outputId": "60256aff-a739-47e0-c43b-88d6f71d8c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plot_perplexity(dev_perplexities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrMu3XssuqYj",
        "outputId": "18785a4c-0233-4730-83ec-2af4d13e5416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import sacrebleu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-a42160e8fb94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msacrebleu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sacrebleu'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8K29vJnuyBb",
        "outputId": "36218401-d401-4c65-f5d3-890370c2ad7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "len(valid_data)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "690"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3fnIZQFu0Qb",
        "outputId": "b8ec379d-edc5-4633-cf20-72ec07afa59f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "references = [\" \".join(example.trg) for example in valid_data]\n",
        "print(len(references))\n",
        "print(references[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "690\n",
            "when i was 11 , i remember waking up one morning to the sound of joy in my house .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbl-BnoOu2i0",
        "outputId": "dc94a4ce-192b-48aa-e7fd-fcafa3a02a1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "references[-2]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"i 'm always the one taking the picture .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLo0rDCyu4UD",
        "outputId": "458eabed-1a57-45e5-9f57-17eddbbf4b53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "hypotheses = []\n",
        "alphas = []  # save the last attention scores\n",
        "for batch in valid_iter:\n",
        "  batch = rebatch(PAD_INDEX, batch)\n",
        "  pred, attention = greedy_decode(\n",
        "    model, batch.src, batch.src_mask, batch.src_lengths, max_len=25,\n",
        "    sos_index=TRG.vocab.stoi[SOS_TOKEN],\n",
        "    eos_index=TRG.vocab.stoi[EOS_TOKEN])\n",
        "  hypotheses.append(pred)\n",
        "  alphas.append(attention)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoaNsGCpu7E7",
        "outputId": "991bc9b0-0966-4a87-dd6c-2ffade3d1124",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# we will still need to convert the indices to actual words!\n",
        "hypotheses[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  70,   11,   24, 1460,  103,  217,    5,   11,   24,    9,   40,\n",
              "         10,    6,  690,   10,    6, 1956,   10, 1956,    4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhqNooaGu9zL",
        "outputId": "85cf2e4b-238b-4c65-8f33-378295570bee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hypotheses = [lookup_words(x, TRG.vocab) for x in hypotheses]\n",
        "hypotheses[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['when',\n",
              " 'i',\n",
              " 'was',\n",
              " '11',\n",
              " 'years',\n",
              " 'old',\n",
              " ',',\n",
              " 'i',\n",
              " 'was',\n",
              " 'a',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'morning',\n",
              " 'of',\n",
              " 'the',\n",
              " 'pleasure',\n",
              " 'of',\n",
              " 'pleasure',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ivquOCZvA1b",
        "outputId": "a8ff000a-537a-4ddb-c28c-1b5361d8fcd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# finally, the SacreBLEU raw scorer requires string input, so we convert the lists to strings\n",
        "hypotheses = [\" \".join(x) for x in hypotheses]\n",
        "print(len(hypotheses))\n",
        "print(hypotheses[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "690\n",
            "when i was 11 years old , i was a one of the morning of the pleasure of pleasure .\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
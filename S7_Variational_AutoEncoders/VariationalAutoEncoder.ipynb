{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled19.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZsQpx33Xrkqwrhgpisw06",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EVA4-RS-Group/Phase2/blob/master/S7_Variational_AutoEncoders/VariationalAutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LsSj_KVboud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "569f7e71-1b5c-44d8-8054-9454be50d7fd"
      },
      "source": [
        "!wget -q https://github.com/EVA4-RS-Group/Phase2/releases/download/S6/data.zip\n",
        "!unzip data.zip\n",
        "!rm -rf data.zip\n",
        "!mkdir models\n",
        "!mkdir samples"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "   creating: data/test/\n",
            "   creating: data/test/data_test/\n",
            "  inflating: data/test/data_test/desktop.ini  \n",
            "  inflating: data/test/data_test/img_002.jpg  \n",
            "  inflating: data/test/data_test/img_005.jpg  \n",
            "  inflating: data/test/data_test/img_012.jpg  \n",
            "  inflating: data/test/data_test/img_015.jpg  \n",
            "  inflating: data/test/data_test/img_022.jpg  \n",
            "  inflating: data/test/data_test/img_025.jpg  \n",
            "  inflating: data/test/data_test/img_032.jpg  \n",
            "  inflating: data/test/data_test/img_035.jpg  \n",
            "  inflating: data/test/data_test/img_042.jpg  \n",
            "  inflating: data/test/data_test/img_045.jpg  \n",
            "  inflating: data/test/data_test/img_052.jpg  \n",
            "  inflating: data/test/data_test/img_055.jpg  \n",
            "  inflating: data/test/data_test/img_062.jpg  \n",
            "  inflating: data/test/data_test/img_065.jpg  \n",
            "  inflating: data/test/data_test/img_072.jpg  \n",
            "  inflating: data/test/data_test/img_075.jpg  \n",
            "  inflating: data/test/data_test/img_082.jpg  \n",
            "  inflating: data/test/data_test/img_085.jpg  \n",
            "  inflating: data/test/data_test/img_092.jpg  \n",
            "  inflating: data/test/data_test/img_095.jpg  \n",
            "  inflating: data/test/data_test/img_102.jpg  \n",
            "  inflating: data/test/data_test/img_105.jpg  \n",
            "  inflating: data/test/data_test/img_112.jpg  \n",
            "  inflating: data/test/data_test/img_115.jpg  \n",
            "  inflating: data/test/data_test/img_122.jpg  \n",
            "  inflating: data/test/data_test/img_125.jpg  \n",
            "  inflating: data/test/data_test/img_132.jpg  \n",
            "  inflating: data/test/data_test/img_135.jpg  \n",
            "  inflating: data/test/data_test/img_142.jpg  \n",
            "  inflating: data/test/data_test/img_145.jpg  \n",
            "  inflating: data/test/data_test/img_152.jpg  \n",
            "  inflating: data/test/data_test/img_155.jpg  \n",
            "  inflating: data/test/data_test/img_162.jpg  \n",
            "  inflating: data/test/data_test/img_165.jpg  \n",
            "  inflating: data/test/data_test/img_172.jpg  \n",
            "  inflating: data/test/data_test/img_175.jpg  \n",
            "  inflating: data/test/data_test/img_182.jpg  \n",
            "  inflating: data/test/data_test/img_185.jpg  \n",
            "  inflating: data/test/data_test/img_192.jpg  \n",
            "  inflating: data/test/data_test/img_195.jpg  \n",
            "  inflating: data/test/data_test/img_202.jpg  \n",
            "  inflating: data/test/data_test/img_205.jpg  \n",
            "  inflating: data/test/data_test/img_212.jpg  \n",
            "  inflating: data/test/data_test/img_215.jpg  \n",
            "  inflating: data/test/data_test/img_222.jpg  \n",
            "  inflating: data/test/data_test/img_225.jpg  \n",
            "  inflating: data/test/data_test/img_232.jpg  \n",
            "  inflating: data/test/data_test/img_235.jpg  \n",
            "  inflating: data/test/data_test/img_242.jpg  \n",
            "  inflating: data/test/data_test/img_245.jpg  \n",
            "  inflating: data/test/data_test/img_252.jpg  \n",
            "  inflating: data/test/data_test/img_255.jpg  \n",
            "  inflating: data/test/data_test/img_262.jpg  \n",
            "  inflating: data/test/data_test/img_265.jpg  \n",
            "  inflating: data/test/data_test/img_272.jpg  \n",
            "  inflating: data/test/data_test/img_275.jpg  \n",
            "  inflating: data/test/data_test/img_282.jpg  \n",
            "  inflating: data/test/data_test/img_285.jpg  \n",
            "  inflating: data/test/data_test/img_292.jpg  \n",
            "  inflating: data/test/data_test/img_295.jpg  \n",
            "  inflating: data/test/data_test/img_302.jpg  \n",
            "  inflating: data/test/data_test/img_305.jpg  \n",
            "  inflating: data/test/data_test/img_312.jpg  \n",
            "  inflating: data/test/data_test/img_315.jpg  \n",
            "  inflating: data/test/data_test/img_322.jpg  \n",
            "  inflating: data/test/data_test/img_325.jpg  \n",
            "  inflating: data/test/data_test/img_332.jpg  \n",
            "  inflating: data/test/data_test/img_335.jpg  \n",
            "  inflating: data/test/data_test/img_342.jpg  \n",
            "  inflating: data/test/data_test/img_345.jpg  \n",
            "  inflating: data/test/data_test/img_352.jpg  \n",
            "  inflating: data/test/data_test/img_355.jpg  \n",
            "  inflating: data/test/data_test/img_362.jpg  \n",
            "  inflating: data/test/data_test/img_365.jpg  \n",
            "  inflating: data/test/data_test/img_372.jpg  \n",
            "  inflating: data/test/data_test/img_375.jpg  \n",
            "  inflating: data/test/data_test/img_382.jpg  \n",
            "  inflating: data/test/data_test/img_385.jpg  \n",
            "  inflating: data/test/data_test/img_392.jpg  \n",
            "  inflating: data/test/data_test/img_395.jpg  \n",
            "  inflating: data/test/data_test/img_402.jpg  \n",
            "  inflating: data/test/data_test/img_405.jpg  \n",
            "  inflating: data/test/data_test/img_412.jpg  \n",
            "  inflating: data/test/data_test/img_415.jpg  \n",
            "  inflating: data/test/data_test/img_422.jpg  \n",
            "  inflating: data/test/data_test/img_425.jpg  \n",
            "  inflating: data/test/data_test/img_432.jpg  \n",
            "  inflating: data/test/data_test/img_435.jpg  \n",
            "  inflating: data/test/data_test/img_442.jpg  \n",
            "  inflating: data/test/data_test/img_445.jpg  \n",
            "  inflating: data/test/data_test/img_452.jpg  \n",
            "  inflating: data/test/data_test/img_455.jpg  \n",
            "  inflating: data/test/data_test/img_462.jpg  \n",
            "  inflating: data/test/data_test/img_465.jpg  \n",
            "  inflating: data/test/data_test/img_472.jpg  \n",
            "  inflating: data/test/data_test/img_475.jpg  \n",
            "  inflating: data/test/data_test/img_482.jpg  \n",
            "  inflating: data/test/data_test/img_485.jpg  \n",
            "  inflating: data/test/data_test/img_492.jpg  \n",
            "  inflating: data/test/data_test/img_495.jpg  \n",
            "  inflating: data/test/data_test/img_502.jpg  \n",
            "  inflating: data/test/data_test/img_505.jpg  \n",
            "  inflating: data/test/desktop.ini   \n",
            "   creating: data/train/\n",
            "   creating: data/train/data_train/\n",
            "  inflating: data/train/data_train/img_000.jpg  \n",
            "  inflating: data/train/data_train/img_001.jpg  \n",
            "  inflating: data/train/data_train/img_003.jpg  \n",
            "  inflating: data/train/data_train/img_004.jpg  \n",
            "  inflating: data/train/data_train/img_006.jpg  \n",
            "  inflating: data/train/data_train/img_007.jpg  \n",
            "  inflating: data/train/data_train/img_008.jpg  \n",
            "  inflating: data/train/data_train/img_009.jpg  \n",
            "  inflating: data/train/data_train/img_010.jpg  \n",
            "  inflating: data/train/data_train/img_011.jpg  \n",
            "  inflating: data/train/data_train/img_013.jpg  \n",
            "  inflating: data/train/data_train/img_014.jpg  \n",
            "  inflating: data/train/data_train/img_016.jpg  \n",
            "  inflating: data/train/data_train/img_017.jpg  \n",
            "  inflating: data/train/data_train/img_018.jpg  \n",
            "  inflating: data/train/data_train/img_019.jpg  \n",
            "  inflating: data/train/data_train/img_020.jpg  \n",
            "  inflating: data/train/data_train/img_021.jpg  \n",
            "  inflating: data/train/data_train/img_023.jpg  \n",
            "  inflating: data/train/data_train/img_024.jpg  \n",
            "  inflating: data/train/data_train/img_026.jpg  \n",
            "  inflating: data/train/data_train/img_027.jpg  \n",
            "  inflating: data/train/data_train/img_028.jpg  \n",
            "  inflating: data/train/data_train/img_029.jpg  \n",
            "  inflating: data/train/data_train/img_030.jpg  \n",
            "  inflating: data/train/data_train/img_031.jpg  \n",
            "  inflating: data/train/data_train/img_033.jpg  \n",
            "  inflating: data/train/data_train/img_034.jpg  \n",
            "  inflating: data/train/data_train/img_036.jpg  \n",
            "  inflating: data/train/data_train/img_037.jpg  \n",
            "  inflating: data/train/data_train/img_038.jpg  \n",
            "  inflating: data/train/data_train/img_039.jpg  \n",
            "  inflating: data/train/data_train/img_040.jpg  \n",
            "  inflating: data/train/data_train/img_041.jpg  \n",
            "  inflating: data/train/data_train/img_043.jpg  \n",
            "  inflating: data/train/data_train/img_044.jpg  \n",
            "  inflating: data/train/data_train/img_046.jpg  \n",
            "  inflating: data/train/data_train/img_047.jpg  \n",
            "  inflating: data/train/data_train/img_048.jpg  \n",
            "  inflating: data/train/data_train/img_049.jpg  \n",
            "  inflating: data/train/data_train/img_050.jpg  \n",
            "  inflating: data/train/data_train/img_051.jpg  \n",
            "  inflating: data/train/data_train/img_053.jpg  \n",
            "  inflating: data/train/data_train/img_054.jpg  \n",
            "  inflating: data/train/data_train/img_056.jpg  \n",
            "  inflating: data/train/data_train/img_057.jpg  \n",
            "  inflating: data/train/data_train/img_058.jpg  \n",
            "  inflating: data/train/data_train/img_059.jpg  \n",
            "  inflating: data/train/data_train/img_060.jpg  \n",
            "  inflating: data/train/data_train/img_061.jpg  \n",
            "  inflating: data/train/data_train/img_063.jpg  \n",
            "  inflating: data/train/data_train/img_064.jpg  \n",
            "  inflating: data/train/data_train/img_066.jpg  \n",
            "  inflating: data/train/data_train/img_067.jpg  \n",
            "  inflating: data/train/data_train/img_068.jpg  \n",
            "  inflating: data/train/data_train/img_069.jpg  \n",
            "  inflating: data/train/data_train/img_070.jpg  \n",
            "  inflating: data/train/data_train/img_071.jpg  \n",
            "  inflating: data/train/data_train/img_073.jpg  \n",
            "  inflating: data/train/data_train/img_074.jpg  \n",
            "  inflating: data/train/data_train/img_076.jpg  \n",
            "  inflating: data/train/data_train/img_077.jpg  \n",
            "  inflating: data/train/data_train/img_078.jpg  \n",
            "  inflating: data/train/data_train/img_079.jpg  \n",
            "  inflating: data/train/data_train/img_080.jpg  \n",
            "  inflating: data/train/data_train/img_081.jpg  \n",
            "  inflating: data/train/data_train/img_083.jpg  \n",
            "  inflating: data/train/data_train/img_084.jpg  \n",
            "  inflating: data/train/data_train/img_086.jpg  \n",
            "  inflating: data/train/data_train/img_087.jpg  \n",
            "  inflating: data/train/data_train/img_088.jpg  \n",
            "  inflating: data/train/data_train/img_089.jpg  \n",
            "  inflating: data/train/data_train/img_090.jpg  \n",
            "  inflating: data/train/data_train/img_091.jpg  \n",
            "  inflating: data/train/data_train/img_093.jpg  \n",
            "  inflating: data/train/data_train/img_094.jpg  \n",
            "  inflating: data/train/data_train/img_096.jpg  \n",
            "  inflating: data/train/data_train/img_097.jpg  \n",
            "  inflating: data/train/data_train/img_098.jpg  \n",
            "  inflating: data/train/data_train/img_099.jpg  \n",
            "  inflating: data/train/data_train/img_100.jpg  \n",
            "  inflating: data/train/data_train/img_101.jpg  \n",
            "  inflating: data/train/data_train/img_103.jpg  \n",
            "  inflating: data/train/data_train/img_104.jpg  \n",
            "  inflating: data/train/data_train/img_106.jpg  \n",
            "  inflating: data/train/data_train/img_107.jpg  \n",
            "  inflating: data/train/data_train/img_108.jpg  \n",
            "  inflating: data/train/data_train/img_109.jpg  \n",
            "  inflating: data/train/data_train/img_110.jpg  \n",
            "  inflating: data/train/data_train/img_111.jpg  \n",
            "  inflating: data/train/data_train/img_113.jpg  \n",
            "  inflating: data/train/data_train/img_114.jpg  \n",
            "  inflating: data/train/data_train/img_116.jpg  \n",
            "  inflating: data/train/data_train/img_117.jpg  \n",
            "  inflating: data/train/data_train/img_118.jpg  \n",
            "  inflating: data/train/data_train/img_119.jpg  \n",
            "  inflating: data/train/data_train/img_120.jpg  \n",
            "  inflating: data/train/data_train/img_121.jpg  \n",
            "  inflating: data/train/data_train/img_123.jpg  \n",
            "  inflating: data/train/data_train/img_124.jpg  \n",
            "  inflating: data/train/data_train/img_126.jpg  \n",
            "  inflating: data/train/data_train/img_127.jpg  \n",
            "  inflating: data/train/data_train/img_128.jpg  \n",
            "  inflating: data/train/data_train/img_129.jpg  \n",
            "  inflating: data/train/data_train/img_130.jpg  \n",
            "  inflating: data/train/data_train/img_131.jpg  \n",
            "  inflating: data/train/data_train/img_133.jpg  \n",
            "  inflating: data/train/data_train/img_134.jpg  \n",
            "  inflating: data/train/data_train/img_136.jpg  \n",
            "  inflating: data/train/data_train/img_137.jpg  \n",
            "  inflating: data/train/data_train/img_138.jpg  \n",
            "  inflating: data/train/data_train/img_139.jpg  \n",
            "  inflating: data/train/data_train/img_140.jpg  \n",
            "  inflating: data/train/data_train/img_141.jpg  \n",
            "  inflating: data/train/data_train/img_143.jpg  \n",
            "  inflating: data/train/data_train/img_144.jpg  \n",
            "  inflating: data/train/data_train/img_146.jpg  \n",
            "  inflating: data/train/data_train/img_147.jpg  \n",
            "  inflating: data/train/data_train/img_148.jpg  \n",
            "  inflating: data/train/data_train/img_149.jpg  \n",
            "  inflating: data/train/data_train/img_150.jpg  \n",
            "  inflating: data/train/data_train/img_151.jpg  \n",
            "  inflating: data/train/data_train/img_153.jpg  \n",
            "  inflating: data/train/data_train/img_154.jpg  \n",
            "  inflating: data/train/data_train/img_156.jpg  \n",
            "  inflating: data/train/data_train/img_157.jpg  \n",
            "  inflating: data/train/data_train/img_158.jpg  \n",
            "  inflating: data/train/data_train/img_159.jpg  \n",
            "  inflating: data/train/data_train/img_160.jpg  \n",
            "  inflating: data/train/data_train/img_161.jpg  \n",
            "  inflating: data/train/data_train/img_163.jpg  \n",
            "  inflating: data/train/data_train/img_164.jpg  \n",
            "  inflating: data/train/data_train/img_166.jpg  \n",
            "  inflating: data/train/data_train/img_167.jpg  \n",
            "  inflating: data/train/data_train/img_168.jpg  \n",
            "  inflating: data/train/data_train/img_169.jpg  \n",
            "  inflating: data/train/data_train/img_170.jpg  \n",
            "  inflating: data/train/data_train/img_171.jpg  \n",
            "  inflating: data/train/data_train/img_173.jpg  \n",
            "  inflating: data/train/data_train/img_174.jpg  \n",
            "  inflating: data/train/data_train/img_176.jpg  \n",
            "  inflating: data/train/data_train/img_177.jpg  \n",
            "  inflating: data/train/data_train/img_178.jpg  \n",
            "  inflating: data/train/data_train/img_179.jpg  \n",
            "  inflating: data/train/data_train/img_180.jpg  \n",
            "  inflating: data/train/data_train/img_181.jpg  \n",
            "  inflating: data/train/data_train/img_183.jpg  \n",
            "  inflating: data/train/data_train/img_184.jpg  \n",
            "  inflating: data/train/data_train/img_186.jpg  \n",
            "  inflating: data/train/data_train/img_187.jpg  \n",
            "  inflating: data/train/data_train/img_188.jpg  \n",
            "  inflating: data/train/data_train/img_189.jpg  \n",
            "  inflating: data/train/data_train/img_190.jpg  \n",
            "  inflating: data/train/data_train/img_191.jpg  \n",
            "  inflating: data/train/data_train/img_193.jpg  \n",
            "  inflating: data/train/data_train/img_194.jpg  \n",
            "  inflating: data/train/data_train/img_196.jpg  \n",
            "  inflating: data/train/data_train/img_197.jpg  \n",
            "  inflating: data/train/data_train/img_198.jpg  \n",
            "  inflating: data/train/data_train/img_199.jpg  \n",
            "  inflating: data/train/data_train/img_200.jpg  \n",
            "  inflating: data/train/data_train/img_201.jpg  \n",
            "  inflating: data/train/data_train/img_203.jpg  \n",
            "  inflating: data/train/data_train/img_204.jpg  \n",
            "  inflating: data/train/data_train/img_206.jpg  \n",
            "  inflating: data/train/data_train/img_207.jpg  \n",
            "  inflating: data/train/data_train/img_208.jpg  \n",
            "  inflating: data/train/data_train/img_209.jpg  \n",
            "  inflating: data/train/data_train/img_210.jpg  \n",
            "  inflating: data/train/data_train/img_211.jpg  \n",
            "  inflating: data/train/data_train/img_213.jpg  \n",
            "  inflating: data/train/data_train/img_214.jpg  \n",
            "  inflating: data/train/data_train/img_216.jpg  \n",
            "  inflating: data/train/data_train/img_217.jpg  \n",
            "  inflating: data/train/data_train/img_218.jpg  \n",
            "  inflating: data/train/data_train/img_219.jpg  \n",
            "  inflating: data/train/data_train/img_220.jpg  \n",
            "  inflating: data/train/data_train/img_221.jpg  \n",
            "  inflating: data/train/data_train/img_223.jpg  \n",
            "  inflating: data/train/data_train/img_224.jpg  \n",
            "  inflating: data/train/data_train/img_226.jpg  \n",
            "  inflating: data/train/data_train/img_227.jpg  \n",
            "  inflating: data/train/data_train/img_228.jpg  \n",
            "  inflating: data/train/data_train/img_229.jpg  \n",
            "  inflating: data/train/data_train/img_230.jpg  \n",
            "  inflating: data/train/data_train/img_231.jpg  \n",
            "  inflating: data/train/data_train/img_233.jpg  \n",
            "  inflating: data/train/data_train/img_234.jpg  \n",
            "  inflating: data/train/data_train/img_236.jpg  \n",
            "  inflating: data/train/data_train/img_237.jpg  \n",
            "  inflating: data/train/data_train/img_238.jpg  \n",
            "  inflating: data/train/data_train/img_239.jpg  \n",
            "  inflating: data/train/data_train/img_240.jpg  \n",
            "  inflating: data/train/data_train/img_241.jpg  \n",
            "  inflating: data/train/data_train/img_243.jpg  \n",
            "  inflating: data/train/data_train/img_244.jpg  \n",
            "  inflating: data/train/data_train/img_246.jpg  \n",
            "  inflating: data/train/data_train/img_247.jpg  \n",
            "  inflating: data/train/data_train/img_248.jpg  \n",
            "  inflating: data/train/data_train/img_249.jpg  \n",
            "  inflating: data/train/data_train/img_250.jpg  \n",
            "  inflating: data/train/data_train/img_251.jpg  \n",
            "  inflating: data/train/data_train/img_253.jpg  \n",
            "  inflating: data/train/data_train/img_254.jpg  \n",
            "  inflating: data/train/data_train/img_256.jpg  \n",
            "  inflating: data/train/data_train/img_257.jpg  \n",
            "  inflating: data/train/data_train/img_258.jpg  \n",
            "  inflating: data/train/data_train/img_259.jpg  \n",
            "  inflating: data/train/data_train/img_260.jpg  \n",
            "  inflating: data/train/data_train/img_261.jpg  \n",
            "  inflating: data/train/data_train/img_263.jpg  \n",
            "  inflating: data/train/data_train/img_264.jpg  \n",
            "  inflating: data/train/data_train/img_266.jpg  \n",
            "  inflating: data/train/data_train/img_267.jpg  \n",
            "  inflating: data/train/data_train/img_268.jpg  \n",
            "  inflating: data/train/data_train/img_269.jpg  \n",
            "  inflating: data/train/data_train/img_270.jpg  \n",
            "  inflating: data/train/data_train/img_271.jpg  \n",
            "  inflating: data/train/data_train/img_273.jpg  \n",
            "  inflating: data/train/data_train/img_274.jpg  \n",
            "  inflating: data/train/data_train/img_276.jpg  \n",
            "  inflating: data/train/data_train/img_277.jpg  \n",
            "  inflating: data/train/data_train/img_278.jpg  \n",
            "  inflating: data/train/data_train/img_279.jpg  \n",
            "  inflating: data/train/data_train/img_280.jpg  \n",
            "  inflating: data/train/data_train/img_281.jpg  \n",
            "  inflating: data/train/data_train/img_283.jpg  \n",
            "  inflating: data/train/data_train/img_284.jpg  \n",
            "  inflating: data/train/data_train/img_286.jpg  \n",
            "  inflating: data/train/data_train/img_287.jpg  \n",
            "  inflating: data/train/data_train/img_288.jpg  \n",
            "  inflating: data/train/data_train/img_289.jpg  \n",
            "  inflating: data/train/data_train/img_290.jpg  \n",
            "  inflating: data/train/data_train/img_291.jpg  \n",
            "  inflating: data/train/data_train/img_293.jpg  \n",
            "  inflating: data/train/data_train/img_294.jpg  \n",
            "  inflating: data/train/data_train/img_296.jpg  \n",
            "  inflating: data/train/data_train/img_297.jpg  \n",
            "  inflating: data/train/data_train/img_298.jpg  \n",
            "  inflating: data/train/data_train/img_299.jpg  \n",
            "  inflating: data/train/data_train/img_300.jpg  \n",
            "  inflating: data/train/data_train/img_301.jpg  \n",
            "  inflating: data/train/data_train/img_303.jpg  \n",
            "  inflating: data/train/data_train/img_304.jpg  \n",
            "  inflating: data/train/data_train/img_306.jpg  \n",
            "  inflating: data/train/data_train/img_307.jpg  \n",
            "  inflating: data/train/data_train/img_308.jpg  \n",
            "  inflating: data/train/data_train/img_309.jpg  \n",
            "  inflating: data/train/data_train/img_310.jpg  \n",
            "  inflating: data/train/data_train/img_311.jpg  \n",
            "  inflating: data/train/data_train/img_313.jpg  \n",
            "  inflating: data/train/data_train/img_314.jpg  \n",
            "  inflating: data/train/data_train/img_316.jpg  \n",
            "  inflating: data/train/data_train/img_317.jpg  \n",
            "  inflating: data/train/data_train/img_318.jpg  \n",
            "  inflating: data/train/data_train/img_319.jpg  \n",
            "  inflating: data/train/data_train/img_320.jpg  \n",
            "  inflating: data/train/data_train/img_321.jpg  \n",
            "  inflating: data/train/data_train/img_323.jpg  \n",
            "  inflating: data/train/data_train/img_324.jpg  \n",
            "  inflating: data/train/data_train/img_326.jpg  \n",
            "  inflating: data/train/data_train/img_327.jpg  \n",
            "  inflating: data/train/data_train/img_328.jpg  \n",
            "  inflating: data/train/data_train/img_329.jpg  \n",
            "  inflating: data/train/data_train/img_330.jpg  \n",
            "  inflating: data/train/data_train/img_331.jpg  \n",
            "  inflating: data/train/data_train/img_333.jpg  \n",
            "  inflating: data/train/data_train/img_334.jpg  \n",
            "  inflating: data/train/data_train/img_336.jpg  \n",
            "  inflating: data/train/data_train/img_337.jpg  \n",
            "  inflating: data/train/data_train/img_338.jpg  \n",
            "  inflating: data/train/data_train/img_339.jpg  \n",
            "  inflating: data/train/data_train/img_340.jpg  \n",
            "  inflating: data/train/data_train/img_341.jpg  \n",
            "  inflating: data/train/data_train/img_343.jpg  \n",
            "  inflating: data/train/data_train/img_344.jpg  \n",
            "  inflating: data/train/data_train/img_346.jpg  \n",
            "  inflating: data/train/data_train/img_347.jpg  \n",
            "  inflating: data/train/data_train/img_348.jpg  \n",
            "  inflating: data/train/data_train/img_349.jpg  \n",
            "  inflating: data/train/data_train/img_350.jpg  \n",
            "  inflating: data/train/data_train/img_351.jpg  \n",
            "  inflating: data/train/data_train/img_353.jpg  \n",
            "  inflating: data/train/data_train/img_354.jpg  \n",
            "  inflating: data/train/data_train/img_356.jpg  \n",
            "  inflating: data/train/data_train/img_357.jpg  \n",
            "  inflating: data/train/data_train/img_358.jpg  \n",
            "  inflating: data/train/data_train/img_359.jpg  \n",
            "  inflating: data/train/data_train/img_360.jpg  \n",
            "  inflating: data/train/data_train/img_361.jpg  \n",
            "  inflating: data/train/data_train/img_363.jpg  \n",
            "  inflating: data/train/data_train/img_364.jpg  \n",
            "  inflating: data/train/data_train/img_366.jpg  \n",
            "  inflating: data/train/data_train/img_367.jpg  \n",
            "  inflating: data/train/data_train/img_368.jpg  \n",
            "  inflating: data/train/data_train/img_369.jpg  \n",
            "  inflating: data/train/data_train/img_370.jpg  \n",
            "  inflating: data/train/data_train/img_371.jpg  \n",
            "  inflating: data/train/data_train/img_373.jpg  \n",
            "  inflating: data/train/data_train/img_374.jpg  \n",
            "  inflating: data/train/data_train/img_376.jpg  \n",
            "  inflating: data/train/data_train/img_377.jpg  \n",
            "  inflating: data/train/data_train/img_378.jpg  \n",
            "  inflating: data/train/data_train/img_379.jpg  \n",
            "  inflating: data/train/data_train/img_380.jpg  \n",
            "  inflating: data/train/data_train/img_381.jpg  \n",
            "  inflating: data/train/data_train/img_383.jpg  \n",
            "  inflating: data/train/data_train/img_384.jpg  \n",
            "  inflating: data/train/data_train/img_386.jpg  \n",
            "  inflating: data/train/data_train/img_387.jpg  \n",
            "  inflating: data/train/data_train/img_388.jpg  \n",
            "  inflating: data/train/data_train/img_389.jpg  \n",
            "  inflating: data/train/data_train/img_390.jpg  \n",
            "  inflating: data/train/data_train/img_391.jpg  \n",
            "  inflating: data/train/data_train/img_393.jpg  \n",
            "  inflating: data/train/data_train/img_394.jpg  \n",
            "  inflating: data/train/data_train/img_396.jpg  \n",
            "  inflating: data/train/data_train/img_397.jpg  \n",
            "  inflating: data/train/data_train/img_398.jpg  \n",
            "  inflating: data/train/data_train/img_399.jpg  \n",
            "  inflating: data/train/data_train/img_400.jpg  \n",
            "  inflating: data/train/data_train/img_401.jpg  \n",
            "  inflating: data/train/data_train/img_403.jpg  \n",
            "  inflating: data/train/data_train/img_404.jpg  \n",
            "  inflating: data/train/data_train/img_406.jpg  \n",
            "  inflating: data/train/data_train/img_407.jpg  \n",
            "  inflating: data/train/data_train/img_408.jpg  \n",
            "  inflating: data/train/data_train/img_409.jpg  \n",
            "  inflating: data/train/data_train/img_410.jpg  \n",
            "  inflating: data/train/data_train/img_411.jpg  \n",
            "  inflating: data/train/data_train/img_413.jpg  \n",
            "  inflating: data/train/data_train/img_414.jpg  \n",
            "  inflating: data/train/data_train/img_416.jpg  \n",
            "  inflating: data/train/data_train/img_417.jpg  \n",
            "  inflating: data/train/data_train/img_418.jpg  \n",
            "  inflating: data/train/data_train/img_419.jpg  \n",
            "  inflating: data/train/data_train/img_420.jpg  \n",
            "  inflating: data/train/data_train/img_421.jpg  \n",
            "  inflating: data/train/data_train/img_423.jpg  \n",
            "  inflating: data/train/data_train/img_424.jpg  \n",
            "  inflating: data/train/data_train/img_426.jpg  \n",
            "  inflating: data/train/data_train/img_427.jpg  \n",
            "  inflating: data/train/data_train/img_428.jpg  \n",
            "  inflating: data/train/data_train/img_429.jpg  \n",
            "  inflating: data/train/data_train/img_430.jpg  \n",
            "  inflating: data/train/data_train/img_431.jpg  \n",
            "  inflating: data/train/data_train/img_433.jpg  \n",
            "  inflating: data/train/data_train/img_434.jpg  \n",
            "  inflating: data/train/data_train/img_436.jpg  \n",
            "  inflating: data/train/data_train/img_437.jpg  \n",
            "  inflating: data/train/data_train/img_438.jpg  \n",
            "  inflating: data/train/data_train/img_439.jpg  \n",
            "  inflating: data/train/data_train/img_440.jpg  \n",
            "  inflating: data/train/data_train/img_441.jpg  \n",
            "  inflating: data/train/data_train/img_443.jpg  \n",
            "  inflating: data/train/data_train/img_444.jpg  \n",
            "  inflating: data/train/data_train/img_446.jpg  \n",
            "  inflating: data/train/data_train/img_447.jpg  \n",
            "  inflating: data/train/data_train/img_448.jpg  \n",
            "  inflating: data/train/data_train/img_449.jpg  \n",
            "  inflating: data/train/data_train/img_450.jpg  \n",
            "  inflating: data/train/data_train/img_451.jpg  \n",
            "  inflating: data/train/data_train/img_453.jpg  \n",
            "  inflating: data/train/data_train/img_454.jpg  \n",
            "  inflating: data/train/data_train/img_456.jpg  \n",
            "  inflating: data/train/data_train/img_457.jpg  \n",
            "  inflating: data/train/data_train/img_458.jpg  \n",
            "  inflating: data/train/data_train/img_459.jpg  \n",
            "  inflating: data/train/data_train/img_460.jpg  \n",
            "  inflating: data/train/data_train/img_461.jpg  \n",
            "  inflating: data/train/data_train/img_463.jpg  \n",
            "  inflating: data/train/data_train/img_464.jpg  \n",
            "  inflating: data/train/data_train/img_466.jpg  \n",
            "  inflating: data/train/data_train/img_467.jpg  \n",
            "  inflating: data/train/data_train/img_468.jpg  \n",
            "  inflating: data/train/data_train/img_469.jpg  \n",
            "  inflating: data/train/data_train/img_470.jpg  \n",
            "  inflating: data/train/data_train/img_471.jpg  \n",
            "  inflating: data/train/data_train/img_473.jpg  \n",
            "  inflating: data/train/data_train/img_474.jpg  \n",
            "  inflating: data/train/data_train/img_476.jpg  \n",
            "  inflating: data/train/data_train/img_477.jpg  \n",
            "  inflating: data/train/data_train/img_478.jpg  \n",
            "  inflating: data/train/data_train/img_479.jpg  \n",
            "  inflating: data/train/data_train/img_480.jpg  \n",
            "  inflating: data/train/data_train/img_481.jpg  \n",
            "  inflating: data/train/data_train/img_483.jpg  \n",
            "  inflating: data/train/data_train/img_484.jpg  \n",
            "  inflating: data/train/data_train/img_486.jpg  \n",
            "  inflating: data/train/data_train/img_487.jpg  \n",
            "  inflating: data/train/data_train/img_488.jpg  \n",
            "  inflating: data/train/data_train/img_489.jpg  \n",
            "  inflating: data/train/data_train/img_490.jpg  \n",
            "  inflating: data/train/data_train/img_491.jpg  \n",
            "  inflating: data/train/data_train/img_493.jpg  \n",
            "  inflating: data/train/data_train/img_494.jpg  \n",
            "  inflating: data/train/data_train/img_496.jpg  \n",
            "  inflating: data/train/data_train/img_497.jpg  \n",
            "  inflating: data/train/data_train/img_498.jpg  \n",
            "  inflating: data/train/data_train/img_499.jpg  \n",
            "  inflating: data/train/data_train/img_500.jpg  \n",
            "  inflating: data/train/data_train/img_501.jpg  \n",
            "  inflating: data/train/data_train/img_503.jpg  \n",
            "  inflating: data/train/data_train/img_504.jpg  \n",
            "  inflating: data/train/data_train/img_506.jpg  \n",
            "  inflating: data/train/data_train/img_507.jpg  \n",
            "  inflating: data/train/data_train/img_508.jpg  \n",
            "  inflating: data/train/data_train/img_509.jpg  \n",
            "  inflating: data/train/data_train/img_510.jpg  \n",
            "  inflating: data/train/data_train/img_511.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIo9l2fJVyGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!mkdir models\n",
        "!mkdir samples"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifkYl0L3azDE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7ba25155-8dfe-4201-84c3-cd4d442bc414"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io0Yg5mHuoWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.distributions.normal import Normal\n",
        "from torch.distributions import kl_divergence\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g6LaCf4uwMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CUDA = True\n",
        "SEED = 2\n",
        "BATCH_SIZE = 128\n",
        "# LOG_INTERVAL = 10\n",
        "# EPOCHS = 10\n",
        "# ZDIMS = 36"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgaIL_ck-75V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(SEED)\n",
        "if CUDA:\n",
        "    torch.cuda.manual_seed(SEED)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgA1Hr_ou0aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# # I do this so that the MNIST dataset is downloaded where I want it\n",
        "# #os.chdir(\"/home/cpbotha/Downloads/pytorch-vae\")\n",
        "\n",
        "\n",
        "\n",
        "# # DataLoader instances will load tensors directly into GPU memory\n",
        "# kwargs = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n",
        "\n",
        "# # Download or load downloaded MNIST dataset\n",
        "# # shuffle data at every epoch\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('data', train=True, download=True,\n",
        "#                    transform=transforms.ToTensor()),\n",
        "#     batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
        "\n",
        "# # Same for test data\n",
        "# test_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
        "#     batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JnUSXSEzXN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
        "                                std=(0.5, 0.5, 0.5))\n",
        "                               ])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG9b_25UvJRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_test = datasets.ImageFolder('data/test/', transform=transform)\n",
        "test_loader = DataLoader(dataset=dataset_test, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "dataset_train = datasets.ImageFolder('data/train/', transform=transform)\n",
        "train_loader = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=4, pin_memory=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKCCdP5XU3FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        try:\n",
        "            nn.init.xavier_uniform_(m.weight.data)\n",
        "            m.bias.data.fill_(0)\n",
        "        except AttributeError:\n",
        "            print(\"Skipping initialization of \", classname)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyuVbw12spcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim, dim, z_dim):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(input_dim, dim, 4, 2, 1),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(dim, dim, 4, 2, 1),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(dim, dim, 5, 1, 0),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(dim, z_dim * 2, 3, 1, 0),\n",
        "            nn.BatchNorm2d(z_dim * 2)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(z_dim, dim, 3, 1, 0),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(dim, dim, 5, 1, 0),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(dim, dim, 4, 2, 1),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(dim, input_dim, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.apply(weights_init)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encoder(x).chunk(2, dim=1)\n",
        "\n",
        "        q_z_x = Normal(mu, logvar.mul(.5).exp())\n",
        "        p_z = Normal(torch.zeros_like(mu), torch.ones_like(logvar))\n",
        "        kl_div = kl_divergence(q_z_x, p_z).sum(1).mean()\n",
        "\n",
        "        x_tilde = self.decoder(q_z_x.rsample())\n",
        "        return x_tilde, kl_div\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d8fJHfvvGWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Not this \n",
        "# class VAE(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(VAE, self).__init__()\n",
        "\n",
        "#         # ENCODER\n",
        "#         # 28 x 28 pixels = 784 input pixels, 400 outputs\n",
        "#         self.fc1 = nn.Linear(784, 400)\n",
        "#         # rectified linear unit layer from 400 to 400\n",
        "#         # max(0, x)\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.fc21 = nn.Linear(400, ZDIMS)  # mu layer\n",
        "#         self.fc22 = nn.Linear(400, ZDIMS)  # logvariance layer\n",
        "#         # this last layer bottlenecks through ZDIMS connections\n",
        "\n",
        "#         # DECODER\n",
        "#         # from bottleneck to hidden 400\n",
        "#         self.fc3 = nn.Linear(ZDIMS, 400)\n",
        "#         # from hidden 400 to 784 outputs\n",
        "#         self.fc4 = nn.Linear(400, 784)\n",
        "#         self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "#     def encode(self, x: Variable) -> (Variable, Variable):\n",
        "#         \"\"\"Input vector x -> fully connected 1 -> ReLU -> (fully connected\n",
        "#         21, fully connected 22)\n",
        "\n",
        "#         Parameters\n",
        "#         ----------\n",
        "#         x : [128, 784] matrix; 128 digits of 28x28 pixels each\n",
        "\n",
        "#         Returns\n",
        "#         -------\n",
        "\n",
        "#         (mu, logvar) : ZDIMS mean units one for each latent dimension, ZDIMS\n",
        "#             variance units one for each latent dimension\n",
        "\n",
        "#         \"\"\"\n",
        "\n",
        "#         # h1 is [128, 400]\n",
        "#         h1 = self.relu(self.fc1(x))  # type: Variable\n",
        "#         return self.fc21(h1), self.fc22(h1)\n",
        "\n",
        "#     def reparameterize(self, mu: Variable, logvar: Variable) -> Variable:\n",
        "#         \"\"\"THE REPARAMETERIZATION IDEA:\n",
        "\n",
        "#         For each training sample (we get 128 batched at a time)\n",
        "\n",
        "#         - take the current learned mu, stddev for each of the ZDIMS\n",
        "#           dimensions and draw a random sample from that distribution\n",
        "#         - the whole network is trained so that these randomly drawn\n",
        "#           samples decode to output that looks like the input\n",
        "#         - which will mean that the std, mu will be learned\n",
        "#           *distributions* that correctly encode the inputs\n",
        "#         - due to the additional KLD term (see loss_function() below)\n",
        "#           the distribution will tend to unit Gaussians\n",
        "\n",
        "#         Parameters\n",
        "#         ----------\n",
        "#         mu : [128, ZDIMS] mean matrix\n",
        "#         logvar : [128, ZDIMS] variance matrix\n",
        "\n",
        "#         Returns\n",
        "#         -------\n",
        "\n",
        "#         During training random sample from the learned ZDIMS-dimensional\n",
        "#         normal distribution; during inference its mean.\n",
        "#         \"\"\"\n",
        "\n",
        "#         if self.training:\n",
        "#             # multiply log variance with 0.5, then in-place exponent\n",
        "#             # yielding the standard deviation\n",
        "#             std = logvar.mul(0.5).exp_()  # type: Variable\n",
        "#             # - std.data is the [128,ZDIMS] tensor that is wrapped by std\n",
        "#             # - so eps is [128,ZDIMS] with all elements drawn from a mean 0\n",
        "#             #   and stddev 1 normal distribution that is 128 samples\n",
        "#             #   of random ZDIMS-float vectors\n",
        "#             eps = Variable(std.data.new(std.size()).normal_())\n",
        "#             # - sample from a normal distribution with standard\n",
        "#             #   deviation = std and mean = mu by multiplying mean 0\n",
        "#             #   stddev 1 sample with desired std and mu, see\n",
        "#             #   https://stats.stackexchange.com/a/16338\n",
        "#             # - so we have 128 sets (the batch) of random ZDIMS-float\n",
        "#             #   vectors sampled from normal distribution with learned\n",
        "#             #   std and mu for the current input\n",
        "#             return eps.mul(std).add_(mu)\n",
        "\n",
        "#         else:\n",
        "#             # During inference, we simply spit out the mean of the\n",
        "#             # learned distribution for the current input.  We could\n",
        "#             # use a random sample from the distribution, but mu of\n",
        "#             # course has the highest probability.\n",
        "#             return mu\n",
        "\n",
        "#     def decode(self, z: Variable) -> Variable:\n",
        "#         h3 = self.relu(self.fc3(z))\n",
        "#         return self.sigmoid(self.fc4(h3))\n",
        "\n",
        "#     def forward(self, x: Variable) -> (Variable, Variable, Variable):\n",
        "#         mu, logvar = self.encode(x.view(-1, 784))\n",
        "#         z = self.reparameterize(mu, logvar)\n",
        "#         return self.decode(z), mu, logvar"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1hWiitRshPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = 3\n",
        "DIM = 256\n",
        "Z_DIM = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eELWfsiEhj1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = VAE()\n",
        "model = VAE(INPUT_DIM, DIM, Z_DIM)\n",
        "if CUDA:\n",
        "    model.cuda()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXQAccQOJHvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "N_EPOCHS = 150\n",
        "PRINT_INTERVAL = 500\n",
        "DATASET = 'DATATSET' #'FashionMNIST'  # CIFAR10 | MNIST | FashionMNIST\n",
        "NUM_WORKERS = 4"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXJn7yx4pPbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3, amsgrad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZScXfYr7pNLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train():\n",
        "    train_loss = []\n",
        "    model.train()\n",
        "    for batch_idx, (x, _) in enumerate(train_loader):\n",
        "        start_time = time.time()\n",
        "        x = x.cuda()\n",
        "\n",
        "        x_tilde, kl_d = model(x)\n",
        "        loss_recons = F.mse_loss(x_tilde, x, size_average=False) / x.size(0)\n",
        "        loss = loss_recons + kl_d\n",
        "\n",
        "        nll = -Normal(x_tilde, torch.ones_like(x_tilde)).log_prob(x)\n",
        "        log_px = nll.mean().item() - np.log(128) + kl_d.item()\n",
        "        log_px /= np.log(2)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        train_loss.append([log_px, loss.item()])\n",
        "\n",
        "        if (batch_idx + 1) % PRINT_INTERVAL == 0:\n",
        "            print('\\tIter [{}/{} ({:.0f}%)]\\tLoss: {} Time: {:5.3f} ms/batch'.format(\n",
        "                batch_idx * len(x), len(train_loader.dataset),\n",
        "                PRINT_INTERVAL * batch_idx / len(train_loader),\n",
        "                np.asarray(train_loss)[-PRINT_INTERVAL:].mean(0),\n",
        "                1000 * (time.time() - start_time)\n",
        "            ))\n",
        "\n",
        "\n",
        "def test():\n",
        "    start_time = time.time()\n",
        "    val_loss = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (x, _) in enumerate(test_loader):\n",
        "            x = x.cuda()\n",
        "            x_tilde, kl_d = model(x)\n",
        "            loss_recons = F.mse_loss(x_tilde, x, size_average=False) / x.size(0)\n",
        "            loss = loss_recons + kl_d\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "    print('\\nValidation Completed!\\tLoss: {:5.4f} Time: {:5.3f} s'.format(\n",
        "        np.asarray(val_loss).mean(0),\n",
        "        time.time() - start_time\n",
        "    ))\n",
        "    return np.asarray(val_loss).mean(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axstZC9PH_DB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff7dacac-2938-42ea-c0e2-cfa66a138ef5"
      },
      "source": [
        "def generate_reconstructions():\n",
        "    model.eval()\n",
        "    x, _ = test_loader.__iter__().next()\n",
        "    x = x[:32].cuda()\n",
        "    x_tilde, kl_div = model(x)\n",
        "\n",
        "    x_cat = torch.cat([x, x_tilde], 0)\n",
        "    images = (x_cat.cpu().data + 1) / 2\n",
        "\n",
        "    save_image(\n",
        "        images,\n",
        "        'samples/vae_reconstructions_{}.png'.format(DATASET),\n",
        "        nrow=8\n",
        "    )\n",
        "\n",
        "\n",
        "def generate_samples():\n",
        "    model.eval()\n",
        "    z_e_x = torch.randn(64, Z_DIM, 1, 1).cuda()\n",
        "    x_tilde = model.decoder(z_e_x)\n",
        "\n",
        "    images = (x_tilde.cpu().data + 1) / 2\n",
        "\n",
        "    save_image(\n",
        "        images,\n",
        "        'samples/vae_samples_{}.png'.format(DATASET),\n",
        "        nrow=8\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Completed!\tLoss: 2777.6169 Time: 0.861 s\n",
            "Saving model!\n",
            "Epoch 2:\n",
            "\n",
            "Validation Completed!\tLoss: 1126.2717 Time: 0.885 s\n",
            "Saving model!\n",
            "Epoch 3:\n",
            "\n",
            "Validation Completed!\tLoss: 972.3497 Time: 0.929 s\n",
            "Saving model!\n",
            "Epoch 4:\n",
            "\n",
            "Validation Completed!\tLoss: 1135.3329 Time: 0.927 s\n",
            "Not saving model! Last saved: 3\n",
            "Epoch 5:\n",
            "\n",
            "Validation Completed!\tLoss: 790.3290 Time: 0.910 s\n",
            "Saving model!\n",
            "Epoch 6:\n",
            "\n",
            "Validation Completed!\tLoss: 755.8874 Time: 0.915 s\n",
            "Saving model!\n",
            "Epoch 7:\n",
            "\n",
            "Validation Completed!\tLoss: 717.1599 Time: 0.932 s\n",
            "Saving model!\n",
            "Epoch 8:\n",
            "\n",
            "Validation Completed!\tLoss: 684.0746 Time: 0.912 s\n",
            "Saving model!\n",
            "Epoch 9:\n",
            "\n",
            "Validation Completed!\tLoss: 708.1324 Time: 0.939 s\n",
            "Not saving model! Last saved: 8\n",
            "Epoch 10:\n",
            "\n",
            "Validation Completed!\tLoss: 709.3853 Time: 0.914 s\n",
            "Not saving model! Last saved: 8\n",
            "Epoch 11:\n",
            "\n",
            "Validation Completed!\tLoss: 659.0143 Time: 0.935 s\n",
            "Saving model!\n",
            "Epoch 12:\n",
            "\n",
            "Validation Completed!\tLoss: 744.4080 Time: 0.916 s\n",
            "Not saving model! Last saved: 11\n",
            "Epoch 13:\n",
            "\n",
            "Validation Completed!\tLoss: 770.1364 Time: 0.902 s\n",
            "Not saving model! Last saved: 11\n",
            "Epoch 14:\n",
            "\n",
            "Validation Completed!\tLoss: 684.2791 Time: 0.922 s\n",
            "Not saving model! Last saved: 11\n",
            "Epoch 15:\n",
            "\n",
            "Validation Completed!\tLoss: 710.0839 Time: 0.937 s\n",
            "Not saving model! Last saved: 11\n",
            "Epoch 16:\n",
            "\n",
            "Validation Completed!\tLoss: 695.1294 Time: 0.871 s\n",
            "Not saving model! Last saved: 11\n",
            "Epoch 17:\n",
            "\n",
            "Validation Completed!\tLoss: 666.1513 Time: 0.939 s\n",
            "Not saving model! Last saved: 11\n",
            "Epoch 18:\n",
            "\n",
            "Validation Completed!\tLoss: 638.8777 Time: 0.891 s\n",
            "Saving model!\n",
            "Epoch 19:\n",
            "\n",
            "Validation Completed!\tLoss: 673.4066 Time: 0.939 s\n",
            "Not saving model! Last saved: 18\n",
            "Epoch 20:\n",
            "\n",
            "Validation Completed!\tLoss: 595.7859 Time: 0.911 s\n",
            "Saving model!\n",
            "Epoch 21:\n",
            "\n",
            "Validation Completed!\tLoss: 700.4629 Time: 0.897 s\n",
            "Not saving model! Last saved: 20\n",
            "Epoch 22:\n",
            "\n",
            "Validation Completed!\tLoss: 602.7094 Time: 0.911 s\n",
            "Not saving model! Last saved: 20\n",
            "Epoch 23:\n",
            "\n",
            "Validation Completed!\tLoss: 547.5401 Time: 0.925 s\n",
            "Saving model!\n",
            "Epoch 24:\n",
            "\n",
            "Validation Completed!\tLoss: 675.9872 Time: 0.892 s\n",
            "Not saving model! Last saved: 23\n",
            "Epoch 25:\n",
            "\n",
            "Validation Completed!\tLoss: 622.3910 Time: 0.906 s\n",
            "Not saving model! Last saved: 23\n",
            "Epoch 26:\n",
            "\n",
            "Validation Completed!\tLoss: 522.5871 Time: 0.938 s\n",
            "Saving model!\n",
            "Epoch 27:\n",
            "\n",
            "Validation Completed!\tLoss: 515.9411 Time: 0.904 s\n",
            "Saving model!\n",
            "Epoch 28:\n",
            "\n",
            "Validation Completed!\tLoss: 550.7646 Time: 0.893 s\n",
            "Not saving model! Last saved: 27\n",
            "Epoch 29:\n",
            "\n",
            "Validation Completed!\tLoss: 510.2070 Time: 0.929 s\n",
            "Saving model!\n",
            "Epoch 30:\n",
            "\n",
            "Validation Completed!\tLoss: 511.1264 Time: 0.891 s\n",
            "Not saving model! Last saved: 29\n",
            "Epoch 31:\n",
            "\n",
            "Validation Completed!\tLoss: 570.8195 Time: 0.894 s\n",
            "Not saving model! Last saved: 29\n",
            "Epoch 32:\n",
            "\n",
            "Validation Completed!\tLoss: 569.8472 Time: 0.920 s\n",
            "Not saving model! Last saved: 29\n",
            "Epoch 33:\n",
            "\n",
            "Validation Completed!\tLoss: 509.5888 Time: 0.941 s\n",
            "Saving model!\n",
            "Epoch 34:\n",
            "\n",
            "Validation Completed!\tLoss: 520.8156 Time: 0.897 s\n",
            "Not saving model! Last saved: 33\n",
            "Epoch 35:\n",
            "\n",
            "Validation Completed!\tLoss: 496.7679 Time: 0.904 s\n",
            "Saving model!\n",
            "Epoch 36:\n",
            "\n",
            "Validation Completed!\tLoss: 489.1108 Time: 0.878 s\n",
            "Saving model!\n",
            "Epoch 37:\n",
            "\n",
            "Validation Completed!\tLoss: 601.1388 Time: 0.922 s\n",
            "Not saving model! Last saved: 36\n",
            "Epoch 38:\n",
            "\n",
            "Validation Completed!\tLoss: 785.6307 Time: 0.930 s\n",
            "Not saving model! Last saved: 36\n",
            "Epoch 39:\n",
            "\n",
            "Validation Completed!\tLoss: 675.7471 Time: 0.908 s\n",
            "Not saving model! Last saved: 36\n",
            "Epoch 40:\n",
            "\n",
            "Validation Completed!\tLoss: 518.7689 Time: 0.924 s\n",
            "Not saving model! Last saved: 36\n",
            "Epoch 41:\n",
            "\n",
            "Validation Completed!\tLoss: 594.0899 Time: 0.929 s\n",
            "Not saving model! Last saved: 36\n",
            "Epoch 42:\n",
            "\n",
            "Validation Completed!\tLoss: 490.2623 Time: 0.924 s\n",
            "Not saving model! Last saved: 36\n",
            "Epoch 43:\n",
            "\n",
            "Validation Completed!\tLoss: 488.8396 Time: 0.924 s\n",
            "Saving model!\n",
            "Epoch 44:\n",
            "\n",
            "Validation Completed!\tLoss: 458.9588 Time: 0.918 s\n",
            "Saving model!\n",
            "Epoch 45:\n",
            "\n",
            "Validation Completed!\tLoss: 517.4991 Time: 0.928 s\n",
            "Not saving model! Last saved: 44\n",
            "Epoch 46:\n",
            "\n",
            "Validation Completed!\tLoss: 458.4976 Time: 0.910 s\n",
            "Saving model!\n",
            "Epoch 47:\n",
            "\n",
            "Validation Completed!\tLoss: 477.4295 Time: 0.901 s\n",
            "Not saving model! Last saved: 46\n",
            "Epoch 48:\n",
            "\n",
            "Validation Completed!\tLoss: 509.3709 Time: 0.930 s\n",
            "Not saving model! Last saved: 46\n",
            "Epoch 49:\n",
            "\n",
            "Validation Completed!\tLoss: 506.3285 Time: 0.936 s\n",
            "Not saving model! Last saved: 46\n",
            "Epoch 50:\n",
            "\n",
            "Validation Completed!\tLoss: 538.1369 Time: 0.918 s\n",
            "Not saving model! Last saved: 46\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 51:\n",
            "\n",
            "Validation Completed!\tLoss: 470.0304 Time: 0.925 s\n",
            "Not saving model! Last saved: 46\n",
            "Epoch 52:\n",
            "\n",
            "Validation Completed!\tLoss: 528.2658 Time: 0.893 s\n",
            "Not saving model! Last saved: 46\n",
            "Epoch 53:\n",
            "\n",
            "Validation Completed!\tLoss: 492.2996 Time: 0.923 s\n",
            "Not saving model! Last saved: 46\n",
            "Epoch 54:\n",
            "\n",
            "Validation Completed!\tLoss: 443.7544 Time: 0.885 s\n",
            "Saving model!\n",
            "Epoch 55:\n",
            "\n",
            "Validation Completed!\tLoss: 425.8155 Time: 0.894 s\n",
            "Saving model!\n",
            "Epoch 56:\n",
            "\n",
            "Validation Completed!\tLoss: 440.9887 Time: 0.917 s\n",
            "Not saving model! Last saved: 55\n",
            "Epoch 57:\n",
            "\n",
            "Validation Completed!\tLoss: 447.4692 Time: 0.919 s\n",
            "Not saving model! Last saved: 55\n",
            "Epoch 58:\n",
            "\n",
            "Validation Completed!\tLoss: 501.8758 Time: 0.895 s\n",
            "Not saving model! Last saved: 55\n",
            "Epoch 59:\n",
            "\n",
            "Validation Completed!\tLoss: 580.7373 Time: 0.904 s\n",
            "Not saving model! Last saved: 55\n",
            "Epoch 60:\n",
            "\n",
            "Validation Completed!\tLoss: 528.8986 Time: 0.931 s\n",
            "Not saving model! Last saved: 55\n",
            "Epoch 61:\n",
            "\n",
            "Validation Completed!\tLoss: 533.1783 Time: 0.905 s\n",
            "Not saving model! Last saved: 55\n",
            "Epoch 62:\n",
            "\n",
            "Validation Completed!\tLoss: 507.2183 Time: 0.890 s\n",
            "Not saving model! Last saved: 55\n",
            "Epoch 63:\n",
            "\n",
            "Validation Completed!\tLoss: 499.1252 Time: 0.871 s\n",
            "Not saving model! Last saved: 55\n",
            "Epoch 64:\n",
            "\n",
            "Validation Completed!\tLoss: 439.7404 Time: 0.890 s\n",
            "Not saving model! Last saved: 55\n",
            "Epoch 65:\n",
            "\n",
            "Validation Completed!\tLoss: 425.6332 Time: 0.871 s\n",
            "Saving model!\n",
            "Epoch 66:\n",
            "\n",
            "Validation Completed!\tLoss: 437.5693 Time: 0.897 s\n",
            "Not saving model! Last saved: 65\n",
            "Epoch 67:\n",
            "\n",
            "Validation Completed!\tLoss: 399.8049 Time: 0.920 s\n",
            "Saving model!\n",
            "Epoch 68:\n",
            "\n",
            "Validation Completed!\tLoss: 399.7684 Time: 0.897 s\n",
            "Saving model!\n",
            "Epoch 69:\n",
            "\n",
            "Validation Completed!\tLoss: 391.2449 Time: 0.884 s\n",
            "Saving model!\n",
            "Epoch 70:\n",
            "\n",
            "Validation Completed!\tLoss: 408.5042 Time: 0.927 s\n",
            "Not saving model! Last saved: 69\n",
            "Epoch 71:\n",
            "\n",
            "Validation Completed!\tLoss: 414.8999 Time: 0.934 s\n",
            "Not saving model! Last saved: 69\n",
            "Epoch 72:\n",
            "\n",
            "Validation Completed!\tLoss: 408.3684 Time: 0.934 s\n",
            "Not saving model! Last saved: 69\n",
            "Epoch 73:\n",
            "\n",
            "Validation Completed!\tLoss: 406.2295 Time: 0.944 s\n",
            "Not saving model! Last saved: 69\n",
            "Epoch 74:\n",
            "\n",
            "Validation Completed!\tLoss: 450.5569 Time: 0.936 s\n",
            "Not saving model! Last saved: 69\n",
            "Epoch 75:\n",
            "\n",
            "Validation Completed!\tLoss: 417.7052 Time: 0.911 s\n",
            "Not saving model! Last saved: 69\n",
            "Epoch 76:\n",
            "\n",
            "Validation Completed!\tLoss: 397.4744 Time: 0.932 s\n",
            "Not saving model! Last saved: 69\n",
            "Epoch 77:\n",
            "\n",
            "Validation Completed!\tLoss: 403.1011 Time: 0.922 s\n",
            "Not saving model! Last saved: 69\n",
            "Epoch 78:\n",
            "\n",
            "Validation Completed!\tLoss: 415.8209 Time: 0.928 s\n",
            "Not saving model! Last saved: 69\n",
            "Epoch 79:\n",
            "\n",
            "Validation Completed!\tLoss: 382.5431 Time: 0.930 s\n",
            "Saving model!\n",
            "Epoch 80:\n",
            "\n",
            "Validation Completed!\tLoss: 385.9583 Time: 0.870 s\n",
            "Not saving model! Last saved: 79\n",
            "Epoch 81:\n",
            "\n",
            "Validation Completed!\tLoss: 366.5252 Time: 0.936 s\n",
            "Saving model!\n",
            "Epoch 82:\n",
            "\n",
            "Validation Completed!\tLoss: 362.2036 Time: 0.916 s\n",
            "Saving model!\n",
            "Epoch 83:\n",
            "\n",
            "Validation Completed!\tLoss: 349.7089 Time: 0.919 s\n",
            "Saving model!\n",
            "Epoch 84:\n",
            "\n",
            "Validation Completed!\tLoss: 363.2367 Time: 0.941 s\n",
            "Not saving model! Last saved: 83\n",
            "Epoch 85:\n",
            "\n",
            "Validation Completed!\tLoss: 368.2621 Time: 0.891 s\n",
            "Not saving model! Last saved: 83\n",
            "Epoch 86:\n",
            "\n",
            "Validation Completed!\tLoss: 356.7896 Time: 0.917 s\n",
            "Not saving model! Last saved: 83\n",
            "Epoch 87:\n",
            "\n",
            "Validation Completed!\tLoss: 352.1127 Time: 0.892 s\n",
            "Not saving model! Last saved: 83\n",
            "Epoch 88:\n",
            "\n",
            "Validation Completed!\tLoss: 377.6432 Time: 0.884 s\n",
            "Not saving model! Last saved: 83\n",
            "Epoch 89:\n",
            "\n",
            "Validation Completed!\tLoss: 436.7818 Time: 0.917 s\n",
            "Not saving model! Last saved: 83\n",
            "Epoch 90:\n",
            "\n",
            "Validation Completed!\tLoss: 371.1467 Time: 0.929 s\n",
            "Not saving model! Last saved: 83\n",
            "Epoch 91:\n",
            "\n",
            "Validation Completed!\tLoss: 446.6180 Time: 0.926 s\n",
            "Not saving model! Last saved: 83\n",
            "Epoch 92:\n",
            "\n",
            "Validation Completed!\tLoss: 362.5943 Time: 0.902 s\n",
            "Not saving model! Last saved: 83\n",
            "Epoch 93:\n",
            "\n",
            "Validation Completed!\tLoss: 399.7868 Time: 0.893 s\n",
            "Not saving model! Last saved: 83\n",
            "Epoch 94:\n",
            "\n",
            "Validation Completed!\tLoss: 356.1926 Time: 0.934 s\n",
            "Not saving model! Last saved: 83\n",
            "Epoch 95:\n",
            "\n",
            "Validation Completed!\tLoss: 356.7613 Time: 0.928 s\n",
            "Not saving model! Last saved: 83\n",
            "Epoch 96:\n",
            "\n",
            "Validation Completed!\tLoss: 390.4553 Time: 0.894 s\n",
            "Not saving model! Last saved: 83\n",
            "Epoch 97:\n",
            "\n",
            "Validation Completed!\tLoss: 382.3761 Time: 0.930 s\n",
            "Not saving model! Last saved: 83\n",
            "Epoch 98:\n",
            "\n",
            "Validation Completed!\tLoss: 336.7859 Time: 0.890 s\n",
            "Saving model!\n",
            "Epoch 99:\n",
            "\n",
            "Validation Completed!\tLoss: 393.9122 Time: 0.923 s\n",
            "Not saving model! Last saved: 98\n",
            "Epoch 100:\n",
            "\n",
            "Validation Completed!\tLoss: 412.7171 Time: 0.940 s\n",
            "Not saving model! Last saved: 98\n",
            "Epoch 101:\n",
            "\n",
            "Validation Completed!\tLoss: 355.6527 Time: 0.879 s\n",
            "Not saving model! Last saved: 98\n",
            "Epoch 102:\n",
            "\n",
            "Validation Completed!\tLoss: 358.6392 Time: 0.907 s\n",
            "Not saving model! Last saved: 98\n",
            "Epoch 103:\n",
            "\n",
            "Validation Completed!\tLoss: 400.0049 Time: 0.928 s\n",
            "Not saving model! Last saved: 98\n",
            "Epoch 104:\n",
            "\n",
            "Validation Completed!\tLoss: 396.0251 Time: 0.937 s\n",
            "Not saving model! Last saved: 98\n",
            "Epoch 105:\n",
            "\n",
            "Validation Completed!\tLoss: 325.3541 Time: 0.921 s\n",
            "Saving model!\n",
            "Epoch 106:\n",
            "\n",
            "Validation Completed!\tLoss: 420.5379 Time: 0.888 s\n",
            "Not saving model! Last saved: 105\n",
            "Epoch 107:\n",
            "\n",
            "Validation Completed!\tLoss: 352.0461 Time: 0.908 s\n",
            "Not saving model! Last saved: 105\n",
            "Epoch 108:\n",
            "\n",
            "Validation Completed!\tLoss: 336.7732 Time: 0.901 s\n",
            "Not saving model! Last saved: 105\n",
            "Epoch 109:\n",
            "\n",
            "Validation Completed!\tLoss: 339.6149 Time: 0.934 s\n",
            "Not saving model! Last saved: 105\n",
            "Epoch 110:\n",
            "\n",
            "Validation Completed!\tLoss: 333.5489 Time: 0.907 s\n",
            "Not saving model! Last saved: 105\n",
            "Epoch 111:\n",
            "\n",
            "Validation Completed!\tLoss: 359.3335 Time: 0.917 s\n",
            "Not saving model! Last saved: 105\n",
            "Epoch 112:\n",
            "\n",
            "Validation Completed!\tLoss: 315.9574 Time: 0.926 s\n",
            "Saving model!\n",
            "Epoch 113:\n",
            "\n",
            "Validation Completed!\tLoss: 351.3649 Time: 0.889 s\n",
            "Not saving model! Last saved: 112\n",
            "Epoch 114:\n",
            "\n",
            "Validation Completed!\tLoss: 344.3995 Time: 0.927 s\n",
            "Not saving model! Last saved: 112\n",
            "Epoch 115:\n",
            "\n",
            "Validation Completed!\tLoss: 331.4007 Time: 0.921 s\n",
            "Not saving model! Last saved: 112\n",
            "Epoch 116:\n",
            "\n",
            "Validation Completed!\tLoss: 328.7338 Time: 0.926 s\n",
            "Not saving model! Last saved: 112\n",
            "Epoch 117:\n",
            "\n",
            "Validation Completed!\tLoss: 402.3654 Time: 0.937 s\n",
            "Not saving model! Last saved: 112\n",
            "Epoch 118:\n",
            "\n",
            "Validation Completed!\tLoss: 304.2055 Time: 0.898 s\n",
            "Saving model!\n",
            "Epoch 119:\n",
            "\n",
            "Validation Completed!\tLoss: 334.4239 Time: 0.928 s\n",
            "Not saving model! Last saved: 118\n",
            "Epoch 120:\n",
            "\n",
            "Validation Completed!\tLoss: 328.1973 Time: 0.930 s\n",
            "Not saving model! Last saved: 118\n",
            "Epoch 121:\n",
            "\n",
            "Validation Completed!\tLoss: 341.6790 Time: 0.934 s\n",
            "Not saving model! Last saved: 118\n",
            "Epoch 122:\n",
            "\n",
            "Validation Completed!\tLoss: 316.4260 Time: 0.940 s\n",
            "Not saving model! Last saved: 118\n",
            "Epoch 123:\n",
            "\n",
            "Validation Completed!\tLoss: 316.8904 Time: 0.890 s\n",
            "Not saving model! Last saved: 118\n",
            "Epoch 124:\n",
            "\n",
            "Validation Completed!\tLoss: 319.4291 Time: 0.917 s\n",
            "Not saving model! Last saved: 118\n",
            "Epoch 125:\n",
            "\n",
            "Validation Completed!\tLoss: 325.1719 Time: 0.927 s\n",
            "Not saving model! Last saved: 118\n",
            "Epoch 126:\n",
            "\n",
            "Validation Completed!\tLoss: 333.3939 Time: 0.905 s\n",
            "Not saving model! Last saved: 118\n",
            "Epoch 127:\n",
            "\n",
            "Validation Completed!\tLoss: 380.4235 Time: 0.935 s\n",
            "Not saving model! Last saved: 118\n",
            "Epoch 128:\n",
            "\n",
            "Validation Completed!\tLoss: 314.0121 Time: 0.948 s\n",
            "Not saving model! Last saved: 118\n",
            "Epoch 129:\n",
            "\n",
            "Validation Completed!\tLoss: 303.1969 Time: 0.923 s\n",
            "Saving model!\n",
            "Epoch 130:\n",
            "\n",
            "Validation Completed!\tLoss: 320.7022 Time: 0.938 s\n",
            "Not saving model! Last saved: 129\n",
            "Epoch 131:\n",
            "\n",
            "Validation Completed!\tLoss: 389.4123 Time: 0.910 s\n",
            "Not saving model! Last saved: 129\n",
            "Epoch 132:\n",
            "\n",
            "Validation Completed!\tLoss: 350.7432 Time: 0.921 s\n",
            "Not saving model! Last saved: 129\n",
            "Epoch 133:\n",
            "\n",
            "Validation Completed!\tLoss: 312.2831 Time: 0.906 s\n",
            "Not saving model! Last saved: 129\n",
            "Epoch 134:\n",
            "\n",
            "Validation Completed!\tLoss: 325.0398 Time: 0.944 s\n",
            "Not saving model! Last saved: 129\n",
            "Epoch 135:\n",
            "\n",
            "Validation Completed!\tLoss: 303.7075 Time: 0.924 s\n",
            "Not saving model! Last saved: 129\n",
            "Epoch 136:\n",
            "\n",
            "Validation Completed!\tLoss: 312.7582 Time: 0.886 s\n",
            "Not saving model! Last saved: 129\n",
            "Epoch 137:\n",
            "\n",
            "Validation Completed!\tLoss: 306.4611 Time: 0.942 s\n",
            "Not saving model! Last saved: 129\n",
            "Epoch 138:\n",
            "\n",
            "Validation Completed!\tLoss: 297.0110 Time: 0.932 s\n",
            "Saving model!\n",
            "Epoch 139:\n",
            "\n",
            "Validation Completed!\tLoss: 297.3482 Time: 0.933 s\n",
            "Not saving model! Last saved: 138\n",
            "Epoch 140:\n",
            "\n",
            "Validation Completed!\tLoss: 300.5099 Time: 0.927 s\n",
            "Not saving model! Last saved: 138\n",
            "Epoch 141:\n",
            "\n",
            "Validation Completed!\tLoss: 309.7850 Time: 0.890 s\n",
            "Not saving model! Last saved: 138\n",
            "Epoch 142:\n",
            "\n",
            "Validation Completed!\tLoss: 309.3974 Time: 0.920 s\n",
            "Not saving model! Last saved: 138\n",
            "Epoch 143:\n",
            "\n",
            "Validation Completed!\tLoss: 341.7031 Time: 0.936 s\n",
            "Not saving model! Last saved: 138\n",
            "Epoch 144:\n",
            "\n",
            "Validation Completed!\tLoss: 316.2288 Time: 0.893 s\n",
            "Not saving model! Last saved: 138\n",
            "Epoch 145:\n",
            "\n",
            "Validation Completed!\tLoss: 427.0264 Time: 0.910 s\n",
            "Not saving model! Last saved: 138\n",
            "Epoch 146:\n",
            "\n",
            "Validation Completed!\tLoss: 346.7676 Time: 0.925 s\n",
            "Not saving model! Last saved: 138\n",
            "Epoch 147:\n",
            "\n",
            "Validation Completed!\tLoss: 332.6573 Time: 0.895 s\n",
            "Not saving model! Last saved: 138\n",
            "Epoch 148:\n",
            "\n",
            "Validation Completed!\tLoss: 298.4692 Time: 0.885 s\n",
            "Not saving model! Last saved: 138\n",
            "Epoch 149:\n",
            "\n",
            "Validation Completed!\tLoss: 296.5660 Time: 0.889 s\n",
            "Saving model!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFLvqQbbpaHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BEST_LOSS = 99999\n",
        "LAST_SAVED = -1\n",
        "for epoch in range(1, N_EPOCHS):\n",
        "    print(\"Epoch {}:\".format(epoch))\n",
        "    train()\n",
        "    cur_loss = test()\n",
        "\n",
        "    if cur_loss <= BEST_LOSS:\n",
        "        BEST_LOSS = cur_loss\n",
        "        LAST_SAVED = epoch\n",
        "        print(\"Saving model!\")\n",
        "        torch.save(model.state_dict(), 'models/{}_vae.pt'.format(DATASET))\n",
        "    else:\n",
        "        print(\"Not saving model! Last saved: {}\".format(LAST_SAVED))\n",
        "\n",
        "    generate_reconstructions()\n",
        "    generate_samples()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyBG8oz0hodo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def loss_function(recon_x, x, mu, logvar) -> Variable:\n",
        "#     # how well do input x and output recon_x agree?\n",
        "#     BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784))\n",
        "\n",
        "#     # KLD is KullbackLeibler divergence -- how much does one learned\n",
        "#     # distribution deviate from another, in this specific case the\n",
        "#     # learned distribution from the unit Gaussian\n",
        "\n",
        "#     # see Appendix B from VAE paper:\n",
        "#     # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "#     # https://arxiv.org/abs/1312.6114\n",
        "#     # - D_{KL} = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "#     # note the negative D_{KL} in appendix B of the paper\n",
        "#     KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "#     # Normalise by same number of elements as in reconstruction\n",
        "#     KLD /= BATCH_SIZE * 784\n",
        "\n",
        "#     # BCE tries to make our reconstruction as accurate as possible\n",
        "#     # KLD tries to push the distributions as close as possible to unit Gaussian\n",
        "#     return BCE + KLD\n",
        "\n",
        "# # Dr Diederik Kingma: as if VAEs weren't enough, he also gave us Adam!\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdWJGPmBzGiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def train(epoch):\n",
        "#     # toggle model to train mode\n",
        "#     model.train()\n",
        "#     train_loss = 0\n",
        "#     # in the case of MNIST, len(train_loader.dataset) is 60000\n",
        "#     # each `data` is of BATCH_SIZE samples and has shape [128, 1, 28, 28]\n",
        "#     for batch_idx, (data, _) in enumerate(train_loader):\n",
        "#         data = Variable(data)\n",
        "#         if CUDA:\n",
        "#             data = data.cuda()\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         # push whole batch of data through VAE.forward() to get recon_loss\n",
        "#         recon_batch, mu, logvar = model(data)\n",
        "#         # calculate scalar loss\n",
        "#         loss = loss_function(recon_batch, data, mu, logvar)\n",
        "#         # calculate the gradient of the loss w.r.t. the graph leaves\n",
        "#         # i.e. input variables -- by the power of pytorch!\n",
        "#         loss.backward()\n",
        "#         train_loss += loss.data#[0]\n",
        "#         optimizer.step()\n",
        "#         if batch_idx % LOG_INTERVAL == 0:\n",
        "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "#                 100. * batch_idx / len(train_loader),\n",
        "#                 loss.data/ len(data)))\n",
        "\n",
        "#     print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "#           epoch, train_loss / len(train_loader.dataset)))\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_uoH4M1zHui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def test(epoch):\n",
        "#     # toggle model to test / inference mode\n",
        "#     model.eval()\n",
        "#     test_loss = 0\n",
        "\n",
        "#     # each data is of BATCH_SIZE (default 128) samples\n",
        "#     for i, (data, _) in enumerate(test_loader):\n",
        "#         if CUDA:\n",
        "#             # make sure this lives on the GPU\n",
        "#             data = data.cuda()\n",
        "\n",
        "#         # we're only going to infer, so no autograd at all required: volatile=True\n",
        "#         data = Variable(data, volatile=True)\n",
        "#         recon_batch, mu, logvar = model(data)\n",
        "#         test_loss += loss_function(recon_batch, data, mu, logvar).data#[0]\n",
        "#         if i == 0:\n",
        "#           n = min(data.size(0), 8)\n",
        "#           # for the first 128 batch of the epoch, show the first 8 input digits\n",
        "#           # with right below them the reconstructed output digits\n",
        "#           comparison = torch.cat([data[:n],\n",
        "#                                   recon_batch.view(BATCH_SIZE, 1, 28, 28)[:n]])\n",
        "#           save_image(comparison.data.cpu(),\n",
        "#                      'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
        "\n",
        "#     test_loss /= len(test_loader.dataset)\n",
        "#     print('====> Test set loss: {:.4f}'.format(test_loss))\n",
        "\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dBS-vQdqXzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf results\n",
        "!mkdir results"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhAgS6ZOzTco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for epoch in range(1, EPOCHS + 1):\n",
        "#     train(epoch)\n",
        "#     test(epoch)\n",
        "\n",
        "#     # 64 sets of random ZDIMS-float vectors, i.e. 64 locations / MNIST\n",
        "#     # digits in latent space\n",
        "#     sample = Variable(torch.randn(64, ZDIMS))\n",
        "#     if CUDA:\n",
        "#         sample = sample.cuda()\n",
        "#     sample = model.decode(sample).cpu()\n",
        "\n",
        "#     # save out as an 8x8 matrix of MNIST digits\n",
        "#     # this will give you a visual idea of how well latent space can generate things\n",
        "#     # that look like digits\n",
        "#     save_image(sample.data.view(64, 1, 28, 28),'results/sample_' + str(epoch) + '.png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}